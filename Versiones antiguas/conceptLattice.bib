@InProceedings{valverdeipmu18art,
author="Valverde-Albacete, Francisco J.
and Pel{\'a}ez-Moreno, Carmen
and Cabrera, Inma P.
and Cordero, Pablo
and Ojeda-Aciego, Manuel",
editor="Medina, Jes{\'u}s
and Ojeda-Aciego, Manuel
and Verdegay, Jos{\'e} Luis
and Pelta, David A.
and Cabrera, Inma P.
and Bouchon-Meunier, Bernadette
and Yager, Ronald R.",
title="Formal Independence Analysis",
booktitle="Information Processing and Management of Uncertainty in Knowledge-Based Systems. Theory and Foundations",
year="2018",
publisher="Springer International Publishing",
address="Cham",
pages="596--608",
abstract="In this paper we propose a new lens through which to observe the information contained in a formal context. Instead of focusing on the hierarchical relation between objects or attributes induced by their incidence, we focus on the ``unrelatedness'' of the objects with respect to those attributes with which they are not incident. The crucial order concept for this is that of maximal anti-chain and the corresponding representation capabilities are provided by Behrendt's theorem. With these tools we introduce the fundamental theorem of Formal Independence Analysis and use it to provide an example of what its affordances are for the analysis of data tables. We also discuss its relation to Formal Concept Analysis.",
isbn="978-3-319-91473-2"
}

@article{COAMfac2024,
title = {Factorizing formal contexts from closures of necessity operators},
AUTHOR = {Arag\'on, Roberto G. and Medina, Jes\'us and Ram\'irez-Poussa, Elo\'isa},
journal = {Computational and Applied Mathematics},
volume = {X},
pages = {1-32},
year = {2024},
doi = {https://doi.org/10.1007/s40314-024-02590-0},
note={In press}
}


@inproceedings{Trevor96, 
author = {Jones, Trevor H. and Song, Il-Yeol and Park, E. K.}, 
title = {Ternary Relationship Decomposition and Higher Normal Form Structures Derived from Entity Relationship Conceptual Modeling}, 
year = {1996}, 
isbn = {0897918282}, 
publisher = {Association for Computing Machinery}, 
address = {New York, NY, USA}, 
url = {https://doi.org/10.1145/228329.228340}, 
doi = {10.1145/228329.228340}, 
booktitle = {Proceedings of the 1996 ACM 24th Annual Conference on Computer Science}, 
pages = {96--104}, 
numpages = {9}, 
keywords = {higher normal forms, conceptual modeling, entity relationship, ternary relationship}, 
location = {Philadelphia, Pennsylvania, USA}, 
series = {CSC '96} }

@inproceedings{Heath71, 
author = {Heath, I. J.}, 
title = {Unacceptable File Operations in a Relational Data Base}, 
year = {1971}, 
isbn = {9781450373005}, 
publisher = {Association for Computing Machinery}, 
address = {New York, NY, USA}, 
url = {https://doi.org/10.1145/1734714.1734717}, 
doi = {10.1145/1734714.1734717}, 
abstract = {This paper is written within the context of a relational data base model as presented by E. F. Codd in [1]. It also serves as a companion paper to his paper [2].The central thesis is that a file operation should not produce unexpected 'side effects' in order to maintain a restriction (such as one-one, or many-one) on the file. Any file operation which would violate a restriction for some possible data is called 'violative'. It is determined which cases of the file operations WRITE, REWRITE and DELETE are violative. We argue that most violative file operations should be rejected. Instead, the equivalent operations should be carried out on projections in E. F. Codd's 'third normal form' in order to alleviate the necessity for spurious side effects. It is therefore convenient for the programmer to be able to refer directly to these projections by name and for the data management system to allow operations on them. This provides further justification to that in [2] for modelling the data base interface between programmer and data management system in terms of relations in 'third normal form'.}, 
booktitle = {Proceedings of the 1971 ACM SIGFIDET (Now SIGMOD) Workshop on Data Description, Access and Control},
pages = {19--33}, 
numpages = {15}, 
location = {San Diego, California}, 
series = {SIGFIDET '71} }


@article{Fagin77, author = {Fagin, Ronald}, title = {Multivalued Dependencies and a New Normal Form for Relational Databases}, year = {1977}, issue_date = {Sept. 1977}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, volume = {2}, number = {3}, issn = {0362-5915}, url = {https://doi.org/10.1145/320557.320571}, doi = {10.1145/320557.320571}, abstract = {A new type of dependency, which includes the well-known functional dependencies as a special case, is defined for relational databases. By using this concept, a new (“fourth”) normal form for relation schemata is defined. This fourth normal form is strictly stronger than Codd's “improved third normal form” (or “Boyce-Codd normal form”). It is shown that every relation schema can be decomposed into a family of relation schemata in fourth normal form without loss of information (that is, the original relation can be obtained from the new relations by taking joins).}, journal = {ACM Trans. Database Syst.}, month = {sep}, pages = {262--278}, numpages = {17}, keywords = {database design, 4NF, Boyce-Codd normal form, fourth normal form, relatioanl database, multivalued dependency, decomposition, 3NF, normalization, functional dependency, third normal form} }


@ARTICLE{Chi2023,
	author = {Chi, Xiao-Jv and Song, Yi-Bei and Liu, Deng-He and Wei, Li-Qiang and An, Xin and Feng, Zi-Zhen and Lan, Xiao-Hua and Lan, Dong and Huang, Chao},
	title = {Significance of platelet adhesion-related genes in colon cancer based on non-negative matrix factorization-based clustering algorithm},
	year = {2023},
	journal = {Digital Health},
	volume = {9},
	doi = {10.1177/20552076231203902},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172162826&doi=10.1177%2f20552076231203902&partnerID=40&md5=8b78b458523c969d3857ef149470275f},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@inproceedings{Ene2008,
author = {Ene, Alina and Horne, William and Milosavljevic, Nikola and Rao, Prasad and Schreiber, Robert and Tarjan, Robert E.},
title = {Fast Exact and Heuristic Methods for Role Minimization Problems},
year = {2008},
isbn = {9781605581293},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1377836.1377838},
doi = {10.1145/1377836.1377838},
abstract = {We describe several new bottom-up approaches to problems in role engineering for Role-Based Access Control (RBAC). The salient problems are all NP-complete, even to approximate, yet we find that in instances that arise in practice these problems can be solved in minutes. We first consider role minimization, the process of finding a smallest collection of roles that can be used to implement a pre-existing user-to-permission relation. We introduce fast graph reductions that allow recovery of the solution from the solution to a problem on a smaller input graph. For our test cases, these reductions either solve the problem, or reduce the problem enough that we find the optimum solution with a (worst-case) exponential method. We introduce lower bounds that are sharp for seven of nine test cases and are within 3.4\% on the other two. We introduce and test a new polynomial-time approximation that on average yields 2\% more roles than the optimum. We next consider the related problem of minimizing the number of connections between roles and users or permissions, and we develop effective heuristic methods for this problem as well. Finally, we propose methods for several related problems.},
booktitle = {Proceedings of the 13th ACM Symposium on Access Control Models and Technologies},
pages = {1--10},
numpages = {10},
keywords = {role mining, role-based access control},
location = {Estes Park, CO, USA},
series = {SACMAT '08}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@article{Myllykangas2006,
	author={Myllykangas, S.
	and Himberg, J.
	and B{\"o}hling, T.
	and Nagy, B.
	and Hollm{\'e}n, J.
	and Knuutila, S.},
	title={DNA copy number amplification profiling of human neoplasms},
	journal={Oncogene},
	year={2006},
	month={Nov},
	day={01},
	volume={25},
	number={55},
	pages={7324-7332},
	abstract={DNA copy number amplifications activate oncogenes and are hallmarks of nearly all advanced tumors. Amplified genes represent attractive targets for therapy, diagnostics and prognostics. To investigate DNA amplifications in different neoplasms, we performed a bibliomics survey using 838 published chromosomal comparative genomic hybridization studies and collected amplification data at chromosome band resolution from more than 4500 cases. Amplification profiles were determined for 73 distinct neoplasms. Neoplasms were clustered according to the amplification profiles, and frequently amplified chromosomal loci (amplification hot spots) were identified using computational modeling. To investigate the site specificity and mechanisms of gene amplifications, colocalization of amplification hot spots, cancer genes, fragile sites, virus integration sites and gene size cohorts were tested in a statistical framework. Amplification-based clustering demonstrated that cancers with similar etiology, cell-of-origin or topographical location have a tendency to obtain convergent amplification profiles. The identified amplification hot spots were colocalized with the known fragile sites, cancer genes and virus integration sites, but global statistical significance could not be ascertained. Large genes were significantly overrepresented on the fragile sites and the reported amplification hot spots. These findings indicate that amplifications are selected in the cancer tissue environment according to the qualitative traits and localization of cancer genes.},
	issn={1476-5594},
	doi={10.1038/sj.onc.1209717},
	url={https://doi.org/10.1038/sj.onc.1209717}
}



@article{BELOHLAVEK2015,
	title = {From-below approximations in Boolean matrix factorization: Geometry and new algorithm},
	journal = {Journal of Computer and System Sciences},
	volume = {81},
	number = {8},
	pages = {1678-1697},
	year = {2015},
	issn = {0022-0000},
	doi = {https://doi.org/10.1016/j.jcss.2015.06.002},
	url = {https://www.sciencedirect.com/science/article/pii/S002200001500063X},
	author = {Radim B{\v e}lohl{\'a}vek and Martin Trnecka},
	keywords = {Boolean matrix, Matrix decomposition, Closure structures, Concept lattice, Approximation algorithm},
	abstract = {We present new results on Boolean matrix factorization and a new algorithm based on these results. The results emphasize the significance of factorizations that provide from-below approximations of the input matrix. While the previously proposed algorithms do not consider the possibly different significance of different matrix entries, our results help measure such significance and suggest where to focus when computing factors. An experimental evaluation of the new algorithm on both synthetic and real data demonstrates its good performance in terms of good coverage by the first few factors as well as a small number of factors needed for an almost exact decomposition and indicates that the algorithm outperforms the available ones in these terms. We also propose future research topics.}
}

@article{singh19,
title = {Single-valued neutrosophic context analysis at distinct multi-granulation},
journal = {Computational and Applied Mathematics},
volume = {38(80)},
year = {2019},
doi = {https://doi.org/10.1007/s40314-019-0842-4},
author = {Prem Kumar Singh},
}

@article{singh18,
title = {Medical diagnoses using three-way fuzzy concept lattice and their Euclidean distance},
journal = {Computational and Applied Mathematics},
volume = {37},
pages = {3283-3306},
year = {2018},
doi = {https://doi.org/10.1007/s40314-017-0513-2},
author = {Prem Kumar Singh},
}

@article{Kome23,
title = {Factorizations and eigenvalues of the $(r, k)$-bonacci matrices},
journal = {Computational and Applied Mathematics},
volume = {42(1185)},
year = {2023},
doi = {https://doi.org/10.1007/s40314-023-02331-9},
author = {Cahit K\"{o}me},
}

@article{OJEDAHERNANDEZ23,
title = {Fuzzy closure structures as formal concepts},
journal = {Fuzzy Sets and Systems},
volume = {463},
pages = {108458},
year = {2023},
issn = {0165-0114},
doi = {https://doi.org/10.1016/j.fss.2022.12.014},
url = {https://www.sciencedirect.com/science/article/pii/S0165011422005139},
author = {Manuel Ojeda-Hern\'andez and Inma P. Cabrera and Pablo Cordero and Emilio Mu{\~n}oz-Velasco},
keywords = {Closure system, Galois connection, Fuzzy lattice},
abstract = {Galois connections seem to be ubiquitous in mathematics. They have been used to model solutions for both pure and application-oriented problems. Throughout the paper, the general framework is a complete fuzzy lattice over a complete residuated lattice. The existence of three fuzzy Galois connections (two antitone and one isotone) between three specific ordered sets is proved in this paper. The most interesting part is that fuzzy closure systems, fuzzy closure operators and strong fuzzy closure relations are formal concepts of these fuzzy Galois connections.}
}

@ARTICLE{Zhang10057970,
  author={Zhang, Xiaohe and Chen, Degang and Mi, Jusheng},
  journal={IEEE Transactions on Fuzzy Systems}, 
  title={Fuzzy Decision Rule-Based Online Classification Algorithm in Fuzzy Formal Decision Contexts}, 
  year={2023},
  volume={},
  number={},
  pages={1-15},
  doi={10.1109/TFUZZ.2023.3250955}}

@article{KOYDA202370,
title = {Factorizing lattices by interval relations},
journal = {International Journal of Approximate Reasoning},
volume = {157},
pages = {70-87},
year = {2023},
issn = {0888-613X},
doi = {https://doi.org/10.1016/j.ijar.2023.03.003},
url = {https://www.sciencedirect.com/science/article/pii/S0888613X2300035X},
author = {Maren Koyda and Gerd Stumme},
keywords = {Formal concept analysis, Lattices, Intervals, Factorization, Order, Crowns},
abstract = {This work investigates the factorization of finite lattices to implode selected intervals while preserving the remaining order structure. We examine how complete congruence relations and complete tolerance relations can be utilized for this purpose and answer the question of finding the finest of those relations to implode a given interval in the generated factor lattice. To overcome the limitations of the factorization based on those relations, we introduce a new lattice factorization that enables the imploding of selected disjoint intervals of a finite lattice. To this end, we propose an interval relation that generates this factorization. To obtain lattices rather than arbitrary ordered sets, we restrict this approach to so-called pure intervals. For our study, we will make use of methods from Formal Concept Analysis (FCA). We will also provide a new FCA construction by introducing the enrichment of an incidence relation by a set of intervals in a formal context, to investigate the approach for lattice-generating interval relations on the context side.}
}

@article{BARTL23,
title = {Avoiding flatness in factoring ordinal data},
journal = {Information Sciences},
volume = {629},
pages = {471-487},
year = {2023},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2023.02.002},
url = {https://www.sciencedirect.com/science/article/pii/S0020025523001755},
author = {Eduard Bartl and Radim B{\v e}lohl{\'a}vek},
keywords = {Factor analysis, Ordinal attributes, Fuzzy logic, Quality of factors},
abstract = {Factorization of classical, two-valued Boolean data became a widely studied topic in the past decade due to its role in analyzing relational data as well as its significance for other fields. Recently, various extensions to factorization of ordinal data, or data with graded (fuzzy) attributes, have been proposed. We identify and describe a fundamental problem regarding quality of factors, which is non-existent in the Boolean case, but naturally appears in the more general setting of ordinal data. As we demonstrate, the problem gets more significant with growing size of the factorized data. We analyze the problem, propose a method to alleviate it, and evaluate experimentally our solution to the problem. We also provide a discussion regarding ramifications of our findings for the concept of cardinality of fuzzy sets.}
}

@article{OLIVEIRA22,
title = {Unsupervised feature selection method based on iterative similarity graph factorization and clustering by modularity},
journal = {Expert Systems with Applications},
volume = {208},
pages = {118092},
year = {2022},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2022.118092},
url = {https://www.sciencedirect.com/science/article/pii/S095741742201288X},
author = {Marcos Oliveira and Sergio Queiroz and Francisco de Carvalho},
keywords = {Feature selection, Unsupervised learning, Low-rank approximation, Graph modularity},
abstract = {Feature selection is an important research area aimed at eliminating unwanted features from high-dimensional datasets. Feature selection methods are categorized according to the availability of labels. Supervised methods usually select features that have high correlations with the data labels, however, this cannot be done by unsupervised methods, since the labels are not available, making the development of them even more challenging. Some unsupervised methods proposed in the literature get around this problem by generating â€œpseudo-labelsâ€ , using clustering techniques, and then making feature selection as in the supervised scenario. There are also methods in which the selection is not guided by a clustering criterion, generally performing some kind of reconstruction of the original dataset in low dimensionality. However, in both approaches a local structure is generated, usually starting from a similarity graph built by using the entire set of features. This may compromise the results of the methods when there are many irrelevant and noisy features, which makes it difficult to reveal patterns or an initial representation of the data. Another drawback of some current methods is the large amount of hyper-parameters, or the computational time required for a single execution, which can render such methods unfeasible for some large datasets. In order to address these problems, it is proposed in this work a new unsupervised feature selection method, called KNMFS, which performs the scoring of the features in low computational time using a three-step procedure: (1) a similarity graph learning step based on non-negative iterative matrix factorization together with a Gaussian filter to mitigate the noise effects caused by irrelevant features; (2) a clustering step from the learned graph using a modularity optimization strategy and (3) a random forest algorithm is applied to compute the scores based on the labels generated by the clustering step. To verify the effectiveness of the proposed method, experiments in real and synthetic datasets were conducted. In both cases, the obtained results showed that the KNMFS method, compared to other state-of-the-art methods, obtained good results according to the metrics of Accuracy, ARI and NMI. Friedmanâ€™s statistical tests were also performed to give stronger evidence to the reported results.}
}

@ARTICLE{Gugliermo23,
  author={Gugliermo, Simona and Schaffernicht, Erik and Koniaris, Christos and Pecora, Federico},
  journal={IEEE Robotics and Automation Letters}, 
  title={Learning Behavior Trees From Planning Experts Using Decision Tree and Logic Factorization}, 
  year={2023},
  volume={8},
  number={6},
  pages={3534-3541},
  doi={10.1109/LRA.2023.3268598}}

@article{aragonCCIS22,
    author="Arag\'on, Roberto G. 
    and Medina, Jes{\'u}s
    and Ram{\'i}rez-Poussa, Elo{\'i}sa",
    title="Study on the Necessity Operator to Factorize Formal Contexts in a Multi-adjoint Framework", bookTitle="Information Processing and Management of Uncertainty in Knowledge-Based Systems.",
    journal="Communications in Computer and Information Science",
    volume = "1601",
    year = "2022",
pages="107--117",
}


@article{KRIDLO22IS,
title = {Selection of appropriate bonds between $L$-fuzzy formal contexts for recommendation tasks},
journal = {Information Sciences},
volume = {606},
pages = {21-37},
year = {2022},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2022.05.047},
url = {https://www.sciencedirect.com/science/article/pii/S0020025522004790},
author = {Ondrej Kr\'idlo and Lubom{\'i}r Antoni and Stanislav Kraj{\v c}i},
keywords = {-fuzzy formal context, Bond, Direct product, Sugeno integral, Factorization},
abstract = {The bond between L-fuzzy formal contexts can be defined as a (Galois) connection between L-fuzzy concept lattices of L-fuzzy formal contexts. The selection of appropriate bond from the set of all bonds between L-fuzzy formal contexts is an important challenge to apply it in recommendation tasks. We propose the general method for the selection of bonds regarding external information given by L-fuzzy relation. The alternative versions of direct products of L-fuzzy formal contexts are formulated and explored since we demonstrate that the extent of direct product is a bond between input L-fuzzy formal contexts. We present examples of the benevolent and rigorous recommendations in several application domains including the real dataset about music genres. Finally, the connections with factorization of L-fuzzy formal contexts and Sugeno integral are thoroughly studied in our paper.}
}

@article{Kumar15MCS,
title = {Knowledge reduction in formal contexts using non-negative matrix factorization},
journal = {Mathematics and Computers in Simulation},
volume = {109},
pages = {46-63},
year = {2015},
issn = {0378-4754},
doi = {https://doi.org/10.1016/j.matcom.2014.08.004},
url = {https://www.sciencedirect.com/science/article/pii/S0378475414001992},
author = {Aswani Kumar Ch. and Sergio M. Dias and Newton J. Vieira},
keywords = {Concept lattice, Formal concept analysis, Knowledge reduction, Non-negative matrix factorization, Singular value decomposition},
abstract = {Formal Concept Analysis (FCA) is a mathematical framework that offers conceptual data analysis and knowledge discovery. One of the main issues of knowledge discovery is knowledge reduction. The objective of this paper is to investigate the knowledge reduction in FCA and propose a method based on Non-Negative Matrix Factorization (NMF) for addressing the issue. Experiments on real world and benchmark datasets offer the evidence for the performance of the proposed method.}
}

@article{TRNECKA201875,
	title = {Data reduction for Boolean matrix factorization algorithms based on formal concept analysis},
	journal = {Knowledge-Based Systems},
	volume = {158},
	pages = {75-80},
	year = {2018},
	issn = {0950-7051},
	doi = {https://doi.org/10.1016/j.knosys.2018.05.035},
	url = {https://www.sciencedirect.com/science/article/pii/S0950705118302594},
	author = {Martin Trnecka and Marketa Trneckova},
	keywords = {Boolean matrix factorization, Formal concept analysis, Data reduction},
	abstract = {Data size reduction is an important step in many data mining techniques. We present a novel approach based on formal concept analysis to data reduction tailored for Boolean matrix factorization methods. A general aim of these methods is to find factors that exactly or approximately explain data. The presented approach is able to significantly reduce the size of data by choosing a representative set of rows, and preserve (with a little loss) factors behind the data, i.e. it only slightly affects a quality of the factors produced by Boolean matrix factorization algorithms.}
}

@article{BELOHLAVEK201836,
	title = {A new algorithm for Boolean matrix factorization which admits overcovering},
	journal = {Discrete Applied Mathematics},
	volume = {249},
	pages = {36--52},
	year = {2018},
	issn = {0166-218X},
	doi = {https://doi.org/10.1016/j.dam.2017.12.044},
	url = {https://www.sciencedirect.com/science/article/pii/S0166218X18303755},
	author = {Radim B{\v e}lohl{\'a}vek and Martin Trnecka},
	keywords = {Boolean matrix factorization, Formal concept analysis, Algorithms},
	abstract = {We present a new algorithm for general Boolean matrix factorization. The algorithm is based on two key ideas. First, it utilizes formal concepts of the factorized matrix as crucial components of constructed factors. Second, it performs steps back during the construction of factors to see if some of the already constructed factors may be improved or even eliminated in view of the subsequently added factors. The second idea is inspired by 8M?an old, previously incompletely described and virtually unknown factorization algorithm, which we analyze and describe in detail. We provide experimental evaluation of the new algorithm and compare it to 8M and two other well-known algorithms. The results demonstrate that our algorithm outperforms these algorithms in terms of quality of the decompositions as well in its robustness with respect to small changes in data.}
}


@article{Medina2021:escim,
  title={Mathematics and Computational Intelligence Synergies for Emerging Challenges},
  author={Jesús Medina and Juan Moreno-García and Eloísa Ramírez-Poussa and László T. Kóczy},
  year={2021},
  journal={International Journal of Computational Intelligence Systems},
  volume={14},
  issue={1},
  pages={818-820},
  issn={1875-6883},
  url={https://doi.org/10.2991/ijcis.d.210121.001},
  doi={https://doi.org/10.2991/ijcis.d.210121.001}
}


@article{cabrera2020, title = "Relational Galois connections between transitive digraphs: Characterization and construction", journal = "Information Sciences", volume = "519", pages = "439 - 450", year = "2020", issn = "0020-0255", doi = "https://doi.org/10.1016/j.ins.2020.01.034", url = "http://www.sciencedirect.com/science/article/pii/S0020025520300347", author = "Inma P. Cabrera and Pablo Cordero and Emilio Muñoz-Velasco and Manuel Ojeda-Aciego and Bernard {De Baets}", abstract = "This paper focuses on a twofold relational generalization of the notion of Galois connection. It is twofold because it is defined between sets endowed with arbitrary transitive relations and, moreover, both components of the connection are relations, not necessarily functions. A characterization theorem of the notion of relational Galois connection is provided and, then, it is proved that a suitable notion of closure can be obtained within this framework. Finally, we state a necessary and sufficient condition that allows to build a relational Galois connection starting from a single transitive digraph and a single binary relation."}

@ARTICLE{TFS:2020-acmr, author={Antoni, Lubomir and Cornejo, M. Eugenia and Medina, Jesús and Ram\'irez-Poussa, Eloísa},
	journal={IEEE Transactions on Fuzzy Systems}, 
	title={Attribute Classification and Reduct Computation in Multi-Adjoint Concept Lattices}, 
	year={2021},
	volume={29},
	number={5},
	pages={1121-1132}, doi={10.1109/TFUZZ.2020.2969114}}

@article{BELOHLAVEK20103,
	title = {Discovery of optimal factors in binary data via a novel method of matrix decomposition},
	journal = {Journal of Computer and System Sciences},
	volume = {76},
	number = {1},
	pages = {3-20},
	year = {2010},
	issn = {0022-0000},
	doi = {https://doi.org/10.1016/j.jcss.2009.05.002},
	url = {https://www.sciencedirect.com/science/article/pii/S0022000009000415},
	author = {Radim B{\v e}lohl{\'a}vek and Vilem Vychodil},
	keywords = {Binary matrix decomposition, Factor analysis, Binary data, Formal concept analysis, Concept lattice},
	abstract = {We present a novel method of decomposition of an n×m binary matrix I into a Boolean product A?B of an n×k binary matrix A and a k×m binary matrix B with k as small as possible. Attempts to solve this problem are known from Boolean factor analysis where I is interpreted as an object?attribute matrix, A and B are interpreted as object?factor and factor?attribute matrices, and the aim is to find a decomposition with a small number k of factors. The method presented here is based on a theorem proved in this paper. It says that optimal decompositions, i.e. those with the least number of factors possible, are those where factors are formal concepts in the sense of formal concept analysis. Finding an optimal decomposition is an NP-hard problem. However, we present an approximation algorithm for finding optimal decompositions which is based on the insight provided by the theorem. The algorithm avoids the need to compute all formal concepts and significantly outperforms a greedy approximation algorithm for a set covering problem to which the problem of matrix decomposition is easily shown to be reducible. We present results of several experiments with various data sets including those from CIA World Factbook and UCI Machine Learning Repository. In addition, we present further geometric insight including description of transformations between the space of attributes and the space of factors.}
}

@article{BELOHLAVEK2019132,
title = "A reduction theorem to compute fixpoints of fuzzy closure operators",
journal = "Fuzzy Sets and Systems",
volume = "369",
pages = "132 - 144",
year = "2019",
issn = "0165-0114",
doi = "https://doi.org/10.1016/j.fss.2018.05.015",
url = "http://www.sciencedirect.com/science/article/pii/S0165011418302914",
author = "Radim  B{\v e}lohl{\'a}vek and Jan Konecny",
keywords = "Formal concept analysis, Fuzzy closure operator, Fixed point, Algorithm",
abstract = "We present a reduction theorem which relates sets of fixpoints of fuzzy closure operators to sets of fixpoints of ordinary closure operators. As a result we obtain a method to compute sets of fixpoints of fuzzy closure operators by algorithms available for ordinary operators. We also provide explicit descriptions of selected algorithms which result from the presented approach."}
@InProceedings{aragonIJCRS20,
author="Arag{\'o}n, Roberto G.
and Medina, Jes{\'u}s
and Ram{\'i}rez-Poussa, Elo{\'i}sa",
editor="Bello, Rafael
and Miao, Duoqian
and Falcon, Rafael
and Nakata, Michinori
and Rosete, Alejandro
and Ciucci, Davide",
title="On the Hierarchy of Equivalence Classes Provided by Local Congruences",
booktitle="Rough Sets",
year="2020",
publisher="Springer International Publishing",
address="Cham",
pages="298--307",
abstract="In this work, we consider a special kind of equivalence relations, which are called local congruences. Specifically, local congruences are equivalence relations defined on lattices, whose equivalence classes are convex sublattices of the original lattices. In the present paper, we introduce an initial study about how the set of equivalence classes provided by a local congruence can be ordered.",
isbn="978-3-030-52705-1"}



@InProceedings{aragon:ipmu:2020,
author="Arag{\'o}n, Roberto G.
and Medina, Jes{\'u}s
and Ram{\'i}rez-Poussa, Elo{\'i}sa",
editor="Lesot, Marie-Jeanne
and Vieira, Susana
and Reformat, Marek Z.
and Carvalho, Jo{\~a}o Paulo
and Wilbik, Anna
and Bouchon-Meunier, Bernadette
and Yager, Ronald R.",
title="Impact of Local Congruences in Attribute Reduction",
booktitle="Information Processing and Management of Uncertainty in Knowledge-Based Systems",
year="2020",
publisher="Springer International Publishing",
address="Cham",
volume = "1239",
pages="748--758",
abstract="Local congruences are equivalence relations whose equivalence classes are convex sublattices of the original lattice. In this paper, we present a study that relates local congruences to attribute reduction in FCA. Specifically, we will analyze the impact in the context of the use of local congruences, when they are used for complementing an attribute reduction.",
isbn="978-3-030-50153-2"}



%:%%%%%%%%%%%%%%%%%%.  GENERALIZED QUANTIFIERS


@article{cornejo2022113772,
title = {Generalized quantifiers in formal concept analysis},
journal = {Journal of Computational and Applied Mathematics},
volume = {404},
pages = {113772},
year = {2022},
issn = {0377-0427},
doi = {https://doi.org/10.1016/j.cam.2021.113772},
url = {https://www.sciencedirect.com/science/article/pii/S0377042721003940},
author = {M. Eugenia Cornejo and Juan Carlos D\'iaz-Moreno and Jes\'us Medina},
keywords = {Concept lattice, Fuzzy set, Generalized quantifier, Adjoint triple},
abstract = {Usually, datasets contain imprecise data (noise), which can produce unsuspected results on the considered mappings. For instance, this can happen with the infimum and supremum operators, since both operators are straightforwardly associated with the universal and existencial quantifiers, respectively. An interesting possibility, of decreasing the impact of this possible noise in the final results, is the consideration of generalized quantifiers. This paper introduces four kinds of generalized quantifiers based on adjoint triples, which generalize the current approaches to a more flexible framework. Different properties and characterizations are studied and they have been applied to formal concept analysis, presenting the conjunctive and implicative concept-forming operators in this outstanding theory.}
}


@CONFERENCE{Cornejo2020273,
author={Cornejo, M.E. and D\'iaz-Moreno, J.C. and L\'opez-Rodr\'iguez, J. and Medina, J.},
title={Quantified concept-forming operators},
journal={CEUR Workshop Proceedings},
year={2020},
volume={2668},
pages={273-280},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091447569&partnerID=40&md5=e82a9a3039581e857596b77b6b7ce9da},
document_type={Conference Paper},
source={Scopus},
}



@InProceedings{dvorak2020,
author="Dvo{\v{r}}{\'a}k, Anton{\'i}n
and Hol{\v{c}}apek, Michal",
editor="Lesot, Marie-Jeanne
and Vieira, Susana
and Reformat, Marek Z.
and Carvalho, Jo{\~a}o Paulo
and Wilbik, Anna
and Bouchon-Meunier, Bernadette
and Yager, Ronald R.",
title="On Semantic Properties of Fuzzy Quantifiers over Fuzzy Universes: Restriction and Living on",
booktitle="Information Processing and Management of Uncertainty in Knowledge-Based Systems",
year="2020",
publisher="Springer International Publishing",
address="Cham",
pages="173--186",
abstract="The article investigates important semantic properties of fuzzy quantifiers, namely restriction and living on a (fuzzy) set. These properties are introduced in the novel frame of fuzzy quantifiers over fuzzy universes.",
isbn="978-3-030-50153-2"
}



@article{stepnicka2020,
title = "The concept of unavoidable features in fuzzy relational compositions",
journal = "Knowledge-Based Systems",
volume = "196",
pages = "105785",
year = "2020",
issn = "0950-7051",
doi = "https://doi.org/10.1016/j.knosys.2020.105785",
url = "http://www.sciencedirect.com/science/article/pii/S0950705120301805",
  author    = {Martin {\v S}t{\v e}pni{\v c}ka and Nhung Cao and
               Michal Burda and Ale{\v s} Doln\'y and Stanislav O{\v z}ana},
keywords = "Fuzzy relational compositions, Unavoidable features, Excluding features, Bandler-Kohout products, Fuzzy quantifiers, Dragonflies, Amphibians",
abstract = "Fuzzy relational calculus, and especially, the compositions of fuzzy relations, had a great impact on many theoretical as well as practical areas of fuzzy modeling and it attracted numerous researchers. Recently, the compositions had been extended in distinct directions including the incorporation of excluding features or the direct use of generalized quantifiers instead of the standard ones. This article provides an investigation of an extension that is mathematically similarly constructed to the concept of excluding features although from the semantic point of view it is opposite. In particular, we introduce the concept of unavoidable features. Formally, the concept is again constructed as conjunctive fusion of an existing fuzzy relational composition with another composition, namely the Bandler-Kohout superproduct, employing a newly defined fuzzy relation of unavoidable features for particular classes. We provide an investigation of mathematical properties of the new concept and we demonstrate the appropriateness of the proposed concept on the classification task. This is provided with help of a real biological classification problems running on a data-sets of dragonflies and amphibians. A significant improvement of the results is emphasizing how strong influence may be provided with simple ideas and concepts fused appropriately together to a more complicated yet still explainable concept."
}


@article {bosc96,
author = {Bosc, P. and Lietard, L. and Pivert, O.},
title = {Flexible Database Querying and the Division of Fuzzy Relations},
journal = {Scientia Iranica},
volume = {2},
number = {4},
pages = {-},
year  = {1996},
publisher = {Sharif University of Technology},
issn = {1026-3098}, 
eissn = {2345-3605}, 
doi = {},
abstract = {},
keywords = {},
url = {http://scientiairanica.sharif.edu/article_3062.html},
eprint = {http://scientiairanica.sharif.edu/article_3062_fe01419586ebd7002532bf92a1469794.pdf}
}


@article{delgado00,
title = "Fuzzy cardinality based evaluation of quantified sentences",
journal = "International Journal of Approximate Reasoning",
volume = "23",
number = "1",
pages = "23 - 66",
year = "2000",
issn = "0888-613X",
doi = "https://doi.org/10.1016/S0888-613X(99)00031-6",
url = "http://www.sciencedirect.com/science/article/pii/S0888613X99000316",
author = "Miguel Delgado and Daniel S\'anchez and Maria Amparo Vila",
abstract = "Quantified statements are used in the resolution of a great variety of problems. Several methods have been proposed to evaluate statements of types I and II. The objective of this paper is to study these methods, by comparing and generalizing them. In order to do so, we propose a set of properties that must be fulfilled by any method of evaluation of quantified statements, we discuss some existing methods from this point of view and we describe a general approach for the evaluation of quantified statements based on the fuzzy cardinality and fuzzy relative cardinality of fuzzy sets. In addition, we discuss some concrete methods derived from the mentioned approach. These new methods fulfill all the properties proposed and, in some cases, they provide an interpretation or generalization of existing methods."
}

@article{dvorak09,
title = "L-fuzzy quantifiers of type $\langle 1\rangle$ determined by fuzzy measures",
journal = "Fuzzy Sets and Systems",
volume = "160",
number = "23",
pages = "3425 - 3452",
year = "2009",
issn = "0165-0114",
doi = "https://doi.org/10.1016/j.fss.2009.05.010",
url = "http://www.sciencedirect.com/science/article/pii/S0165011409002541",
author = "Anton\'in Dvo{\v r}\'ak and Michal Hol{\v c}apek",
keywords = "Fuzzy measure, Fuzzy integral, Fuzzy logic, Monadic -fuzzy quantifier",
abstract = "The aim of this paper is, first, to introduce two new types of fuzzy integrals, namely, ?-fuzzy integral and ?-fuzzy integral. The first integral is based on a fuzzy measure of L-fuzzy sets and the second one on a complementary fuzzy measure of L-fuzzy sets, where L is a complete residuated lattice. Some of their properties and a relation to the fuzzy (Sugeno) integral are investigated. Second, using these integrals, two classes of monadic L-fuzzy quantifiers of type ?1? are defined. These L-fuzzy quantifiers can be used for modeling the semantics of natural language quantifiers like ?all?, ?some?, ?many?, ?none?, ?at most half?, etc. Several semantic properties of these L-fuzzy quantifiers are studied."
}
@inproceedings{cao19,
  author    = {Nhung Cao and
               Martin Stepnicka and
               Michal Burda},
  title     = {Fuzzy Quantifiers and Compositions of Partial Fuzzy Relations Employing
               Dragonfly Algebras},
  booktitle = {2019 {IEEE} International Conference on Fuzzy Systems, {FUZZ-IEEE}
               2019, New Orleans, LA, USA, June 23-26, 2019},
  pages     = {1--6},
  publisher = {{IEEE}},
  year      = {2019},
  url       = {https://doi.org/10.1109/FUZZ-IEEE.2019.8858832},
  doi       = {10.1109/FUZZ-IEEE.2019.8858832},
  timestamp = {Wed, 16 Oct 2019 14:14:52 +0200},
  biburl    = {https://dblp.org/rec/conf/fuzzIEEE/CaoSB19.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{cao18,
title = "Extensions of fuzzy relational compositions based on generalized quantifiers",
journal = "Fuzzy Sets and Systems",
volume = "339",
pages = "73 - 98",
year = "2018",
issn = "0165-0114",
doi = "https://doi.org/10.1016/j.fss.2017.04.009",
url = "http://www.sciencedirect.com/science/article/pii/S0165011417301756",
author = "Nhung Cao and Michal Hol{\v c}apek and Martin {\v S}t{\v e}pni{\v c}ka",
keywords = "Fuzzy relational compositions, Fuzzy relational products, Bandler?Kohout products, Fuzzy measures, Generalized (fuzzy) quantifiers, Sup-T composition, Inf-R composition, Medical diagnosis",
abstract = "The aim of this paper is to extend the fuzzy relational compositions motivated by their applications to medical diagnosis problem by Bandler and Kohout. These compositions employ two quantifiers, the universal quantifier and the existential quantifier. As there exists a big gap between these two quantifiers, that may be appropriately filled in by intermediate generalized quantifiers, we take this as a motivation for our study. In particular, we introduce the concept of fuzzy relational compositions based on generalized quantifiers. Furthermore, we show that the properties that are typically valid for standard fuzzy relational compositions are also valid for the compositions based on generalized quantifiers, yet sometimes in a weaken form. Apart from fuzzy relational compositions, the use of generalized quantifiers is also applied to images and preimages of fuzzy sets under fuzzy relations."
}

@InProceedings{stepnicka14,
author="{\v{S}}t{\v{e}}pni{\v{c}}ka, Martin
and Hol{\v{c}}apek, Michal",
editor="Laurent, Anne
and Strauss, Olivier
and Bouchon-Meunier, Bernadette
and Yager, Ronald R.",
title="Fuzzy Relational Compositions Based on Generalized Quantifiers",
booktitle="Information Processing and Management of Uncertainty in Knowledge-Based Systems",
year="2014",
publisher="Springer International Publishing",
address="Cham",
pages="224--233",
abstract="Fuzzy relational compositions have been extensively studied by many authors. Especially, we would like to highlight initial studies of the fuzzy relational compositions motivated by their applications to medical diagnosis by Willis¬?Bandler and Ladislav¬?Kohout. We revisit these types of compositions and introduce new definitions that directly employ generalized quantifiers. The motivation for this step is twofold: first, the application needs for filling a huge gap between the classical existential and universal quantifiers and second, the already existing successful implementation of generalized quantifiers in so called divisions of fuzzy relations, that constitute a database application counterpart of the theory of fuzzy relational compositions. Recall that the latter topic is studied within fuzzy relational databases and flexible querying systems for more than twenty years. This paper is an introductory study that should demonstrate a unifying theoretical framework and introduce that the properties typically valid for fuzzy relational compositions are valid also for the generalized ones, yet sometimes in a weaken form.",
isbn="978-3-319-08855-6"
}


%:%%%%%%%%%%%%%%%%%%.  CONGRUENCES

@Inbook{aragonclasses22,
author="Arag{\'o}n, Roberto G.
and Medina, Jes{\'u}s
and Ram{\'i}rez-Poussa, Elo{\'i}sa",
editor="Harmati, Istv{\'a}n {\'A}.
and K{\'o}czy, L{\'a}szl{\'o} T.
and Medina, Jes{\'u}s
and Ram{\'i}rez-Poussa, Elo{\'i}sa",
title="Characterization of the Infimum of Classes Induced by an Attribute Reduction in FCA",
bookTitle="Computational Intelligence and Mathematics for Tackling Complex Problems 3",
year="2022",
publisher="Springer International Publishing",
address="Cham",
pages="73--79",
abstract="Attribute reduction is a topic of interest in data analysis. In particular, in formal concept analysis attribute reductions are associated with equivalence relations defined on concept lattices. In this paper, we study the equivalence relations induced by attribute reductions with the goal of characterizing when the equivalence classes are not convex sublattices of the original concept lattice.",
isbn="978-3-030-74970-5",
doi="10.1007/978-3-030-74970-5_9",
url="https://doi.org/10.1007/978-3-030-74970-5_9"
}

@InCollection{aragonSCI2022,
	author= {Arag{\'o}n, Roberto G.
	and Medina, Jes{\'u}s
	and Ram{\'i}rez-Poussa, Elo{\'i}sa},
	editor={Cornejo, Mar{\'i}a Eugenia
	and K{\'o}czy, L{\'a}szl{\'o} T.
	and Medina-Moreno, Jes{\'u}s
	and Moreno-Garc{\'i}a, Juan},
	title={A weakened notion of congruence to reduce concept lattices},
	bookTitle={Computational Intelligence and Mathematics for Tackling Complex Problems 2},
	year={2022},
	publisher={Springer International Publishing},
	address={Cham},
	pages={139--145},
	isbn={978-3-030-88817-6},
	doi={10.1007/978-3-030-88817-6_16},
	url={https://doi.org/10.1007/978-3-030-88817-6_16}
}




@article{aragonMath21,
	AUTHOR = {Arag\'on, Roberto G. and Medina, Jesús and Ram\'irez-Poussa, Eloísa},
	TITLE = {Identifying Non-Sublattice Equivalence Classes Induced by an Attribute Reduction in FCA},
	JOURNAL = {Mathematics},
	VOLUME = {9},
	YEAR = {2021},
	NUMBER = {5},
	ARTICLE-NUMBER = {565},
	URL = {https://www.mdpi.com/2227-7390/9/5/565},
	ISSN = {2227-7390},
	ABSTRACT = {The detection of redundant or irrelevant variables (attributes) in datasets becomes essential in different frameworks, such as in Formal Concept Analysis (FCA). However, removing such variables can have some impact on the concept lattice, which is closely related to the algebraic structure of the obtained quotient set and their classes. This paper studies the algebraic structure of the induced equivalence classes and characterizes those classes that are convex sublattices of the original concept lattice. Particular attention is given to the reductions removing FCA?s unnecessary attributes. The obtained results will be useful to other complementary reduction techniques, such as the recently introduced procedure based on local congruences.},
	DOI = {10.3390/math9050565}
}



@article{gely2018,
author={Gély, A. and Couceiro, M. and Napoli, A.},
title={Steps towards achieving distributivity in formal concept analysis},
journal={CEUR Workshop Proceedings},
year={2018},
volume={2123},
pages={105-116},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049689043&partnerID=40&md5=c16bccc0d4489699dfe27336d70b3656},
document_type={Conference Paper},
source={Scopus},
}

@InProceedings{kuznetsov07,
author="Kuznetsov, Sergei
and Obiedkov, Sergei
and Roth, Camille",
editor="Priss, Uta
and Polovina, Simon
and Hill, Richard",
title="Reducing the Representation Complexity of Lattice-Based Taxonomies",
booktitle="Conceptual Structures: Knowledge Architectures for Smart Applications",
year="2007",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="241--254",
abstract="Representing concept lattices constructed from large contexts often results in heavy, complex diagrams that can be impractical to handle and, eventually, to make sense of. In this respect, many concepts could allegedly be dropped from the lattice without impairing its relevance towards a taxonomy description task at a certain level of detail. We propose a method where the notion of stability is introduced to select potentially more pertinent concepts. We present some theoretical properties of stability and discuss several use cases where taxonomy building is an issue.",
isbn="978-3-540-73681-3"
}

@article{aragonJCAM21,
title = {Impact of local congruences in variable selection from datasets},
journal = {Journal of Computational and Applied Mathematics},
volume = {404(113416)},
year = {2022},
issn = {0377-0427},
doi = {https://doi.org/10.1016/j.cam.2021.113416},
url = {https://www.sciencedirect.com/science/article/pii/S0377042721000352},
author = {Roberto G. Arag\'on and Jesús Medina and Eloísa Ram\'irez-Poussa},
keywords = {Formal concept analysis, Size concept lattice reduction, Congruence relation},
abstract = {Formal concept analysis (FCA) is a useful mathematical tool for obtaining information from relational datasets. One of the most interesting research goals in FCA is the selection of the most representative variables of the dataset, which is called attribute reduction. Recently, the attribute reduction mechanism has been complemented with the use of local congruences in order to obtain robust clusters of concepts, which form convex sublattices of the original concept lattice. Since the application of such local congruences modifies the quotient set associated with the attribute reduction, it is fundamental to know how the original context (attributes, objects and relationship) has been modified in order to understand the impact of the application of the local congruence in the attribute reduction.}
}


@article{aragon2020,
title = {Reducing concept lattices by means of a weaker notion of congruence},
journal = {Fuzzy Sets and Systems},
volume = {418},
pages = {153-169},
year = {2021},
issn = {0165-0114},
doi = {https://doi.org/10.1016/j.fss.2020.09.013},
url = {https://www.sciencedirect.com/science/article/pii/S0165011420303754},
author = {Roberto G. Arag\'on and Jesús Medina and Eloísa Ram\'irez-Poussa},
keywords = {Formal concept analysis, Size concept lattice reduction, Attribute reduction, Congruence relation, Fuzzy sets},
abstract = {Attribute and size reductions are key issues in formal concept analysis. In this paper, we consider a special kind of equivalence relation to reduce concept lattices, which will be called local congruence. This equivalence relation is based on the notion of congruence on lattices, with the goal of losing as less information as possible and being suitable for the reduction of concept lattices. We analyze how the equivalence classes obtained from a local congruence can be ordered. Moreover, different properties related to the algebraic structure of the whole set of local congruences are also presented. Finally, a procedure to reduce concept lattices by the new weaker notion of congruence is introduced. This procedure can be applied to the classical and fuzzy formal concept analysis frameworks.}
}


@Article{Vojvodic1988,
author="Vojvodi{\'{c}}, Gradimir
and {\v{S}}e{\v{s}}elja, Branimir",
title="On the lattice of weak congruence relations",
journal="algebra universalis",
year="1988",
day="01",
volume="25",
number="1",
pages="121--130",
abstract="We consider the setCw(A) of weak congruences on an algebraA, i.e. of all symmetric and transitive subalgebras ofA {\texttimes}A. (Some other generalizations of compatible relations were given in [2] and [6]).Cw(A) coincides with the set of all congruences on all subalgebras ofA.",
issn="1420-8911",
doi="10.1007/BF01229965",
url="https://doi.org/10.1007/BF01229965"
}

@Article{Walendziak2002,
author="Walendziak, Andrzej",
title="Weak congruences of an algebra with the {CEP} and the {WCIP}",
journal="Czechoslovak Mathematical Journal",
year="2002",
day="01",
volume="52",
number="1",
pages="117--127",
abstract="Here we consider the weak congruence lattice {\$}{\$}C{\_}W (A){\$}{\$}of an algebra {\$}{\$}A{\$}{\$}with the congruence extension property (the CEP for short) and the weak congruence intersection property (briefly the WCIP). In the first section we give necessary and sufficient conditions for the semimodularity of that lattice. In the second part we characterize algebras whose weak congruences form complemented lattices.",
issn="1572-9141",
doi="10.1023/A:1021727522345",
url="https://doi.org/10.1023/A:1021727522345"
}

@article{Tepavcevic2008,
title = "A note on atomistic weak congruence lattices",
journal = "Discrete Mathematics",
volume = "308",
number = "10",
pages = "2054--2057",
year = "2008",
issn = "0012-365X",
doi = "https://doi.org/10.1016/j.disc.2007.04.046",
url = "http://www.sciencedirect.com/science/article/pii/S0012365X07002804",
author = "Branimir \v{S}e\v{s}elja and Andreja Tepav\v{c}evi\'c",
keywords = "Codistributive element, Atomistic lattice, Weak congruences, CEP, CIP",
abstract = "It is proved that a codistributive element in an atomistic algebraic lattice has a complement, implying that kernels of the related homomorphisms coincide. Some applications to weak congruence lattices of algebras are presented. In particular, necessary and sufficient conditions under which the weak congruence lattice of an algebra is atomistic are given."
}

@article{Tepavcevic2015,
title = "Representation of lattices by fuzzy weak congruence relations",
journal = "Fuzzy Sets and Systems",
volume = "260",
pages = "97--109",
year = "2015",
issn = "0165-0114",
doi = "https://doi.org/10.1016/j.fss.2014.05.009",
url = "http://www.sciencedirect.com/science/article/pii/S0165011414002395",
author = "Branimir \v{S}e\v{s}elja and Vanja Stepanovi\'c and Andreja Tepav\v{c}evi\'c",
keywords = "Fuzzy relations, Algebra, Fuzzy algebra, Fuzzy weak congruence, Complete lattice",
abstract = "Fuzzy (lattice valued) weak congruences of abstract algebras are investigated. For an algebra, the family of all such fuzzy relations is a complete lattice; its structure and cut properties are investigated and fully described. These fuzzy weak congruences are applied in representation of complete and algebraic lattices. A wider class of lattices can be represented in such a fuzzy framework, than in classical algebra. We prove that there is a straightforward representation of any complete lattice, using it as a co-domain. In a more general case, it is proved that several subdirect powers of lattices are also representable by fuzzy weak congruences."
}

@Book{GratzerUA,
	author = {George Gr{\"a}tzer},
	title = {Universal Algebra},
	publisher = {Springer-Verlag New York},
	year = {2008},
	edition = {2nd},
	}
@Book{GratzerGLT,
	author = {George Gr{\"a}tzer},
	title = {General Lattice Theory},
	publisher = {Birkh{\"a}user Basel},
	year = {2007},
	edition = {2nd},
}



@Article{LiWang2017,
	author="Li, Jun-Yu
	and Wang, Xia
	and Wu, Wei-Zhi
	and Xu, You-Hong",
	title="Attribute reduction in inconsistent formal decision contexts based on congruence relations",
	journal="International Journal of Machine Learning and Cybernetics",
	year="2017",
	volume="8",
	number="1",
	pages="81--94",
	abstract="In this paper, notions and methods of attribute reduction are investigated for an inconsistent formal decision context. Based on congruence relations defined on the object power set, we first introduce notions of distribution attribute reduct and maximum distribution attribute reduct for an inconsistent formal decision context, and discuss their relations in detail. We then define discernibility matrices and discernibility functions associated with the proposed attribute reducts, from which we can calculate all attribute reducts. Finally, we compare the proposed consistent sets with four types of consistent sets in previously published papers. The results show that a distribution consistent set belongs to any of those four types of consistent sets. Therefore, it has all the properties of those four types of consistent sets.",
	issn="1868-808X",
	doi="10.1007/s13042-016-0586-z",
	url="https://doi.org/10.1007/s13042-016-0586-z"
}


@INPROCEEDINGS{Viaud2015, 
author={J. {Viaud} and K. {Bertet} and C. {Demko} and R. {Missaoui}}, 
booktitle={2015 7th International Joint Conference on Knowledge Discovery, Knowledge Engineering and Knowledge Management (IC3K)}, 
title={The reverse doubling construction}, 
year={2015}, 
volume={}, 
number={}, 
pages={350-357}, 
keywords={Lattices;Context;Formal concept analysis;Upper bound;Knowledge discovery;Databases;Information retrieval;Concept Lattice;Congruence Relation;Factor Lattice;Arrow Relation;Arrow Closed Subcontext;Compatible Subcontext;Doubling Convex}, 
doi={}, 
ISSN={null}}
@inproceedings{viaud145,
  TITLE = {{Subdirect decomposition of contexts into subdirectly irreducible factors}},
  AUTHOR = {Viaud, Jean-Fran{\c c}ois and Bertet, Karell and Demko, Christophe and Missaoui, Rokia},
  URL = {https://hal.archives-ouvertes.fr/hal-01282145},
  BOOKTITLE = {{International Conference on Formal Concept Analysis ICFCA2015}},
  ADDRESS = {Nerja, Spain},
  YEAR = {2015},
  KEYWORDS = {arrow closed subcontext ; compatible subcontext ; concept lattice ; congruence relation ; factor lattice ; arrow relation},
  PDF = {https://hal.archives-ouvertes.fr/hal-01282145/file/sdd.pdf},
  HAL_ID = {hal-01282145},
  HAL_VERSION = {v1},
}

@article{VIAUD,
	title = "Using congruence relations to extract knowledge from concept lattices",
	journal = "Discrete Applied Mathematics",
	volume = "249",
	pages = "135--150",
	year = "2018",
	issn = "0166-218X",
	doi = "https://doi.org/10.1016/j.dam.2016.11.021",
	url = "http://www.sciencedirect.com/science/article/pii/S0166218X16305741",
	author = "Jean-Fran\c{c}ois Viaud and Karell Bertet and Rokia Missaoui and Christophe Demko",
}


%:%%%%%%%%% enterprise architecture ANNETTE

 
@ARTICLE{Lap12, 
author={J. Lapalme}, 
journal={IT Professional}, 
title={Three Schools of Thought on Enterprise Architecture}, 
year={2012}, 
volume={14}, 
number={6}, 
pages={37-43}, 
abstract={Three schools of thought on enterprise architecture exist, each with its own belief system (definitions, concerns, assumptions, and limitations). A novel taxonomy of these schools creates a starting point for resolving terminological challenges to help establish enterprise architecture as a discipline.}, 
keywords={educational institutions;schools;enterprise architecture;belief system;terminological challenges;Network architecture;Enterprise resource planning;Computer architecture;Technological innovation;Strategic planning;Taxonomy;enterprise architecture;systems thinking;organizational learning;enterprise engineering}, 
doi={10.1109/MITP.2011.109}, 
ISSN={1520-9202}, 
month={Nov},}


@ARTICLE{MAL17, 
author={A. Malleuve and D. Alfonso and J. Lavandero}, 
journal={Dyna Colombia}, 
title={Study of elements behavior for integration management system with enterprise architecture approach}, 
year={2017}, 
volume={84}, 
number={203}, 
pages={349--355}, 
abstract ={El título en español es: Estudio del comportamiento de variables para la integración del sistema de dirección de la empresa con enfoque de arquitectura empresarial},
}


@ARTICLE{MAL15, 
author={A. Malleuve and D. Alfonso and Mavis Lis Stuart-Cárdenas}, 
journal={Revista Cubana de Ingeniería}, 
title={Approach to assess enterprise architecture maturity level}, 
year={2015}, 
volume={VI}, 
number={3}, 
pages={33--42}, 
abstract ={El título en inglés sería: Approach to assess enterprise architecture maturity level},
}

@Article{Simon2014,
author="Simon, Daniel
and Fischbach, Kai
and Schoder, Detlef",
title="Enterprise architecture management and its role in corporate strategic management",
journal="Information Systems and e-Business Management",
year="2014",
month="Feb",
day="01",
volume="12",
number="1",
pages="5--42",
abstract="A considerable number of organizations continually face difficulties bringing strategy to execution, and suffer from a lack of structure and transparency in corporate strategic management. Yet, enterprise architecture as a fundamental exercise to achieve a structured description of the enterprise and its relationships appears far from being adopted in the strategic management arena. To move the adoption process along, this paper develops a comprehensive business architecture framework that assimilates and extends prior research and applies the framework to selected scenarios in corporate strategic management. This paper also presents the approach in practice, based on a qualitative appraisal of interviews with strategic directors across different industries. With its integrated conceptual guideline for using enterprise architecture to facilitate corporate strategic management and the insights gained from the interviews, this paper not only delves more deeply into the research but also offers advice for both researchers and practitioners.",
issn="1617-9854",
doi="10.1007/s10257-013-0213-4",
url="https://doi.org/10.1007/s10257-013-0213-4"
}

@Article{MallUn,
author="A. Malleuve",
title="Integration of Management System with Enterprise Architecture approach in a communications enterprise",
journal="Submitted",
year="2018",
volume="",
number="",
pages="",
}





@article{zachman1987framework,
  title={A framework for information systems architecture},
  author={Zachman, John A},
  journal={IBM systems journal},
  volume={26},
  number={3},
  pages={276--292},
  year={1987},
  publisher={IBM}
}

@article{urbaczewski2006comparison,
  title={A comparison of enterprise architecture frameworks},
  author={Urbaczewski, Lise and Mrdalj, Stevan},
  journal={Issues in Information Systems},
  volume={7},
  number={2},
  pages={18--23},
  year={2006}
}
@book{schekkerman2004survive,
  title={How to survive in the jungle of enterprise architecture frameworks: Creating or choosing an enterprise architecture framework},
  author={Schekkerman, Jaap},
  year={2004},
  publisher={Trafford Publishing}
}

@article{hinkelmann2016new,
  title={A new paradigm for the continuous alignment of business and IT: Combining enterprise architecture modelling and enterprise ontology},
  author={Hinkelmann, Knut and Gerber, Aurona and Karagiannis, Dimitris and Thoenssen, Barbara and Van der Merwe, Alta and Woitsch, Robert},
  journal={Computers in Industry},
  volume={79},
  pages={77--86},
  year={2016},
  publisher={Elsevier}
}

@book{lankhorst2009enterprise,
  title={Enterprise architecture at work: Modelling, communication and analysis},
  author={Lankhorst, Marc},
  year={2009},
  publisher={Springer}
}

@article{berrada2013business,
  title={Business Modeling of Enterprise Architecture Based on Multi-Agent System},
  author={Berrada, Mohammed and Bounabat, Bouchaib},
  journal={International Journal of e-Education, e-Business, e-Management and e-Learning},
  volume={3},
  number={6},
  pages={472},
  year={2013},
  publisher={IACSIT Press}
}

@article{vernadat2007interoperable,
  title={Interoperable enterprise systems: Principles, concepts, and methods},
  author={Vernadat, Fran{\c{c}}ois B},
  journal={Annual reviews in Control},
  volume={31},
  number={1},
  pages={137--145},
  year={2007},
  publisher={Elsevier}
}

@inproceedings{braun2007integration,
  title={Integration of IT service management into enterprise architecture},
  author={Braun, Christian and Winter, Robert},
  booktitle={Proceedings of the 2007 ACM symposium on Applied computing},
  pages={1215--1219},
  year={2007},
  organization={ACM}
}

@inproceedings{winter2006essential,
  title={Essential layers, artifacts, and dependencies of enterprise architecture},
  author={Winter, Robert and Fischer, Ronny},
  booktitle={Enterprise Distributed Object Computing Conference Workshops, 2006. EDOCW'06. 10th IEEE International},
  pages={30--30},
  year={2006},
  organization={IEEE}
}

@inproceedings{johnson2004using,
  title={Using enterprise architecture for cio decision-making: On the importance of theory},
  author={Johnson, Pontus and Ekstedt, Mathias and Silva, Enrique and Plazaola, Leonel},
  booktitle={Second Annual Conference on Systems Engineering Research},
  year={2004}
}






%:%%%%%%%%% SOCIAL NETWORKS


@article{sci:kristina19,
author="Medina, Jes{\'u}s
and Pakhomova, Kristina
and Ram{\'i}rez-Poussa, Elo{\'i}sa",
title="Recommendation Solution for a Locate-Based Social Network via Formal", bookTitle="Trends in Mathematics and Computational Intelligence",
journal="Studies in Computational Intelligence",
volume = "796",
year = "2019",
pages="131--138",
abstract="ThisMedina, Jes{\'u}s paperPakhomova, Kristina introducesRam{\'i}rez-Poussa, Elo{\'i}sa a procedure to apply Formal Concept Analysis (FCA) to a database obtained from a locate-base social network. In this way, we can know the interest of a target user and make recommendations according to these interests.",
isbn="978-3-030-00485-9",
doi="10.1007/978-3-030-00485-9_15",
url="https://doi.org/10.1007/978-3-030-00485-9_15"
}




@article{bejar16,
author = {J. Béjar and S. Álvarez and D. García and I. Gámez and L. Oliva and A. Tejeda and J. Vázquez-Salceda},
title = {Discovery of spatio-temporal patterns from location-based social networks},
journal = {Journal of Experimental \& Theoretical Artificial Intelligence},
volume = {28},
number = {1-2},
pages = {313-329},
year = {2016},
doi = {10.1080/0952813X.2015.1024492},
URL = {http://dx.doi.org/10.1080/0952813X.2015.1024492},
eprint = {http://dx.doi.org/10.1080/0952813X.2015.1024492},
abstract = { Location-based social networks (LBSNs) such as Twitter or Instagram are a good source for user spatio-temporal behaviour. These networks collect data from users in such a way that they can be seen as a set of collective and distributed sensors of a geographical area. A low rate sampling of user's location information can be obtained during large intervals of time that can be used to discover complex patterns, including mobility profiles, points of interest or unusual events. These patterns can be used as the elements of a knowledge base for different applications in different domains such as mobility route planning, touristic recommendation systems or city planning. The aim of this paper is twofold, first to analyse the frequent spatio-temporal patterns that users share when living and visiting a city. This behaviour is studied by means of frequent itemsets algorithms in order to establish some associations among visits that can be interpreted as interesting routes or spatio-temporal connections. Second, to analyse how the spatio-temporal behaviour of a large number of users can be segmented in different profiles. These behavioural profiles are obtained by means of clustering algorithms that show the different patterns of behaviour of visitors and citizens. The data analysed were obtained from the public data feeds of Twitter and Instagram within an area surrounding the cities of Barcelona and Milan for a period of several months. The analysis of these data shows that these kinds of algorithms can be successfully applied to data from any city (or general area) to discover useful patterns that can be interpreted on terms of singular places and areas and their temporal relationships. },
}

@inproceedings{Zhu2015,
 author = {Zhu, Wen-Yuan and Peng, Wen-Chih and Chen, Ling-Jyh and Zheng, Kai and Zhou, Xiaofang},
 title = {Modeling User Mobility for Location Promotion in Location-based Social Networks},
 booktitle = {Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
 series = {KDD '15},
 year = {2015},
 isbn = {978-1-4503-3664-2},
 location = {Sydney, NSW, Australia},
 pages = {1573--1582},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2783258.2783331},
 doi = {10.1145/2783258.2783331},
 acmid = {2783331},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {check-in behavior, influence maximization, location-based social network, propagation probability},
} 


@Inbook{Wang2016,
author="Wang, Jianmin
and Tan, Ruhuo
and Zhang, Ri-Peng
and You, Fang",
editor="Meiselwitz, Gabriele",
title="A Recommender System Research Based on Location-Based Social Networks",
bookTitle="Social Computing and Social Media: 8th International Conference, SCSM 2016, Held as Part of HCI International 2016, Toronto, ON, Canada, July 17--22, 2016. Proceedings",
year="2016",
publisher="Springer International Publishing",
address="Cham",
pages="81--90",
abstract="Nowadays, with the rapid development of Location-Based Social Networks, information presents a trend of explosive growth. In order to locate the valuable information in tremendous amounts of location-based service data and prosperi O2O business through LBS, recommender system based on location-based service was presented. This paper takes Sina Microblog LBS data as research object. By analyzing the features of the crawled data and the existing problems of current LBS recommender systems, we present Region-density-based Clustering (RC) recommendation algorithm. For optimization, this paper also presents another algorithm called Distance-and-Category-based Clustering (DCC). This algorithm is mainly about clustering spots base on their distance similarity and category similarity. If two spots are nearby and both category attributes are similar, they will be more likely to gathered into a cluster. Finally, this paper also proposed the visualization method of the LBSNs recommender system.",
isbn="978-3-319-39910-2",
doi="10.1007/978-3-319-39910-2_8",
url="https://doi.org/10.1007/978-3-319-39910-2_8"
}




@article{li2017:SN,
title = "The effectiveness of word of mouth in offline and online social networks",
journal = "Expert Systems with Applications",
volume = "88",
number = "",
pages = "338 - 351",
year = "2017",
note= "",
issn = "0957-4174",
doi = "http://dx.doi.org/10.1016/j.eswa.2017.07.004",
url = "http://www.sciencedirect.com/science/article/pii/S0957417417304736",
author = "Feng Li and Timon C. Du",
keywords = "Online social network",
keywords = "WoM",
keywords = "Newsvendor problem",
abstract = "Social networks connect users to share thoughts and build friendships. The high degree of intimacy among users has made it a good venue for word-of-mouth (WoM) marketing. Admittedly there are some basic differences, but this study focuses on the effectiveness of WoM marketing in offline and online social networks. A system was developed to simulate offline and online networks using small-world (SW) and scale-free (SF) networks, respectively. An offline network was found to be more effective in promoting a product with a fixed advertising budget and in selling higher margin products than an online network. However, if customers have diversified backgrounds and are strongly opinionated, an online network is a better venue. These findings can be used as guidelines to determine the appropriateness of moving WoM marketing from offline to online networks."
}

@Article{ahmedi2017,
author="Ahmedi, Lule
and Rrmoku, Korab
and Sylejmani, Kadri
and Shabani, Dardan",
title="A bimodal social network analysis to recommend points of interest to tourists",
journal="Social Network Analysis and Mining",
year="2017",
month="Apr",
day="21",
volume="7",
number="1",
pages="14",
abstract="With the progressive role of computers and their users as actors in social networks, computations alike social network analysis (SNA) are gaining in attention. This work proposes an approach based on SNA, not alone on social networks as supported by existing approaches, to estimate the tourists' satisfaction with individual Points of Interest (POIs), and accordingly recommend those POIs or not to that tourist or its tour planning system. Moreover, instead of a common unimodal network, a bimodal tourist--reviewer network is modeled as suggested by the SNA literature given tourists and POI reviewers act as two distinct classes of entities with links between them representing their (dis)similarities. Both tourists and reviewers provide their personal attributes (like age), but reviewers then providing preferences for specific POIs, whereas tourists only preferences for certain types or categories of POIs (say archeology). Further, an algorithm for grouping into ``islands'' of most similar reviewers to a certain tourist given the strength of corresponding links in the bimodal network is developed. Additionally, a ranking algorithm based on in-degree or authority centrality is adopted to identify the highest ranked reviewers within the island and recommend their preferred POIs to a given tourist. If there are more than single POIs preferred per reviewer, and there remain more than requested POIs of the highly ranked reviewers to select among for recommendation, a similar centrality algorithm is applied over a reviewer--POI network with links representing a certain reviewer prefers that certain POI. The evaluation initially with an exemplary real-life experiment, and then extended to a massive online dataset from Foursquare, proves our approach as feasible in estimating the tourist's satisfaction with individual POIs. Moreover, it is already promising since incorporating location influence remains yet our future work and might further improve its performance.",
issn="1869-5469",
doi="10.1007/s13278-017-0431-8",
url="https://doi.org/10.1007/s13278-017-0431-8"
}



@Article{bouslimi2016,
author="Bouslimi, Riadh
and Ayadi, Mouhamed Gaith
and Akaichi, Jalel",
title="Semantic medical image retrieval in a medical social network",
journal="Social Network Analysis and Mining",
year="2016",
month="Dec",
day="20",
volume="7",
number="1",
pages="2",
abstract="Medical social networks have become an exchange of opinions between patients and health professionals. However, patients are anxious to quickly find a reliable analysis and a concise explanation of their medical images and express their queries through a textual description or a visual description or both sets. For this, we present in this paper a multimodal research model to research medical images based on multimedia information that is extracted from a radiological collaborative social network. Indeed, the opinions shared on a medical image in a medico-social network are a textual description which in most cases requires cleaning by using a medical thesaurus. In addition, we describe the textual description and medical image in a TF-IDF weight vector using an approach of ``bag of words''. We use latent semantic analysis to establish relationships between textual terms and visual terms in shared opinions on the medical image. The multimodal modeling researches the medical information through multimodal queries. Our model is evaluated against the ImageCLEFMed'2015 baseline, which is the ground truth for our experiments. We have conducted numerous experiments with different descriptors and many combinations of modalities. The analysis of results shows that the model based on two methods can increase the performance of a research system based on a single modality, visual or textual.",
issn="1869-5469",
doi="10.1007/s13278-016-0420-3",
url="https://doi.org/10.1007/s13278-016-0420-3"
}




@article{deng17,
title = "A general and effective diffusion-based recommendation scheme on coupled social networks",
journal = "Information Sciences",
volume = "417",
number = "",
pages = "420 - 434",
year = "2017",
note= "",
issn = "0020-0255",
doi = "http://dx.doi.org/10.1016/j.ins.2017.07.021",
url = "http://www.sciencedirect.com/science/article/pii/S0020025517308368",
author = "Xiaofang Deng and Yuansheng Zhong and Linyuan Lü and Naixue Xiong and Chiho Yeung",
keywords = "Social information",
keywords = "Cold start",
keywords = "Diffusion-based recommendation",
keywords = "Mass diffusion",
abstract = "Online social networks and recommender systems are two of the most common internet applications, but due to their different nature, they are seldom considered under a single framework. Nevertheless we often rely on friends for advices before purchasing products or services. In other words, information embedded in the online social networks may be relevant to recommender systems and the combination of the two systems may benefit each other. In this paper, we introduce a simple recommendation algorithm based on a diffusion process which integrates the networks of friends and user-product relations. Our results show that social networks improve the accuracy of recommendation for inactive users, and increase the diversity of the recommended products for active users. In addition, our approach outperforms conventional popularity-based algorithms and provides personalized recommendations in the cold-start period. These results shed light on a new design of recommendation algorithms in integrating social information and recommendations."
}



@article{demeo17,
title = "Forming time-stable homogeneous groups into Online Social Networks",
journal = "Information Sciences",
volume = "414",
number = "",
pages = "117 - 132",
year = "2017",
note= "",
issn = "0020-0255",
doi = "http://dx.doi.org/10.1016/j.ins.2017.05.048",
url = "http://www.sciencedirect.com/science/article/pii/S0020025517307661",
author = "Pasquale De Meo and Fabrizio Messina and Domenico Rosaci and Giuseppe M.L. Sarn\'e",
keywords = "Online Social Network",
keywords = "Similarity",
keywords = "Homogeneity",
keywords = "Reputation",
keywords = "Trust",
abstract = "In this work we investigate on the time-stability of the homogeneity â“ in terms of mutual usersâ™ similarity within groups â“ into real Online Social Networks by taking into account usersâ™ behavioral information as personal interests. To this purpose, we introduce a conceptual framework to represents the time evolution of the group formation in an OSN. The framework includes a specific experimental approach that has been adopted along with a flexible, distributed algorithm (U2G) designed to drive group formation by weighting two different measures, mutual trust relationships and similarity, denoted by compactness. An experimental campaign has been carried out on datasets extracted from two social networks, CIAO and EPINIONS, and the results show that the time-stability of similarity measure for groups formed by the algorithm U2G based on the sole similarity criterion is lower than that of groups formed by considering similarity and trust together, even when the weight assigned to the trust component is small."
}


@article{dokuz2017,
title = "Discovering socially important locations of social media users",
journal = "Expert Systems with Applications",
volume = "86",
number = "",
pages = "113 - 124",
year = "2017",
note= "",
issn = "0957-4174",
doi = "http://dx.doi.org/10.1016/j.eswa.2017.05.068",
url = "http://www.sciencedirect.com/science/article/pii/S0957417417303949",
author = "Ahmet Sakir Dokuz and Mete Celik",
keywords = "Socially important locations mining",
keywords = "Spatial social media mining",
keywords = "Historical social media data analysis",
keywords = "Social media networking sites",
keywords = "Twitter",
abstract = "Socially important locations are places that are frequently visited by social media users in their social media life. Discovering socially interesting, popular or important locations from a location based social network has recently become important for recommender systems, targeted advertisement applications, and urban planning, etc. However, discovering socially important locations from a social network is challenging due to the data size and variety, spatial and temporal dimensions of the datasets, the need for developing computationally efficient approaches, and the difficulty of modeling human behavior. In the literature, several studies are conducted for discovering socially important locations. However, majority of these studies focused on discovering locations without considering historical data of social media users. They focused on analysis of data of social groups without considering each userâ™s preferences in these groups. In this study, we proposed a method and interest measures to discover socially important locations that consider historical user data and each userâ™s (individualâ™s) preferences. The proposed algorithm was compared with a naÃ¯ve alternative using real-life Twitter dataset. The results showed that the proposed algorithm outperforms the naÃ¯ve alternative."
}

 
%:%%%%%%%%%%%% PROYECTO 2016


@article{Konecny2016,
title = "Block relations in formal fuzzy concept analysis",
journal = "International Journal of Approximate Reasoning",
volume = "73",
number = "",
pages = "27 - 55",
year = "2016",
note= "",
issn = "0888-613X",
doi = "http://dx.doi.org/10.1016/j.ijar.2016.02.004",
url = "http://www.sciencedirect.com/science/article/pii/S0888613X16300056",
author = "Jan Konecny and Michal Krupka",
keywords = "Galois connection",
keywords = "Formal concept analysis",
keywords = "Fuzzy sets",
keywords = "Block relation"
}


@Article{Konecny2017,
  author   = {Jan Konecny and Michal Krupka},
  title    = {Complete relations on fuzzy complete lattices},
  journal  = {Fuzzy Sets and Systems},
  year     = {2017},
  volume   = {320},
  pages    = {64 - 80},
  issn     = {0165-0114},
  note     = {Theme Logic and Algebra},
  doi      = {https://doi.org/10.1016/j.fss.2016.08.007},
  keywords = {Fuzzy tolerance, Fuzzy order, Fuzzy Galois connection, Factorization },
  url      = {http://www.sciencedirect.com/science/article/pii/S0165011416302718},
}


@article{Belohlavek2016357,
title = "Bases of closure systems over residuated lattices ",
journal = "Journal of Computer and System Sciences ",
volume = "82",
number = "2",
pages = "357 - 365",
year = "2016",
note= "",
issn = "0022-0000",
doi = "http://dx.doi.org/10.1016/j.jcss.2015.07.003",
url = "http://www.sciencedirect.com/science/article/pii/S0022000015000781",
author = "Radim Belohlavek and Jan Konecny",
keywords = "Closure operator",
keywords = "Base",
keywords = "Residuated lattice",
keywords = "Fuzzy logic ",
abstract = "Abstract We present results on bases of closure systems over residuated lattices, which appear in applications of fuzzy logic. Unlike the Boolean case, the situation is not straightforward as there are two non-commuting generating operations involved. We present a decomposition theorem for a general closure operator and utilize it for computing generators and bases of the closure system. We show that bases are not unique and may in general have different sizes, and obtain a constructive description of the size of a largest base. We prove that if the underlying residuated lattice is a chain, all bases have the same size. "
}


@Article{He2015,
author="He, Pengfei
and Xin, Xiaolong
and Yang, Yongwei",
title="On state residuated lattices",
journal="Soft Computing",
year="2015",
volume="19",
number="8",
pages="2083--2094",
issn="1433-7479",
doi="10.1007/s00500-015-1620-x",
url="http://dx.doi.org/10.1007/s00500-015-1620-x"
}



@Article{Ma2015,
author="Ma, Zhen Ming and Fu, Zun Wei",
title="Algebraic study to generalized Bosbach states on residuated lattices",
journal="Soft Computing",
year="2015",
volume="19",
number="9",
pages="2541--2550",
abstract="Generalized Bosbach states of type I and II, which are also called type I and II states, are useful for the development of algebraic theory of probabilistic models for fuzzy logics. In this paper, a pure algebraic study to the generalization of Bosbach states on residuated lattices is made. By rewriting the equations of Bosbach states, an alternative definition of type II states is given, and five types of generalized Bosbach states of type III, IV, V, VI and VII (or simply, type III, IV, V, VI and VII states) are introduced. The relationships among these generalized Bosbach states and properties of them are investigated by some examples and results. Particularly, type IV states are a new type of generalized Bosbach states which are different from type I, II and III states; type V (resp. VI) states can be equivalently defined by both type I (resp. II) states and type IV states; type I, II and III states are equivalent when the codomain is an MV-algebra as well as type V and type VI states.",
issn="1433-7479",
doi="10.1007/s00500-015-1671-z",
url="http://dx.doi.org/10.1007/s00500-015-1671-z"
}



%:%%%%%%%%%%%% BIREDUCTS

@Article{bmrd:FCARST:f,
title = {Rough-set-driven approach for attribute reduction in fuzzy formal concept analysis},
journal = {Fuzzy Sets and Systems},
volume = {391},
pages = {117-138},
year = {2020},
issn = {0165-0114},
doi = {https://doi.org/10.1016/j.fss.2019.11.009},
url = {https://www.sciencedirect.com/science/article/pii/S0165011419305044},
author = {Ben{\'\i}tez-Caballero, Mar{\'\i}a Jos{\'e} and Medina, Jes{\'u}s and Ram{\'\i}rez-Poussa, Elo{\'\i}sa and Dominik \'{S}l\c{e}zak}
}




@Inbook{MedinaBireducts2020,
author="Ben{\'i}tez-Caballero, M. Jos{\'e}
and Medina-Moreno, Jes{\'u}s
and Ram{\'i}rez-Poussa, Elo{\'i}sa",
editor="K{\'o}czy, L{\'a}szl{\'o} T
and Medina-Moreno, Jes{\'u}s 
and Ram{\'i}rez-Poussa, Elo{\'i}sa
and {\v{S}}ostak, Alexander",
title="Bireducts in Formal Concept Analysis",
bookTitle="Computational Intelligence and Mathematics for Tackling Complex Problems",
year="2020",
publisher="Springer International Publishing",
address="Cham",
pages="191--198",
abstract="InBen{\'i}tez-Caballero, Jos{\'e} this paper we apply the philosophy of RoughMedina, Jes{\'u}s Set Theory to reduce formal context in the environment of Formal Concept Analysis. Specifically, we propose a reduction mechanism based on the consideration of bireducts and we also study several properties of theRam{\'i}rez-Poussa, Elo{\'i}sa reduced contexts.",
isbn="978-3-030-16024-1",
doi="10.1007/978-3-030-16024-1_24",
url="https://doi.org/10.1007/978-3-030-16024-1_24"
}

@Article{bmrd:RSTFCA:c,
  author    = {M. José Ben{\'i}tez-Caballero and Jesús Medina and Eloísa Ram{\'i}rez-Poussa and Dominik \'{S}l\c{e}zak},
  title     = {A computational procedure for variable selection preserving different initial conditions},
  journal   = {International Journal of Computer Mathematics},
volume = {97},
number = {1-2},
pages = {387-404},
year  = {2020},
publisher = {Taylor & Francis},
  doi       = {10.1080/00207160.2019.1613530},
  eprint    = {https://doi.org/10.1080/00207160.2019.1613530},
  url       = {https://doi.org/10.1080/00207160.2019.1613530},
}


@InProceedings{eusflat17:red,
  author    = {Ben{\'i}tez-Caballero, Mar{\'i}a Jos{\'e} and Medina, Jes{\'u}s and Ram{\'i}rez-Poussa, Elo{\'i}sa},
  title     = {Reducing
  concept lattices from rough set theory},
  booktitle = {Advances in Fuzzy
  Logic and Technology},
  year      = {2017},
 editor    = {Kacprzyk, J. and Szmidt, E. and   Zadro{\.{z}}ny, S. and Atanassov, K.T. and Krawczak, M.},
  publisher = {Springer International Publishing},
   address   = {Cham}, 
  pages     = {177--186},
}

 
  

@InProceedings{ijcrs:2017,
  author    = {Ben{\'i}tez-Caballero, Mar{\'i}a Jos{\'e} and Medina, Jes{\'u}s and Ram{\'i}rez-Poussa, Elo{\'i}sa},
  title     = {Attribute Reduction in Rough Set Theory and Formal Concept Analysis},
  booktitle = {Rough Sets},
  year      = {2017},
  editor    = {Polkowski, Lech and Yao, Yiyu and Artiemjew, Piotr and Ciucci, Davide and Liu, Dun and {\'{S}}l{\c{e}}zak, Dominik and Zielosko, Beata},
  publisher = {Springer International Publishing},
  isbn      = {978-3-319-60840-2},
  pages     = {513--525},
  abstract  = {Rough Set Theory (RST) and Formal Concept Analysis (FCA) are two mathematical tools for data analysis which, in spite of considering different philosophies, are closely related. In this paper, we study the relation between the attribute reduction mechanisms in FCA and in RST. Different properties will be introduced which provide a new size reduction mechanism in FCA based on the philosophy of RST.},
  address   = {Cham},
}


@article{ins2018:bmrs,
title = "Bireducts with tolerance relations",
journal = "Information Sciences",
volume = "435",
pages = "26 - 39",
year = "2018",
issn = "0020-0255",
doi = "https://doi.org/10.1016/j.ins.2017.12.037",
url = "http://www.sciencedirect.com/science/article/pii/S002002551731160X",
author = "Mar\'ia Jos\'e Ben\'itez-Caballero and  Jes\'us Medina and  Eloisa Ram\'irez-Poussa and Dominik \'{S}l\c{e}zak",
keywords = "Attributes reduction, Tolerance relations, Discernibility function, Information bireducts"
}


@article{ijcrs2017:bmr,
  author    = {María José Benítez-Caballero and Jesús Medina and Eloisa Ramírez-Poussa},
  title     = {Attribute Reduction in Rough Set Theory and Formal Concept Analysis},
  year      = {2017},
  pages     = {513--525},
journal={Lecture Notes in Computer Science},
volume ={10314},
}

@Inbook{benitez:escim18,
author="Ben{\'i}tez-Caballero, M. Jos{\'e}
and Medina, Jes{\'u}s
and Ram{\'i}rez-Poussa, Elo{\'i}sa",
editor="Cornejo, Mar{\'i}a Eugenia
and K{\'o}czy, L{\'a}szl{\'o} T.
and Medina, Jes{\'u}s
and De Barros Ruano, Antonio Eduardo",
title="Unifying Reducts in Formal Concept Analysis and Rough Set Theory",
bookTitle="Trends in Mathematics and Computational Intelligence",
year="2019",
publisher="Springer International Publishing",
address="Cham",
pages="89--95",
abstract="AttributeBen{\'i}tez-Caballero, M. Jos{\'e} reductionMedina, Jes{\'u}s isRam{\'i}rez-Poussa, Elo{\'i}sa a fundamental part in different mathematical tools devoted to data analysis, such as, Rough Set Theory and Formal Concept Analysis. These last mathematical theories are closely related and, in this paper, we establish connections between attribute reduction in both frameworks. Mainly, we have introduced a sufficient and necessary condition in order to ensure that the reducts in both theories coincide.",
isbn="978-3-030-00485-9",
doi="10.1007/978-3-030-00485-9_10",
url="https://doi.org/10.1007/978-3-030-00485-9_10"
}

@article{kaytoue143,  
TITLE = {{Biclustering meets triadic concept analysis}},  
AUTHOR = {Kaytoue, Mehdi and Kuznetsov, Sergei O. and Macko, Juraj and Napoli, Amedeo},  
URL = {https://hal.inria.fr/hal-01101143},  
JOURNAL = {{Annals of Mathematics and Artificial Intelligence}},  PUBLISHER = {{Springer Verlag}},  
VOLUME = {70},  
PAGES = {55 - 79},  
YEAR = {2014},  
DOI = {10.1007/s10472-013-9379-1},  
KEYWORDS = {Triadic Analysis ; Formal Concept Analysis},  
PDF = {https://hal.inria.fr/hal-01101143/file/mk-etal-amai70-2014.pdf},
}


@article{Stawicki20177,
title = "Decision bireducts and decision reducts - a comparison ",
journal = "International Journal of Approximate Reasoning ",
volume = "84",
number = "",
pages = "75--109",
year = "2017",
note= "",
issn = "0888-613X",
doi = "https://doi.org/10.1016/j.ijar.2017.02.007",
url = "http://www.sciencedirect.com/science/article/pii/S0888613X17301408",
author = "Sebastian Stawicki and Dominik \'{S}l\c{e}zak and Andrzej Janusz and Sebastian Widz",
keywords = "Decision reducts",
keywords = "Decision bireducts",
keywords = "Classifier ensembles",
keywords = "Boolean reasoning",
keywords = "Computational complexity",
keywords = "Heuristic algorithms ",
abstract = "Abstract In this paper we revise the notion of decision bireducts. We show new interpretations and we prove several important and practically useful facts regarding this notion. We also explain the way in which some of the well-known algorithms for computation of decision reducts can be modified for the purpose of computing decision bireducts. For the sake of completeness of our study we extend our investigations to relations between decision bireducts and so-called approximate decision reducts. We compare different formulations of those two approaches and draw analogies between them. We also report new results related to NP-hardness of searching for optimal decision bireducts and approximate decision reducts from data. Finally, we present new results of empirical tests which demonstrate usefulness of decision bireducts in a construction of efficient, yet simple ensembles of classification models. "
}


 @Book{Gabbay,
  title     = {Handbook of Philosophical Logic. Volume I: Elements of Classical Logic},
  publisher = {Springer Netherlands},
  year      = {1983},
  editor    = {Dov M. Gabbay and Franz Guenthner},
  volume    = {I},
  series    = {Handbook of Philosophical Logic},
}

%: PREFERENCIAS

@article{dubois12,
title = "Gradualness, uncertainty and bipolarity: Making sense of fuzzy sets",
journal = "Fuzzy Sets and Systems",
volume = "192",
pages = "3 - 24",
year = "2012",
issn = "0165-0114",
doi = "https://doi.org/10.1016/j.fss.2010.11.007",
url = "http://www.sciencedirect.com/science/article/pii/S0165011410004598",
author = "Didier Dubois and Henri Prade",
keywords = "Higher-order fuzzy sets, Fuzzy numbers, Possibility theory, Truth-functionality, Uncertainty, Bipolarity",
abstract = "This paper discusses basic notions underlying fuzzy sets, especially gradualness, uncertainty, vagueness and bipolarity, in order to clarify the significance of using fuzzy sets in practice. Starting with the idea that a fuzzy set may represent either a precise gradual composite entity or an epistemic construction refereeing to an ill-known object, it is shown that each of this view suggests a different use of fuzzy sets. Then, it is argued that the usual phrase fuzzy number is ambiguous as it induces some confusion between gradual extensions of real numbers and gradual extensions of interval calculations. The distinction between degrees of truth that are compositional and degrees of belief that cannot be so is recalled. The truth-functional calculi of various extensions of fuzzy sets, motivated by the desire to handle ill-known membership grades, are shown to be of limited significance for handling this kind of uncertainty. Finally, the idea of a separate handling of membership and non-membership grades put forward by Atanassov is cast in the setting of reasoning about bipolar information. This intuition is different from the representation of ill-known membership functions and leads to combination rules differing from the ones proposed for handling uncertainty about membership grades."
}

@article{dubois11,
title = "The role of fuzzy sets in decision sciences: Old techniques and new directions",
journal = "Fuzzy Sets and Systems",
volume = "184",
number = "1",
pages = "3 - 28",
year = "2011",
issn = "0165-0114",
doi = "https://doi.org/10.1016/j.fss.2011.06.003",
url = "http://www.sciencedirect.com/science/article/pii/S0165011411002740",
author = "Didier Dubois",
keywords = "Decision, Qualitative value scales, Aggregation, Linguistic variables, Preference relations, Fuzzy intervals, Ranking methods",
abstract = "We try to provide a tentative assessment of the role of fuzzy sets in decision analysis. We discuss membership functions, aggregation operations, linguistic variables, fuzzy intervals and the valued preference relations they induce. The importance of the notion of bipolarity and the potential of qualitative evaluation methods are also pointed out. We take a critical standpoint on the state-of-the-art, in order to highlight the actual achievements and question what is often considered debatable by decision scientists observing the fuzzy decision analysis literature."
}

@article{dubois97,
title = "The three semantics of fuzzy sets",
journal = "Fuzzy Sets and Systems",
volume = "90",
number = "2",
pages = "141 - 150",
year = "1997",
issn = "0165-0114",
doi = "https://doi.org/10.1016/S0165-0114(97)00080-8",
url = "http://www.sciencedirect.com/science/article/pii/S0165011497000808",
author = "Didier Dubois and Henri Prade",
keywords = "Similarity, Preference, Uncertainty",
abstract = "Three main semantics for membership functions seem to exist in the literature: similarity, preference and uncertainty. Each semantics underlies a particular class of applications. Similarity notions are exploited in clustering analysis and fuzzy controllers. Uncertainty is captured by fuzzy sets in the framework of possibility theory. The membership function of a fuzzy set is also sometimes a kind of utility function that represents flexible constraints in decision problems. This paper advocates the claim that progress in operational semantics of membership functions presupposes that these distinct semantics be acknowledged and related to more basic measurement issues in terms of distance, cost and frequency, on which scientific traditions exist."
}

%:SIMILARITY

@ARTICLE{guan2018,
author={Guan, L. and Huang, D. and Han, F.},
title={Tolerance Dominance Relation in Incomplete Ordered Decision Systems},
journal={International Journal of Intelligent Systems},
year={2018},
volume={33},
number={1},
pages={33-48},
doi={10.1002/int.21932},
}


@inproceedings{Wille1985,
  author        = {Wille, R.},
  title         = {Complete tolerance relations of concept lattices},
editor={{Eigenthaler G. et al.}},
bookTitle={Contributions to General Algebra},
  Volume                   = {3},
 year={1985},
publisher={H\"older-Pichler-Tempsky},
address={Wien},
pages={397-415},
isbn={9783519027621},
}


@Article{czedli82,
  Title                    = {Factor lattices by tolerances},
  Author                   = {Czedli, Gabor},
  Journal                  = {Acta Sci. Math.(Szeged)},
  Year                     = {1982},
  Number                   = {1-2},
  Pages                    = {35--42},
  Volume                   = {44}
}

@inproceedings{escim2015bireduct,
	author = {M.J. Ben\'itez and  J. Medina and D. \'{S}l\c{e}zak},
         editor    = {J. Kacprzyk and L. Koczy and J. Medina},
 	Title = {Reducing information systems considering similarity relations},
         Booktitle     = {7th European Symposium on Computational Intelligence  and Mathematices (ESCIM 2015)},
        location  = {Cádiz, Spain},
        year      = {2015},
        pages = {257--263},
	}



@inproceedings{eusflat2015bireducts,
  title={Delta-information reducts and bireducts},
  author={Mª José Benítez and Jesús Medina and Dominik Slezak},
  year={2015/06},
  booktitle={2015 Conference of the International Fuzzy Systems Association and the European Society for Fuzzy Logic and Technology (IFSA-EUSFLAT-15)},
  issn={1951-6851},
  isbn={978-94-62520-77-6},
  url={https://doi.org/10.2991/ifsa-eusflat-15.2015.163},
  doi={https://doi.org/10.2991/ifsa-eusflat-15.2015.163},
  publisher={Atlantis Press}
}


@article{Ciobanu2015,
title = "Similarity relations in fuzzy attribute-oriented concept lattices ",
journal = "Fuzzy Sets and Systems ",
volume = "275",
number = "",
pages = "88 - 109",
year = "2015",
issn = "0165-0114",
doi = "http://dx.doi.org/10.1016/j.fss.2014.12.011",
url = "http://www.sciencedirect.com/science/article/pii/S0165011414005831",
author = "Gabriel Ciobanu and Cristian V{\v a}ideanu",
keywords = "Similarity relation",
keywords = "Formal concept analysis with fuzzy attributes",
keywords = "Fuzzy attribute-oriented concept lattice ",
abstract = "Abstract The study of concept lattices and oriented concept lattices with fuzzy attributes provides complementary conceptual structures, which can be used to search, analyze and extract information from large datasets. In this paper, we put forward new types of similarity relations between objects or attributes in fuzzy attribute-oriented concept lattices. We analyze how these similarities are related using the definitions and considering the reducibility between antitone and isotone fuzzy concept lattices as well. A comparison is made between two relations which measure the similarity of fuzzy oriented concepts. These relations are employed in factorizing the fuzzy attribute-oriented concept lattice, in order to reduce its complexity. "
}


@article{Li2015,
title = "{T}-similarity of fuzzy relations and related algebraic structures ",
journal = "Fuzzy Sets and Systems ",
volume = "275",
number = "",
pages = "130 - 143",
year = "2015",
issn = "0165-0114",
doi = "http://dx.doi.org/10.1016/j.fss.2014.11.011",
url = "http://www.sciencedirect.com/science/article/pii/S0165011414005144",
author = "Zhaowen Li and Rongchen Cui",
keywords = "Fuzzy relation",
keywords = "T-similarity",
keywords = "Fuzzy topology",
keywords = "Fuzzy approximation space",
keywords = "T-fuzzy rough approximation operator",
keywords = "Algebraic structure ",
abstract = "Abstract In this paper, we show that fuzzy Alexandrov topologies can be induced by fuzzy relations. The concept of T-similarity of fuzzy relations is introduced. Variations of the same fuzzy relation are investigated. The fact that every fuzzy relation is solely T-similar to some T-preorder fuzzy relation is proved. A characteristic condition for fuzzy relations to be T-transitive is established. These results illustrate that fuzzy relations can be studied by means of topology. Moreover, algebraic structures based on T-similarity of fuzzy relations are obtained. "
}

@article{pascual2015,
title = "Proximity-based unification theory ",
journal = "Fuzzy Sets and Systems ",
volume = "262",
number = "",
pages = "21 - 43",
year = "2015",
issn = "0165-0114",
doi = "http://dx.doi.org/10.1016/j.fss.2014.07.006",
url = "http://www.sciencedirect.com/science/article/pii/S0165011414003133",
author = "Pascual Juli\'an-Iranzo and Clemente Rubio-Manzano",
keywords = "Fuzzy logic programming",
keywords = "Unification theory",
keywords = "Proximity relations ",
abstract = "Abstract Similarity-based Logic Programming has been proposed to enhance the Logic Programming paradigm with similarity relations, in order to represent and manage vague or imprecise information. A similarity relation is a reflexive, symmetric, transitive fuzzy binary relation, extending the standard notion of equivalence relation with the purpose of weakening the concept of equality. As is reported, similarity relations have significant limitations, due to the transitivity restriction, that can lead to representing fuzzy information incorrectly in some situations. Recently we have proposed the use of proximity relations (i.e., reflexive, symmetric, fuzzy binary relations) in the context of a logic programming system, called Bousiâˆ?Prolog, as a way of solving this problem and generalizing later approaches exclusively based on similarity relations. However, a naive combination of proximity relations and the existing unification algorithms may cause incompleteness problems. Hence, in this paper, we introduce an accurate definition of proximity between expressions (terms or atomic formulas) and a new unification algorithm able to manage proximity relations properly. The so-called weak unification algorithm is an extension of Martelli and Montanari's unification algorithm supported by the new notion of proximity. As major relevant properties, we prove that the weak unification algorithm terminates and it is sound (i.e., it produces a weak unifier of two expressions, if they are unifiable) and complete (i.e., it is able to compute a weak most general unifier for two unifiable expressions). "
}




@article{rubio2014fuzzy,
  title={A Fuzzy linguistic prolog and its applications},
  author={Rubio-Manzano, Clemente and Juli{\'a}n-Iranzo, Pascual},
  journal={Journal of Intelligent \& Fuzzy Systems},
  volume={26},
  number={3},
  pages={1503--1516},
  year={2014},
  publisher={IOS Press}
}

@article{romero2013classifying,
  title={Classifying unlabeled short texts using a fuzzy declarative approach},
  author={Romero, Francisco P and Juli{\'a}n-Iranzo, Pascual and Soto, Andr{\'e}s and Ferreira-Satler, Mateus and Gallardo-Casero, Juan},
  journal={Language resources and evaluation},
  volume={47},
  number={1},
  pages={151--178},
  year={2013},
  publisher={Springer}
}

@article{rubioincorporation,
  title={Incorporation of abstraction capability in a logic-based framework by using proximity relations},
  author={Rubio-Manzano, Clemente and Juli{\'a}n-Iranzo, Pascual},
  journal={Journal of Intelligent \& Fuzzy Systems},
  volume={29},
  number={4},
  pages={1671--1683},
  year={2015},
  publisher={IOS Press}
}




@inproceedings{trivino2015automatic,
  author    = {Clemente Rubio{-}Manzano and
               Graci{\'{a}}n Trivi{\~{n}}o},
  title     = {Automatic Linguistic Feedback in Computer Games},
  booktitle = {2015 Conference of the International Fuzzy Systems Association and
               the European Society for Fuzzy Logic and Technology (IFSA-EUSFLAT-15),
               Gij{\'{o}}n, Spain., June 30, 2015.},
  year      = {2015},
  crossref  = {DBLP:conf/eusflat/2015},
  timestamp = {Mon, 23 Nov 2015 10:01:26 +0100},
  biburl    = {http://dblp2.uni-trier.de/rec/bib/conf/eusflat/Rubio-ManzanoT15},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@proceedings{DBLP:conf/eusflat/2015,
  editor    = {Jos{\'{e}} M. Alonso and
               Humberto Bustince and
               Marek Reformat},
  title     = {2015 Conference of the International Fuzzy Systems Association and
               the European Society for Fuzzy Logic and Technology (IFSA-EUSFLAT-15),
               Gij{\'{o}}n, Spain., June 30, 2015},
  publisher = {Atlantis Press},
  year      = {2015},
  isbn      = {978-94-62520-77-6},
  timestamp = {Fri, 20 Nov 2015 17:36:31 +0100},
  biburl    = {http://dblp2.uni-trier.de/rec/bib/conf/eusflat/2015},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}
 



@article{pitoura2011contextual,
  title={Contextual Database Preferences.},
  author={Pitoura, Evaggelia and Stefanidis, Kostas and Vassiliadis, Panos},
  journal={IEEE Data Eng. Bull.},
  volume={34},
  number={2},
  pages={19--26},
  year={2011}
}


 @incollection{Bazan2003,
year={2003},
isbn={978-3-540-20256-1},
booktitle={Foundations of Intelligent Systems},
volume={2871},
series={Lecture Notes in Computer Science},
editor={Zhong, Ning and Ra, ZbigniewW. and Tsumoto, Shusaku and Suzuki, Einoshin},
doi={10.1007/978-3-540-39592-8_22},
title={Searching for the Complex Decision Reducts: The Case Study of the Survival Analysis},
url={http://dx.doi.org/10.1007/978-3-540-39592-8_22},
publisher={Springer Berlin Heidelberg},
author={Bazan, Jan and Skowron, Andrzej and \'{S}l\c{e}zak, Dominik and Wr\'oblewski, Jakub},
pages={160-168},
language={English}
}



@INPROCEEDINGS{Stepaniuk95,
  Author                   = {J. Stepaniuk and A. Kr\c{e}towski},
title={Decision system based on tolerance rough sets },
booktitle={Proceedings of the Fourth International Workshop on Intelligent  Information Systems},
year={1995},
month={June 5-9},
pages={62-73},
 address = {Augustow, Poland},
  publisher = {Institute of Computer Science, Polish Academy of Sciences},
}


@INPROCEEDINGS{Stepaniuk96,
  Author                   = {A. Kr\c{e}towski and J. Stepaniuk},
title={Selection of objects and attributes a tolerance rough set approach},
booktitle={Proceedings of the Poster Session of Ninth International Symposium on Methodologies for Intelligent Systems},
year={1996},
month={July 10-13},
pages={169-180},
 address = {Zakopane, Poland},
}


@Article{StepaniukFI96,
  Title                    = {Tolerance approximation spaces},
  Author                   = {A. Skowron and J. Stepaniuk},
  Journal                  = {Fundamenta Informaticae},
  Year                     = {1996},
  Pages                    = {245--253},
  Volume                   = {27},
  number ={2-3},
}



@incollection{dominikjanusz:11,
  Author                   = {Dominik \'{S}l\c{e}zak and Andrzej Janusz},
year={2011},
isbn={978-3-642-27141-0},
booktitle={Future Generation Information Technology},
volume={7105},
series={Lecture Notes in Computer Science},
editor={Kim, Tai-hoon and Adeli, Hojjat and \'{S}l\c{e}zak, Dominik and Sandnes, FrodeEika and Song, Xiaofeng and Chung, Kyo-il and Arnett, KirkP.},
doi={10.1007/978-3-642-27142-7_9},
title={Ensembles of Bireducts: Towards Robust Classification and Simple Representation},
url={http://dx.doi.org/10.1007/978-3-642-27142-7_9},
publisher={Springer Berlin Heidelberg},
keywords={Attribute Subset Selection; Inexact Dependencies; Classifier Ensembles; Discernibility; Decision Rules; Randomized Search},
pages={64-77},
language={English}
}
 
@Article{dominik:fi12,
  Title                    = {Unsupervised Similarity Learning from Textual Data},
  Author                   = {Andrzej Janusz and Dominik \'{S}l\c{e}zak and  Hung Son Nguyen},
  Journal                  = {Fundamenta Informaticae},
  Year                     = {2012},
  Month                    = {01},
  Pages                    = {319 - 336},
  Volume                   = {Volume 119},
  Doi                      = {10.3233/FI-2012-740},
  Url                      = {http://iospress.metapress.com/content/N250164313764352}
}

@Article{dominik:aai14,
  Title                    = {Rough Set Methods for Attribute Clustering and Selection},
  Author                   = {Janusz, Andrzej and \'{S}l\c{e}zak, Dominik},
  Journal                  = {Applied Artificial Intelligence},
  Year                     = {2014},
  Number                   = {3},
  Pages                    = {220-242},
  Volume                   = {28},
  Doi                      = {10.1080/08839514.2014.883902},
  Eprint                   = { http://dx.doi.org/10.1080/08839514.2014.883902},
  Url                      = { http://dx.doi.org/10.1080/08839514.2014.883902}
}

@InCollection{dominik:fgit11,
  Title                    = {Ensembles of Bireducts: Towards Robust Classification and Simple Representation},
  Author                   = {\'{S}l\c{e}zak, Dominik and Janusz, Andrzej},
  Booktitle                = {Future Generation Information Technology},
  Publisher                = {Springer Berlin Heidelberg},
  Year                     = {2011},
  Editor                   = {Kim, Tai-hoon and Adeli, Hojjat and \'{S}l\c{e}zak, Dominik and Sandnes, FrodeEika and Song, Xiaofeng and Chung, Kyo-il and Arnett, KirkP.},
  Pages                    = {64-77},
  Series                   = {Lecture Notes in Computer Science},
  Volume                   = {7105},
  Doi                      = {10.1007/978-3-642-27142-7_9},
  ISBN                     = {978-3-642-27141-0},
  Keywords                 = {Attribute Subset Selection; Inexact Dependencies; Classifier Ensembles; Discernibility; Decision Rules; Randomized Search},
  Language                 = {English},
  Url                      = {http://dx.doi.org/10.1007/978-3-642-27142-7_9}
}

@InCollection{dominik:aikp12,
  Title                    = {Rough Set Based Decision Support Models Easy to Interpret},
  Author                   = {Widz, Sebastian and \'{S}l\c{e}zak, Dominik},
  Booktitle                = {Rough Sets: Selected Methods and Applications in Management and Engineering},
  Publisher                = {Springer London},
  Year                     = {2012},
  Editor                   = {Peters, Georg and Lingras, Pawan and \'{S}l\c{e}zak, Dominik and Yao, Yiyu},
  Pages                    = {95-112},
  Series                   = {Advanced Information and Knowledge Processing},
 Doi                      = {10.1007/978-1-4471-2760-4_6},
  ISBN                     = {978-1-4471-2759-8},
  Keywords                 = {Decision support; Ensembles; Ensemble feature selection; Feature subset selection; Rough sets},
  Language                 = {English},
   Url                      = {http://dx.doi.org/10.1007/978-1-4471-2760-4_6}
}




@article{Dias20131880,
title = "Applying the \{JBOS\} reduction method for relevant knowledge extraction ",
journal = "Expert Systems with Applications ",
volume = "40",
number = "5",
pages = "1880 - 1887",
year = "2013",
note= "",
issn = "0957-4174",
doi = "http://dx.doi.org/10.1016/j.eswa.2012.10.010",
url = "http://www.sciencedirect.com/science/article/pii/S0957417412011244",
author = "Sergio M. Dias and Newton J. Vieira",
keywords = "Formal concept analysis",
keywords = "\{JBOS\} method",
keywords = "Formal context reduction",
keywords = "Lattice reduction ",
abstract = "This work presents results from an experiment used to assess the \{JBOS\} (junction based on objects similarity) reduction method. Two reductions were made of a formal context about patients having symptoms in a tuberculosis data base. The first reduction used the knowledge expressed in the original formal context and the second used the knowledge expressed in expert rules. The assessment was made, in the first case, by comparison of the performances of the sets of extracted rules (stem bases) before and after the reduction, and in the second case, by comparison of the performances of the set of extracted rules after reduction with that of the expert rules. The performance in the first case was exactly the same as before reduction. In the second case the performance even improved, showing that the weighting process, besides incorporating the expert knowledge, resulted in rules well adjusted to the knowledge expressed in the original formal context. So, both reductions resulted in rule sets absolutely consistent with the original ones. The expert rules, \{FCA\} rules and both set of rules obtained after reduction were used also to classify patients of a validation set. In this case, the results have shown that the performance was the same before and after reduction. Therefore, it was shown that by means of an appropriate attributes weight assignment it is possible, by the \{JBOS\} method, to achieve a suitable level of performance in a specific task after reduction. "
}

@INPROCEEDINGS{Dias201080,
author={Dias, S.M. and Vieira, N.J.},
title={Reducing the size of concept lattices: The JBOS approach},
booktitle={7th International Conference on Concept Lattices and Their Applications (CLA 2010)},
year={2010},
volume={672},
pages={80-91},
}

@article{Belohlavek00,
author = {B{\v e}lohl{\'a}vek, R}, 
title = {Similarity relations in concept lattices},
volume = {10}, 
number = {6}, 
pages = {823-845}, 
year = {2000}, 
doi = {10.1093/logcom/10.6.823}, 
abstract ={This paper studies the issue of similarity relations in fuzzy concept lattices. Fuzzy concepts and fuzzy concept lattices represent a formal approach to the modelling of non-sharp (fuzzy) concepts and conceptual structures in the sense of traditional (Port-Royal) logic. Applications of concept lattices are in representation of conceptual knowledge and in conceptual analysis of (fuzzy) data. Similarity relations are defined and considered on three levels: similarity of objects (and similarity of attributes), similarity of concepts, and similarity of concept lattices. We show a way to factorize (simplify) concept lattices by the similarity of concepts. Also shown is how to reduce the computation of the similarity relations.}, 
URL = {http://logcom.oxfordjournals.org/content/10/6/823.abstract}, 
eprint = {http://logcom.oxfordjournals.org/content/10/6/823.full.pdf+html}, 
journal = {Journal of Logic and Computation} 
}



@article{BelohlavekSimilarityFuzzyAFCA2007,
title = "Fast factorization by similarity in formal concept analysis of data with fuzzy attributes ",
journal = "Journal of Computer and System Sciences ",
volume = "73",
number = "6",
pages = "1012 - 1022",
year = "2007",
note= "",
issn = "0022-0000",
doi = "http://dx.doi.org/10.1016/j.jcss.2007.03.016",
url = "http://www.sciencedirect.com/science/article/pii/S0022000007000384",
author = "Radim B{\v e}lohl{\'a}vek and J. Dvo{\v r}ák and Jan Outrata",
keywords = "Tabular data",
keywords = "Clustering",
keywords = "Formal concept analysis",
keywords = "Fuzzy attributes",
keywords = "Similarity",
keywords = "Factorization ",
abstract = "We present a method of fast factorization in formal concept analysis (FCA) of data with fuzzy attributes. The output of \{FCA\} consists of a partially ordered collection of clusters extracted from a data table describing objects and their attributes. The collection is called a concept lattice. Factorization by similarity enables us to obtain, instead of a possibly large concept lattice, its factor lattice. The elements of the factor lattice are maximal blocks of clusters which are pairwise similar to degree exceeding a user-specified threshold. The factor lattice thus represents an approximate version of the original concept lattice. We describe a fuzzy closure operator the fixed points of which are just clusters which uniquely determine the blocks of clusters of the factor lattice. This enables us to compute the factor lattice directly from the data without the need to compute the whole concept lattice. We present theoretical solution and examples demonstrating the speed-up of our method. "
}



@article{dominik:bi13,
year={2013},
isbn={978-3-642-41298-1},
volume={8171},
journal={Lecture Notes in Computer Science},
doi={10.1007/978-3-642-41299-8_19},
title={Recent Advances in Decision Bireducts: Complexity, Heuristics and Streams},
keywords={Bireducts; NP-hardness; Heuristic Search; Data Streams},
author={Stawicki, Sebastian and \'{S}l\c{e}zak, Dominik},
pages={200-212},
abstract={We continue our research on decision bireducts. For a decision system ?? = (U,A ? {d}), a decision bireduct is a pair (B,X), where B???A is a subset of attributes discerning all pairs of objects in X???U with different values on the decision attribute d, and where B and X cannot be, respectively, reduced and extended. We report some new results related to NP-hardness of extraction of optimal decision bireducts, heuristics aimed at searching for sub-optimal decision bireducts, and applications of decision bireducts to stream data mining.},
}


@incollection{dominik:bi132,
year={2013},
isbn={978-3-642-41298-1},
booktitle={Rough Sets and Knowledge Technology},
volume={8171},
series={Lecture Notes in Computer Science},
editor={Lingras, Pawan and Wolski, Marcin and Cornelis, Chris and Mitra, Sushmita and Wasilewski, Piotr},
doi={10.1007/978-3-642-41299-8_19},
title={Recent Advances in Decision Bireducts: Complexity, Heuristics and Streams},
url={http://dx.doi.org/10.1007/978-3-642-41299-8_19},
publisher={Springer Berlin Heidelberg},
keywords={Bireducts; NP-hardness; Heuristic Search; Data Streams},
author={Stawicki, Sebastian and \'{S}l\c{e}zak, Dominik},
pages={200-212},
abstract={We continue our research on decision bireducts. For a decision system ?? = (U,A ? {d}), a decision bireduct is a pair (B,X), where B???A is a subset of attributes discerning all pairs of objects in X???U with different values on the decision attribute d, and where B and X cannot be, respectively, reduced and extended. We report some new results related to NP-hardness of extraction of optimal decision bireducts, heuristics aimed at searching for sub-optimal decision bireducts, and applications of decision bireducts to stream data mining.},
}


@INPROCEEDINGS{jensen13,
author={Mac Parthalain, N. and Jensen, R.},
booktitle={2013 {IEEE} International Conference on Fuzzy Systems ({FUZZ-IEEE} 2013)},
title={Simultaneous feature and instance selection using fuzzy-rough bireducts},
year={2013},
month={July},
pages={1--8},
abstract={Rough set theory has proven to be a useful mathematical basis for developing automated computational approaches which are able to deal with and utilise imperfect knowledge. Ever since its inception, this theory has been successfully employed for developing computationally efficient techniques for addressing problems such as the discovery of hidden patterns in data, decision rule induction, and feature selection. As an extension to this theory, fuzzy-rough sets enhance the ability to model uncertainty and vagueness more effectively. The efficacy of fuzzy-rough set based approaches for the tasks of feature selection and rule induction is now well established in the literature. Although some work has been carried out using fuzzy-rough set theory for the tasks of feature selection and instance selection in isolation, the potential of this theory for its application to tasks for the simultaneous selection of both features and instances has not been investigated thus far. This paper proposes a novel method for simultaneous instance and feature selection based on fuzzy-rough sets. The initial experimentation demonstrates that the method can significantly reduce both the number of instances and features whilst maintaining high classification accuracies.},
keywords={fuzzy set theory;rough set theory;computationally efficient techniques;fuzzy-rough bireducts;fuzzy-rough set theory;simultaneous feature-instance selection;Approximation methods;Computer science;Information systems;Rough sets;Training;Uncertainty;discernibility;feature selection;fuzzy-rough sets;instance selection},
doi={10.1109/FUZZ-IEEE.2013.6622500},
ISSN={1098-7584},}



%:%%%%%%%%%%%%  MATHEMATICAL MORPHOLOGY

@article{ins:morph2019,
title = "L-fuzzy relational mathematical morphology based on adjoint triples",
journal = "Information Sciences",
volume = "474",
pages = "75 - 89",
year = "2019",
issn = "0020-0255",
doi = "https://doi.org/10.1016/j.ins.2018.09.028",
url = "http://www.sciencedirect.com/science/article/pii/S002002551830728X",
author = "Nicol\'as Madrid and Manuel Ojeda-Aciego and Jes\'us Medina and Irina Perfilieva",
keywords = "Fuzzy mathematical morphology, Algebraic mathematical morphology, Fuzzy sets, Adjoint triples",
abstract = "We propose an alternative to the standard structure of L-fuzzy Mathematical Morphology (MM) by, on the one hand, considering L-fuzzy relations as structuring elements and, on the other hand, by using adjoint triples to handle membership values. Those modifications lead to a framework based on set-theoretical operations where we can prove a representation theorem for algebraic morphological erosions and dilations. In addition, we also present some new results concerning duality and transformation invariance. Concerning duality, we show that duality and adjointness can coexist in this L-fuzzy relational MM. Concerning transformation invariance, we show sufficient conditions to guarantee the invariance of morphological operators under arbitrary transformations."
}


@Inbook{bibiloni2016,
author="Bibiloni, P.
and Gonz{\'a}lez-Hidalgo, M.
and Massanet, S.
and Mir, A.
and Ruiz-Aguilera, D.",
editor="Calvo S{\'a}nchez, Tomasa
and Torrens Sastre, Joan",
title="Mayor-Torrens t-norms in the Fuzzy Mathematical Morphology and Their Applications",
bookTitle="Fuzzy Logic and Information Fusion: To commemorate the 70th birthday of Professor Gaspar Mayor",
year="2016",
publisher="Springer International Publishing",
address="Cham",
pages="201--235",
isbn="978-3-319-30421-2",
doi="10.1007/978-3-319-30421-2_13",
url="http://dx.doi.org/10.1007/978-3-319-30421-2_13"
}



@Inbook{gonzalez2015,
author="Gonz{\'a}lez-Hidalgo, Manuel
and Massanet, Sebastia
and Mir, Arnau
and Ruiz-Aguilera, Daniel",
editor="Rojas, Ignacio
and Joya, Gonzalo
and Catala, Andreu",
title="On the Generalization of the Uninorm Morphological Gradient",
bookTitle="Advances in Computational Intelligence: 13th International Work-Conference on Artificial Neural Networks, IWANN 2015, Palma de Mallorca, Spain, June 10-12, 2015. Proceedings, Part II",
year="2015",
publisher="Springer International Publishing",
address="Cham",
pages="436--449",
isbn="978-3-319-19222-2",
doi="10.1007/978-3-319-19222-2_37",
url="http://dx.doi.org/10.1007/978-3-319-19222-2_37"
}



@proceeding{nikhil2004,
author = {Gupta, Nikhil and Sinha, Purnendu},
title = {{FPGA} implementation of fuzzy morphological filters},
journal = {Proc. SPIE},
volume = {5297},
pages = {220-230},
abstract = {In this paper, we consider a natural paradigm for lifting of crisp-set binary filters to fuzzy filters for hardware implementation and process the gray-scale realizations of binary images as [0,1]-valued fuzzy binary images. We present the implementation of the filtering algorithms for smoothing, peak detection and edge detection of such fuzzy images using the Xilinx Virtex series of FPGA for real-time processing of image sequences. The erosion filter forms the core for all of the filtering algorithms and the dilation filter itself is implemented as a function of the erosion filter. Smoothing is achieved using fuzzy opening of the input image using the user defined fuzzy structuring element. A fuzzy top-hat transform is used for peak detection. As opposed to gray-scale top-hat, which detects only the narrow peaks, the fuzzy top-hat is shown to detect both the narrow as well as wide peaks within the same image. Edge detection algorithm uses the fuzzy morphological gradient wherein the set minus operation has been performed between the dilated and the eroded images. Pipelined architectures are used for the erosion filter design and the use of flops has been maximized to achieve a high clock rate. The throughput measurements and the results generated by the implemented filters are also presented.},
year = {2004},
doi = {10.1117/12.526316},
URL = { http://dx.doi.org/10.1117/12.526316},
eprint = {}
}



@article{baczinski2008,
author = "Micha{\l} Baczy\'nski and Balasubramaniam Jayaram",
title = "({S},{N})- and {R}-implications: A state-of-the-art survey",
journal = "Fuzzy Sets and Systems",
volume = "159",
number = "14",
pages = "1836 - 1859",
year = "2008",
issn = "0165-0114",
doi = "http://dx.doi.org/10.1016/j.fss.2007.11.015",
keywords = "Fuzzy implication",
keywords = "-implication",
keywords = "-implication",
keywords = "-implication",
abstract = "In this work we give a state-of-the-art review of two of the most established classes of fuzzy implications, viz., (S,N)- and R-implications. Firstly, we discuss their properties, characterizations and representations. Many new results concerning fuzzy negations and (S,N)-implications, notably their characterizations with respect to the identity principle and ordering property, are presented, which give rise to some representation results. Finally, using the presented facts, an almost complete characterization of the intersections that exist among some subfamilies of (S,N)- and R-implications are obtained."
}


@Article{Caponetti2014,
author="Caponetti, Laura
and Castellano, Giovanna
and Basile, M. Teresa
and Corsini, Vito",
title="Fuzzy mathematical morphology for biological image segmentation",
journal="Applied Intelligence",
year="2014",
volume="41",
number="1",
pages="117--127",
abstract="Due to the imaging devices, real-world images such as biological images may have poor contrast and be corrupted by noise, so that regions in the images present soft edges and their segmentation turns out to be quite difficult. Fuzzy mathematical morphology can be successfully applied to segment biological images having such characteristics of vagueness and imprecision. In this work we introduce an approach based on fuzzy mathematical morphology to segment images of human oocytes in order to extract the oocyte region from the entire image. The approach applies fuzzy morphological operators to detect soft edges in the oocyte images, followed by morphological reconstruction operators to isolate the oocyte region. The main concepts from fuzzy mathematical morphology are briefly introduced and the results of applying fuzzy morphological operators are reported in low-contrast images of human oocytes.",
issn="1573-7497",
doi="10.1007/s10489-013-0509-6",
url="http://dx.doi.org/10.1007/s10489-013-0509-6"
}



@article{sussner11,
  author    = {Peter Sussner and
               Estev{\~{a}}o Laureano Esmi},
  title     = {Morphological perceptrons with competitive learning: Lattice-theoretical
               framework and constructive learning algorithm},
  journal   = {Information Sciences},
  volume    = {181},
  number    = {10},
  pages     = {1929--1950},
  year      = {2011},
  url       = {http://dx.doi.org/10.1016/j.ins.2010.03.016},
  doi       = {10.1016/j.ins.2010.03.016},
  timestamp = {Mon, 04 Apr 2011 09:02:39 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/isci/SussnerE11},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@Article{Sussner2012,
author="Sussner, Peter
and Nachtegael, Mike
and M{\'e}lange, Tom
and Deschrijver, Glad
and Esmi, Estev{\~a}o
and Kerre, Etienne",
title="Interval-Valued and Intuitionistic Fuzzy Mathematical Morphologies as Special Cases of {L}-Fuzzy Mathematical Morphology",
journal="Journal of Mathematical Imaging and Vision",
year="2012",
volume="43",
number="1",
pages="50--71",
abstract="Mathematical morphology (MM) offers a wide range of tools for image processing and computer vision. MM was originally conceived for the processing of binary images and later extended to gray-scale morphology. Extensions of classical binary morphology to gray-scale morphology include approaches based on fuzzy set theory that give rise to fuzzy mathematical morphology (FMM). From a mathematical point of view, FMM relies on the fact that the class of all fuzzy sets over a certain universe forms a complete lattice. Recall that complete lattices provide for the most general framework in which MM can be conducted.",
issn="1573-7683",
doi="10.1007/s10851-011-0283-1",
url="http://dx.doi.org/10.1007/s10851-011-0283-1"
}

@article{Sussner16,
  author    = {Peter Sussner},
  title     = {Lattice fuzzy transforms from the perspective of mathematical morphology},
  journal   = {Fuzzy Sets and Systems},
  volume    = {288},
  pages     = {115--128},
  year      = {2016},
  url       = {http://dx.doi.org/10.1016/j.fss.2015.09.018},
  doi       = {10.1016/j.fss.2015.09.018},
  timestamp = {Wed, 10 Feb 2016 18:24:19 +0100},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/fss/Sussner16},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@article{Nachtegael2011,
title = "On the role of complete lattices in mathematical morphology: From tool to uncertainty model ",
journal = "Information Sciences ",
volume = "181",
number = "10",
pages = "1971 - 1988",
year = "2011",
issn = "0020-0255",
doi = "http://dx.doi.org/10.1016/j.ins.2010.03.009",
url = "//www.sciencedirect.com/science/article/pii/S0020025510001210",
author = "M. Nachtegael and P. Sussner and T. MÃ©lange and E.E. Kerre",
keywords = "Mathematical morphology",
keywords = "Complete lattice",
keywords = "Interval-valued fuzzy set",
keywords = "Intuitionistic fuzzy set",
keywords = "Modeling uncertainty in image processing ",
abstract = "Mathematical morphology has a rich history. Originally introduced for binary images, it was quite soon extended to grayscale images, leading to grayscale morphology with the threshold approach and the umbra approach. Later on, different models based on fuzzy set theory were introduced. These models were based on the observation that, from a formal point of view, grayscale images and fuzzy sets are modeled in the same way. Consequently, techniques from fuzzy set theory could be applied in the context of mathematical morphology, and fuzzy mathematical morphology was born. In that framework, fuzzy set theory was only a tool to construct morphological models, and was not employed to model any fuzziness or uncertainty. Quite recently however, new extensions have led to the construction of fuzzy interval-valued and fuzzy intuitionistic mathematical morphologies. Here, extensions of fuzzy set theory actually take into account the uncertainty that comes along with image capture, specifically regarding the grayscale values, which in some cases is also related to the uncertainty regarding the spatial position of an object in an image. In this framework, (extended) fuzzy set theory not only serves as a tool to deal with grayscale images, but also as a model for uncertainty. This paper sketches this evolution of fuzzy set theory in the field of mathematical morphology, and also points out some directions for future research. "
}



@article{Heijmans1990245,
title = "The algebraic basis of mathematical morphology {I. D}ilations and erosions ",
journal = "Computer Vision, Graphics, and Image Processing ",
volume = "50",
number = "3",
pages = "245 - 295",
year = "1990",
note= "",
issn = "0734-189X",
doi = "http://dx.doi.org/10.1016/0734-189X(90)90148-O",
url = "http://www.sciencedirect.com/science/article/pii/0734189X9090148O",
author = "H.J.A.M Heijmans and C Ronse",
abstract = "Mathematical morphology is a theory of image transformations and functionals deriving its tools from set theory and integral geometry. This paper deals with a general algebraic approach which both reveals the mathematical structure of morphological operations and unifies several examples into one framework. The main assumption is that the object space is a complete lattice and that the transformations of interest are invariant under a given abelian group of automorphisms on that lattice. It turns out that the basic operations called dilation and erosion are adjoints of each other in a very specific lattice sense and can be completely characterized if the automorphism group is assumed to be transitive on a sup-generating subset of the complete lattice. The abstract theory is illustrated by a large variety of examples and applications. "
}


 
@article{Alcalde:2014,
year={2014},
issn={1012-2443},
journal={Annals of Mathematics and Artificial Intelligence},
doi={10.1007/s10472-014-9397-7},
title={Application of the {L}-fuzzy concept analysis in the morphological image and signal processing},
url={http://dx.doi.org/10.1007/s10472-014-9397-7},
publisher={Springer Netherlands},
keywords={L-fuzzy concept analysis; Fuzzy mathematical morphology; Morphological image processing; 68T30; 68U10},
author    = {C. Alcalde and
               A. Burusco and
               R. Fuentes-Gonz{\'a}lez},
  volume    = {72},
  number    = {1-2},
  pages     = {115--128},
  language={English}
}

 
@article{Rivest,
  author    = {Rivest, J.F. and Soille, P. and Beucher, S.},
  title     = {Morphological gradients},
  year      = {2014},
  pages     = {326--336},
journal={Journal of Electronic Imaging},
volume ={2},
number ={4},
}

@article{Meyer,
  author    = {Meyer, F.},
  title     = {Iterative image transformations for an automatic screening of cervical smears},
  year      = {1979},
  pages     = {128--135},
journal={Journal of Histochemistry and Cytochemistry},
volume ={27},
}


@phdthesis{beucher,
	Author = {Beucher, S.},
	Title = {Segmentation d'Images et Morphologic Math\'ematique},
	School = {Ecole des Mines de Paris},
	Year = {1990}
}


@article{ijuks17:morph,
  author    = {Cristina Alcalde and
               Ana Burusco and
               Juan Carlos D{\'{\i}}az{-}Moreno and
               Jes{\'{u}}s Medina},
  title     = {Fuzzy Concept Lattices and Fuzzy Relation Equations in the Retrieval
               Processing of Images and Signals},
  journal   = {International Journal of Uncertainty, Fuzziness and Knowledge-Based
               Systems},
  volume    = {25},
  number    = {Supplement-1},
  pages     = {99--120},
  year      = {2017},
   doi       = {10.1142/s0218488517400050},
 }
 
 


@article{morphology:FSS2019,
title = "L-fuzzy relational mathematical morphology based on adjoint triples",
journal = "Information Sciences",
volume = "474",
pages = "75 - 89",
year = "2019",
issn = "0020-0255",
doi = "https://doi.org/10.1016/j.ins.2018.09.028",
url = "http://www.sciencedirect.com/science/article/pii/S002002551830728X",
author = "Nicolás Madrid and Manuel Ojeda-Aciego and Jesús Medina and Irina Perfilieva",
keywords = "Fuzzy mathematical morphology, Algebraic mathematical morphology, Fuzzy sets, Adjoint triples"
}



@article{iwann2013:morph,
  author    = {C. Alcalde and
               A. Burusco and
               J.C. D\'{\i}az-Moreno and
               R. Fuentes-Gonz{\'a}lez and
               J. Medina},
  title     = {Fuzzy Property-Oriented Concept Lattices in Morphological
               Image and Signal Processing},
  year      = {2013},
  pages     = {246-253},
journal={Lecture Notes in Computer Science},
volume ={7903},
}



@inproceedings{AlcaldeCLA2013,
  author    = {C. Alcalde and
               A. Burusco and
               J.C. D\'{\i}az and
               R. Fuentes-Gonz{\'a}lez and
               J. Medina},
  title     = {Fuzzy Property-Oriented Concept Lattices in Morphological
               Image and Signal Processing},
  booktitle = {The 10th International Conference on Concept Lattices and Their Applications (CLA 2013)},
  year      = {2013},
  pages     = {246-253},
 }


 
@article{Bloch,
  author    = {Bloch, I. and Ma\^{\i}tre, H.},
title = "Fuzzy Mathematical
Morphologies: a comparative study",
journal = "T\'{e}l\'{e}com Paris 94D001",
year = "1994",
}
 
 
 
@article{Bloch2,
  author    = {Bloch, I.},
title = "Duality vs. adjunction for fuzzy mathematical
morphology and general  form of fuzzy erosions and dilations",
journal = "Fuzzy
Sets and Systems",
volume = "160",
number = "0",
pages = "1858--1867",
year = "2009",
}
 
@article{Burillo,
  author    = {Burillo, P. and  Fuentes-Gonz\'{a}lez,  R. and Frago, N.},
title = "Inclusion
grade and fuzzy implication operators",
journal = "Fuzzy
Sets and Systems",
volume = "114",
number = "0",
pages = "417--429",
year = "2000",
}

@article{Burillo2,
  author    = {Burillo, P. and   Frago, N. and Fuentes-Gonz\'{a}lez, R.},
title = "Generation of fuzzy mathematical morphologies",
journal = "Mathware \& Soft Computing",
volume = "VIII",
number = "0",
pages = "31--46",
year = "2001",
}
 
 
 
@article{Goutsias,
  author    = {Goutsias, J. and  Heijmans, H.J.A.M.},
title = "Fundamenta Morphologicae
Mathematicae",
journal = "Fundamenta Informaticae",
volume = "41",
number = "0",
pages = "1--31",
year = "2000",
}

@book{Heijmans,
  author    = {Heijmans, H.J.A.M.},
title = "Morphological Image Operators",
publisher =  "Academic Press Inc.",
year = "1994",
}

@article{Maragos,
  author    = {Maragos, P.},
title = "Lattice Image Precessing: A Unification of Morphological and Fuzzy Algebric Systems",
journal = "Journal of Mathematical Imaging and Vision",
volume = "22",
number = "0",
pages = "333--353",
year = "2005",
}

@article{Mas,
  author    = {Mas, M. and Monserrat, M. and Torrens, J.},
title = "S-implications and
R-implications on a finite chain",
journal = "Kybernetika",
volume = "40",
number = "1",
pages = "3--20",
year = "2004",
}


@book{Mathe,
  author    = {Matheron, G.},
title = "Random Sets and Integral Geometry",
publisher = "Wiley",
year = "1975",
}


 

%\bibitem{Mathe1} Matheron, G.: El\'{e}ments pour une th\'{e}orie des
%milieux poreux. Masson, Paris (1967)

@book{Serra,
  author    = {Serra, J.},
title = "Image Analysis and Mathematical
Morphology",
publisher = "Academic Press",
year = {1990},
abstract = {I (fourth printing 1990) and II
(second printing 1992)},
}

@book{Soille,
  author    = {Soille, P.},
title = "Morphological Image Analysis. Principles and Applications",
edition = "Second",
publisher = {Springer},
year = "2004",
}
 
 


@inproceedings{AlcaldeCLA2012,
  author    = {Alcalde, C. and Burusco, A. and  Fuentes-Gonz\'alez, R.},
  title     = {An interpretation of the L-Fuzzy Concept Analysis as a tool for the Morphological Image and Signal Processing},
  booktitle = {Proc. of CLA 2012},
  year      = {2012},
  pages     = {81-92},
 }


@incollection{baets,
year={1997},
booktitle={Uncertainty Analysis, Engineering and Science: Fuzzy Logic, Statistics and neural network Approach},
editor={Ayyub, B. and  Gupta, M.},
title={Fuzzy morphology: a logical approach},
publisher={Kluwer Academic Publishers},
author={{De Baets}, B.},
pages={53--67}
}

%%%%%%%%%%%%%% GALOIS CONNECTIONS
@INPROCEEDINGS{Erne92aprimer,
    author = {M. Erné and J. Koslowski and A. Melton and G.E. Strecker},
    title = {A Primer On Galois Connections},
    booktitle = {York Academy of Science},
    year = {1992}
}


@book{erne04,
 editor = {Klaus Denecke and M. Erné and Shelly L. Wismath},
 title = {Galois Connections and Applications},
 year = {2004},
 publisher = {Kluwer Academic Publishers},
 address = {Dordrecht. The Netherlands},
}


%:%%%%%%%%%%%%% Dedekind--MacNeille completion


@article{MedinaMulti2016,
title = "On the {D}edekind{-}{M}ac{N}eille completion and formal concept analysis based on multilattices ",
journal = "Fuzzy Sets and Systems ",
volume = "303",
number = "",
pages = "1 - 20",
year = "2016",
note= "",
issn = "0165-0114",
doi = "http://dx.doi.org/10.1016/j.fss.2016.01.007",
url = "http://www.sciencedirect.com/science/article/pii/S0165011416000439",
author = "J. Medina and M. Ojeda-Aciego and J. P\'ocs and E. Ram\'i­rez-Poussa",
keywords = "Multilattices",
keywords = "Dedekind-“MacNeille completion",
keywords = "Formal concept analysis ",
abstract = "Abstract The Dedekind-MacNeille completion of a poset P can be seen as the least complete lattice containing P. In this work, we analyze some results concerning the use of this completion within the framework of Formal Concept Analysis in terms of the poset of concepts associated with a Galois connecxtion between posets. Specifically, we show an interesting property of the Dedekindâ“MacNeille completion, in that the completion of the concept poset of a Galois connection between posets coincides with the concept lattice of the Galois connection extended to the corresponding completions. Moreover, we study the specific case when P has multilattice structure and state and prove the corresponding representation theorem. "
}




@incollection{sergeimacneille98,
year={1998},
isbn={978-3-540-64791-1},
booktitle={Conceptual Structures: Theory, Tools and Applications},
volume={1453},
series={Lecture Notes in Computer Science},
editor={Mugnier, Marie-Laure and Chein, Michel},
title={Stepwise construction of the Dedekind-MacNeille completion},
abstract={http://dx.doi.org/10.1007/BFb0054922},
publisher={Springer Berlin Heidelberg},
author={Ganter, Bernhard and Kuznetsov, SergeiO.},
pages={295-302}
}




@article{macneille37,
  author    = {H. M. MacNeille},
title = "Partially ordered sets",
journal = "Transactions of the American Mathematical Society",
volume = "42",
number = "0",
pages = "416--460",
year = "1937",
}
 

%:%%%%%%%%%%%%% PATTERN STRUCTURES









@article{belfodil2020,
author = { Aimene   Belfodil  and  Sergei O.   Kuznetsov  and  Mehdi   Kaytoue },
title = {On pattern setups and pattern multistructures},
journal = {International Journal of General Systems},
volume = {49},
number = {8},
pages = {785-818},
year  = {2020},
publisher = {Taylor & Francis},
doi = {10.1080/03081079.2020.1806832},
URL = { 
        https://doi.org/10.1080/03081079.2020.1806832
},
eprint = { 
        https://doi.org/10.1080/03081079.2020.1806832
}
,
    abstract = { Order and lattice theory provides convenient mathematical tools for pattern mining, in particular for condensed irredundant representations of pattern spaces and their efficient generation. Formal Concept Analysis (FCA) offers a generic framework, called pattern structures, to formalize many types of patterns, such as itemsets, intervals, graphs, and sequence sets. Moreover, FCA provides generic algorithms to generate irredundantly all closed patterns, the only condition being that the pattern space is a meet-semilattice. This does not always hold, e.g. for sequential and graph patterns. Here, we discuss pattern setups consisting of descriptions making just a partial order. Such a framework can be too broad, causing several problems, so we propose a new model, dubbed pattern multistructures, lying between pattern setups and pattern structures, which relies on multilattices. Finally, we consider some techniques, namely completions, transforming pattern setups to pattern structures using sets/antichains of patterns. }
}





@inproceedings{kuznetsov09,
  author    = {Sergei O. Kuznetsov},
  title     = {Pattern Structures for Analyzing Complex Data},
  booktitle = {RSFDGrC},
  year      = {2009},
  pages     = {33-44},
  ee        = {http://dx.doi.org/10.1007/978-3-642-10646-0_4},
 }

@inproceedings{ganterkuznetsov01,
  author    = {Bernhard Ganter and
               Sergei O. Kuznetsov},
  title     = {Pattern Structures and Their Projections},
  booktitle = {ICCS},
  year      = {2001},
  pages     = {129-142},
  ee        = {http://dx.doi.org/10.1007/3-540-44583-8_10},
}


@incollection{Kaiser11,
year={2011},
isbn={978-3-642-21785-2},
booktitle={Pattern Recognition and Machine Intelligence},
volume={6744},
series={Lecture Notes in Computer Science},
editor={Kuznetsov, SergeiO. and Mandal, DebaP. and Kundu, MalayK. and Pal, SankarK.},
doi={10.1007/978-3-642-21786-9_9},
title={Some Remarks on the Relation between Annotated Ordered Sets and Pattern Structures},
url={http://dx.doi.org/10.1007/978-3-642-21786-9_9},
publisher={Springer Berlin Heidelberg},
author={Kaiser, TimB. and Schmidt, StefanE.},
pages={43-48}
}


%:%%%%%%%%%%%%%% FUZZY DECISION CONTEXTS



@article{Zhai2013230,
title = "Fuzzy decision implications",
journal = "Knowledge-Based Systems",
volume = "37",
number = "0",
pages = "230--236",
year = "2013",
note= "",
issn = "0950-7051",
doi = "10.1016/j.knosys.2012.08.004",
url = "http://www.sciencedirect.com/science/article/pii/S095070511200216X",
author = "Yanhui Zhai and Deyu Li and Kaishe Qu",
keywords = "Fuzzy decision implication",
keywords = "Unite closure",
keywords = "Deduction rule",
keywords = "Sound",
keywords = "Complete",
abstract = "The aim of this paper is to provide the semantical and syntactical characteristics of fuzzy decision implications, an expression concerning two systems of fuzzy-sets. This Pavelka-style fuzzy logic starts from a fuzzy set of fuzzy decision implications and makes deductions from partially true decision implications. Following this idea, in semantical aspect, we present some basic results concerning completeness and more importantly, introduce the notion of âœunite closureâ, which is in fact important not only in semantical aspect but also in syntactical aspect. Besides, we derive three deduction rules, namely (F-Transformation), (F-Add) and (F-Shâ†‘) for syntactical aspect of fuzzy decision implications, which are proved to be sound and complete with respect to semantical aspect. The result ensures that one can obtain a closed fuzzy set of fuzzy decision implications by the semantical way or by the syntactical way, i.e., by the three deduction rules."
}





%:%%%%%%%%%% BIPARTITE GRAPH AND FCA

@incollection{bipartitePrade2010,
year={2010},
isbn={978-3-642-14048-8},
booktitle={Computational Intelligence for Knowledge-Based Systems Design},
volume={6178},
series={Lecture Notes in Computer Science},
editor={Hallermeier, Eyke and Kruse, Rudolf and Hoffmann, Frank},
doi={10.1007/978-3-642-14049-5_28},
title={A Parallel between Extended Formal Concept Analysis and Bipartite Graphs Analysis},
url={http://dx.doi.org/10.1007/978-3-642-14049-5_28},
publisher={Springer Berlin Heidelberg},
keywords={Formal concept analysis (FCA); bipartite graph},
author={Gaume, Bruno and Navarro, Emmanuel and Prade, Henri},
pages={270-280}
}



%:%%%%%%%%%%%% Ontology

@article{Kang2012,
title = "Research on domain ontology in different granulations based on concept lattice ",
journal = "Knowledge-Based Systems ",
volume = "27",
number = "0",
pages = "152--161",
year = "2012",
note= "",
issn = "0950-7051",
doi = "http://dx.doi.org/10.1016/j.knosys.2011.09.016",
url = "http://www.sciencedirect.com/science/article/pii/S0950705111002176",
author = "Xiangping Kang and Deyu Li and Suge Wang",
keywords = "Concept lattice",
keywords = "Granular computing",
keywords = "Ontology building",
keywords = "Ontology merging",
keywords = "Ontology connection "
}


@article{formica:2006,
	Author = {Formica, Anna},
	Date-Added = {2008-12-29 09:56:00 +0100},
	Date-Modified = {2008-12-29 09:57:04 +0100},
	Journal = {Information Sciences},
	Keywords = {Formal Concept Analysis; Semantic Web; Domain ontologies; Similarity reasoning},
	Number = {18},
	Pages = {2624-2641},
	Title = {Ontology-based concept similarity in Formal Concept Analysis},
	Volume = {176},
	Year = {2006},
	Abstract = {Both domain ontologies and Formal Concept Analysis (FCA) aim at modeling concepts, although with different purposes. In the literature, a promising research area concerns the role of FCA in ontology engineering, in particular, in supporting the critical task of reusing independently developed domain ontologies. With this regard, the possibility of evaluating concept similarity is acquiring an increasing relevance, since it allows the identification of different concepts that are semantically close. In this paper, an ontology-based method for assessing similarity between FCA concepts is proposed. Such a method is intended to support the ontology engineer in difficult activities that are becoming fundamental in the development of the Semantic Web, such us ontology merging and ontology mapping and, in particular, it can be used in parallel to existing semi-automatic tools relying on FCA.},
	Bdsk-Url-1 = {http://dx.doi.org/10.1016/j.ins.2005.11.014}}


%:%%%%%%%%% DESCRIPTION LOGIC DIRK WALTHER

@inproceedings{Konev-etal-2008,
 author = {Konev, Boris and Lutz, Carsten and Walther, Dirk and Wolter, Frank},
 title = {Semantic Modularity and Module Extraction in Description Logics},
 booktitle = {Proceedings of {ECAI'08}: the 18th European Conference on Artificial Intelligence},
 year = {2008},
 pages = {55--59},
 publisher = {IOS Press},
 address = {Amsterdam, The Netherlands},
} 

@article{Calvanese-etal-2007,
 author = {Calvanese, Diego and Giacomo, Giuseppe and Lembo, 
           Domenico and Lenzerini, Maurizio and Rosati, Riccardo},
 title = {Tractable Reasoning and Efficient Query Answering in 
          Description Logics: The {DL-Lite} Family},
 journal = {Journal of Automated Reasoning},
 volume = {39},
 issue = {3},
 year = {2007},
 pages = {385--429},
 publisher = {Springer-Verlag New York, Inc.},
 address = {Secaucus, NJ, USA},
} 

@InProceedings{Baader-Brandt-Lutz-2005,
  author =  {F. Baader and S. Brandt and C. Lutz},
  title =    {Pushing the {EL} Envelope},
  booktitle =  {Proceedings of  {IJCAI-05}: the 19th International Joint Conference on Artificial Intelligence},
  year =  {2005},
  address =  {Edinburgh, UK},
  publisher = {Morgan-Kaufmann Publishers},
}

@InProceedings{Baader-Brandt-Lutz-2008,
  title =  {Pushing the {EL} Envelope Further},
  author = {Franz Baader and Sebastian Brandt and Carsten Lutz},
  booktitle =  {Proceedings of the OWLED 2008 DC Workshop on OWL: Experiences and Directions},
  year =  {2008},
  editor = {Kendall Clark and Peter F. Patel-Schneider},
}

@incollection{Minsky-1975,
  address = {London},
  author = {Minsky, Marvin},
  booktitle = {{The Psychology of Computer Vision}},
  description = {The big one},
  editor = {Winston, P. H.},
  pages = {211--277},
  publisher = {McGraw-Hill},
  title = {{A Framework for Representing Knowledge}},
  year = 1975
}

@incollection{Quillian-1968,
  author = {Quillian, Ross},
  booktitle = {Semantic Information Processing},
  pages = {216--270},
  publisher = {MIT Press},
  title = {Semantic Memory},
  year = 1968
}

@incollection{Hayes-1979,
  added-at = {2008-11-17T22:58:57.000+0100},
  address = {Berlin, Germany},
  author = {Hayes, P. J.},
  booktitle = {Frame Conceptions and Text Understanding},
  editor = {Metzing, D.},
  pages = {46--61},
  publisher = {Walter de Gruyter and Co.},
  title = {The Logic of Frames},
  year = 1979
}

@ARTICLE{Woods-Schmolze-1992,
  AUTHOR = {William A. Woods and James G. Schmolze},
  JOURNAL = {Computer and Mathematics with Applications, special
                  issue: Semantic Networks in Artificial Intelligence},
  NUMBER = {2--5},
  PAGES = {133--177},
  PUBLISHER = {Pergamon Press},
  TITLE = {The {KL-ONE} Family},
  VOLUME = {23},
  YEAR = {1992}
}

@book{Baader-etal-DL-Handbook-2007,
 editor = {Baader, Franz and Calvanese, Diego and McGuinness, Deborah L. and Nardi, Daniele and Patel-Schneider, Peter F.},
 title = {The description logic handbook: theory, implementation, and applications, 2nd edition},
 year = {2007},
 publisher = {Cambridge University Press},
 address = {New York, NY, USA},
}

@article{Motik-Rosati-2010,
  author    = {Boris Motik and
               Riccardo Rosati},
  title     = {Reconciling description logics and rules},
  journal   = {Journal of the ACM},
  volume    = {57},
  number    = {5},
  year      = {2010},
  publisher = {ACM},
  address = {New York, NY, USA},
}

@article{Bonatti-Lutz-Wolter-2009,
 author = {Bonatti, Piero A. and Lutz, Carsten and Wolter, Frank},
 title = {The complexity of circumscription in description logic},
 journal = {Journal of Artificial Intelligence Research},
 volume = {35},
 issue = {1},
 year = {2009},
 pages = {717--773},
 numpages = {57},
 publisher = {AI Access Foundation},
 address = {USA},
} 

@article{Konev-Ludwig-Walther-Wolter-2012,
 author = {Boris Konev and Michel Ludwig and Dirk Walther and Frank Wolter},
 title = {The Logical Diff for the Lightweight Description Logic {EL}},
 journal = {Journal of Artificial Intelligence Research},
 year = {2012},
 publisher = {AI Access Foundation},
 address = {USA}
} 

@inproceedings{Konev-Walther-Wolter-2009,
 author = {Konev, Boris and Walther, Dirk and Wolter, Frank},
 title = {Forgetting and uniform interpolation in large-scale description logic terminologies},
 booktitle = {Proceedings of {IJCAI'09}: the 21st International Joint Conference on Artifical Intelligence},
 series = {IJCAI'09},
 year = {2009},
 location = {Pasadena, California, USA},
 pages = {830--835},
 numpages = {6},
 acmid = {1661577},
 publisher = {Morgan Kaufmann Publishers Inc.},
 address = {San Francisco, CA, USA},
} 

@inproceedings{Konev-Walther-Wolter-2008,
 author = {Konev, Boris and Walther, Dirk and Wolter, Frank},
 title = {The Logical Difference Problem for Description Logic Terminologies},
 booktitle = {Proceedings of {IJCAR'08}: the 4th international joint conference on Automated Reasoning},
 series = {IJCAR'08},
 year = {2008},
 isbn = {978-3-540-71069-1},
 location = {Sydney, Australia},
 pages = {259--274},
 numpages = {16},
 url = {http://dx.doi.org/10.1007/978-3-540-71070-7_21},
 doi = {http://dx.doi.org/10.1007/978-3-540-71070-7_21},
 acmid = {1431137},
 publisher = {Springer-Verlag},
 address = {Berlin, Heidelberg},
} 

@inproceedings{Kremen-Smid-Kouba-DEXA2011,
author = {Petr Kremen and Marek Smid and Zdenek Kouba},
title = {OWLDiff: A Practical Tool for Comparison and Merge of OWL Ontologies},
booktitle={Proceedings of {DEXA'11}: International Workshops on Database and Expert Systems Applications},
location={Toulouse, France},
year = {2011},
pages = {229--233},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
}

@inproceedings{Konev-Lutz-Walther-Wolter-2008,
 author = {Konev, Boris and Lutz, Carsten and Walther, Dirk and Wolter, Frank},
 title = {Semantic Modularity and Module Extraction in Description Logics},
 booktitle = {Proceedings of {ECAI'08}: 18th European Conference on Artificial Intelligence},
 year = {2008},
 pages = {55--59},
 publisher = {IOS Press},
 address = {Amsterdam, The Netherlands},
} 

@InProceedings{Lutz-Walther-Wolter-2007,
  author = 	 {Carsten Lutz and Dirk Walther and Frank Wolter},
  title = 	 {Conservative Extensions in Expressive Description Logics},
  booktitle = 	 {Proceedings of {IJCAI'07}: the 20th International Joint Conference on Artificial Intelligence},
  location = {Hyderabad, India},
  year = 	 2007,
  pages =        {453--458},
  publisher = {AAAI Press},
 }

@InProceedings{Lutz-Wolter-IJCAI11,
  author =  {C. Lutz and F. Wolter},
  title =    {Foundations for Uniform Interpolation and Forgetting in Expressive Description Logics},
  booktitle =  {Proceedings of {IJCAI'11}: the 22nd International Joint Conference on Artificial Intelligence},
  year =  {2011},
  publisher = {AAAI Press},
}

@InProceedings{Konev-Walther-Wolter-DL2009,
    author = {Boris Konev and Dirk Walther and Frank Wolter},
    title = {Forgetting and uniform interpolation in extensions of the description logic EL},
    booktitle={Proceedings of {DL'09}: the 22nd International Workshop on Description Logics},
    location={Oxford, United Kingdom},
    year = {2009},
    publisher={CEUR-WS.org},
}

@InProceedings{Pokrywczynski-Walther-WORM2008,
    author = {Daniel Pokrywczynski and Dirk Walther},
    title = {Deciding the logical difference problem for EL with role inclusions},
    booktitle={Proceedings of {WORM'08}: International Workshop on Ontologies--Reasoning and Modularity},
    location={Tenerife, Spain},
    volume={348},
    year = {2008},
    publisher={CEUR-WS.org},
}

@article{Levesque-1984,
 author = {Levesque, Hector J.},
 title = {Foundations of a functional approach to knowledge representation.},
 journal = {Artificial Intelligence},
 volume = {23},
 issue = {2},
 year = {1984},
 pages = {155--212},
 numpages = {58},
 publisher = {Elsevier Science Publishers Ltd.},
 address = {Essex, UK},
} 

@inproceedings{Horrocks-Kutz-Sattler-KR2006,
  author = {Horrocks, Ian and Kutz, Oliver and Sattler, Ulrike},
  title = {The Even More Irresistible SROIQ},
  booktitle = {Proceedings of {KR'06}: the 10th Conference on Principles of Knowledge Representation and Reasoning},
  editor = {Doherty, Patrick and Mylopoulos, John and Welty, Christopher A.},
  pages = {57--67},
  publisher = {AAAI Press},
  year = 2006
}

@techreport{Schneider-Hayes-Horrocks-W3C2004,
  author = {Patel-Schneider, Peter F. and Hayes, Patrick and Horrocks, Ian},
  title = {{OWL} Web Ontology Language: Semantics and Abstract Syntax},
  institution={W3C Recommendation},
  month={February},
  year = 2004
}

@techreport{W3C-TR-OWL2,
  author={Conrad Bock and Achille Fokoue and Peter Haase and Rinke Hoekstra and Ian Horrocks and Alan Ruttenberg and Ulrike Sattler and Michael Smith},
  editor={Boris Motik and Peter F. Patel-Schneider and Bijan Parsia},
  title = {{OWL 2} Web Ontology Language: Structural Specification and Functional-Style Syntax},
  institution={W3C Recommendation},
  month={October},
  year = 2009
}

@article{Grau-Motik-Parsia-Schneider-Sattler-2008,
 author = {Grau, Bernardo Cuenca and Horrocks, Ian and Motik, Boris and Parsia, Bijan and Patel-Schneider, Peter and Sattler, Ulrike},
 title = {OWL 2: The next step for OWL},
 journal = {Web Semantics: Science, Services and Agents on the World Wide Web},
 volume = {6},
 issue = {4},
 month = {November},
 year = {2008},
 pages = {309--322},
 numpages = {14},
 publisher = {Elsevier Science Publishers B. V.},
 address = {Amsterdam, The Netherlands, The Netherlands},
} 

I. Horrocks and H. Graves. Application of OWL 1.1 to Systems Engineering. In
K. Clark and P. F. Patel-Schneider, editors, Proc. of the OWL: Expreiences and
Directions Workshop (OWLED 2008 DC), Washington, DC, USA, April 1Ð2 2008.

@inproceedings{Horrocks-Graves-2008, 
author = {Ian Horrocks and Henson Graves}, 
editor = {K. Clark and P. F. Patel-Schneider},
title = {Application of OWL 1.1 to Systems Engineering}, 
booktitle = {Proceedings of {OWLED'08}: the Experiences and Directions Workshop}, 
year = {2008},
}

@article{Konyk-DeLeon-Dumontier-2008,
   author = {Konyk, Mykola and De Leon, Alexander and Dumontier, Michel},
   title = {Chemical Knowledge for the Semantic Web},
journal = {Lecture Notes in Computer Science},
   pages = {169--176},
   volume = {5109},
   year = {2008}
}

@inproceedings{Goderis-Sattler-Goble-2005,
  author    = {Antoon Goderis and
               Ulrike Sattler and
               Carole A. Goble},
  title     = {Applying Description Logics for Workflow Reuse and Repurposing},
  booktitle = {Proceedings of {DL'05}: International Workshop on Description Logics},
  editor    = {Ian Horrocks and
               Ulrike Sattler and
               Frank Wolter},
  publisher = {CEUR-WS.org},
  series    = {CEUR Workshop Proceedings},
  volume    = {147},
  year      = {2005},
}

@article{Grau-Horrocks-Kazakov-Sattler-2008,
  title = "Modular Reuse of Ontologies: Theory and Practice",
  author = "Bernardo {Cuenca Grau} and Ian Horrocks and Yevgeny Kazakov and Ulrike Sattler",
  year = "2008",
  journal = "Journal of Artificial Intelligence Research",
  pages = "273--318",
  volume = "31",
}



%:%%%%%%%%%  De Juan Moreno y demás
@phdthesis{LuisRodriguez:2008,
  AUTHOR = {Luis Rodr\'­iguez Ben\'itez},
  TITLE = {Razonamiento aproximado aplicado al reconocimiento de acciones sobre la se\~nal de v\'ideo comprimido},
  School= {Universidad de Castilla-La Mancha},
  YEAR = {2008},
}

@phdthesis{CayetanoSolana:2011,
  AUTHOR = {Cayetano Solana Ciprés},
  TITLE = {Arquitectura adaptativa para la segmentación de objetos en secuencias de vídeo H.264/AVC},
  School= {Universidad de Castilla-La Mancha},
  YEAR = {2011},
}

@article{Rodriguez-Benitez:2011,
 author = {Rodr\'iguez-Ben\'itez, L. and Solana-Cipr\'es, C. and Moreno-Garc\'ia, J. and Jim\'enez-Linares, L.},
 title = {Approximate reasoning and finite state machines to the detection of actions in video sequences},
 journal = {Int. J. Approx. Reasoning},
 issue_date = {June, 2011},
 volume = {52},
 issue = {4},
 month = {June},
 year = {2011},
 issn = {0888-613X},
 pages = {526--540},
 numpages = {15},
 url = {http://dx.doi.org/10.1016/j.ijar.2010.12.003},
 doi = {http://dx.doi.org/10.1016/j.ijar.2010.12.003},
 acmid = {1945400},
 publisher = {Elsevier Science Inc.},
 address = {New York, NY, USA},
 keywords = {Action recognition, Approximate reasoning, Video analysis},
}

@article{MorenoGarcia2010318,
title = "Video sequence motion tracking by fuzzification techniques",
journal = "Applied Soft Computing",
volume = "10",
number = "1",
pages = "318--331",
year = "2010",
note= "",
issn = "1568-4946",
doi = "10.1016/j.asoc.2009.08.002",
url = "http://www.sciencedirect.com/science/article/pii/S1568494609001185",
author = "Juan Moreno-Garc\'ia and Luis Rodr\'iguez-Ben\'itez and Antonio Fern\'andez-Caballero and Mar\'ia T. L\'opez",
keywords = "Fuzzy sets",
keywords = "Permanency values",
keywords = "Motion analysis",
keywords = "Segmentation",
keywords = "Tracking"
}

@article{Vallejo:2009,
 author = {Vallejo, David and Albusac, Javier and Jim\'enez, Luis and Gonz\'alez, Carlos and Moreno, Juan},
 title = {A cognitive surveillance system for detecting incorrect traffic behaviors},
 journal = {Expert Syst. Appl.},
 volume = {36},
 issue = {7},
 month = {September},
 year = {2009},
 issn = {0957-4174},
 pages = {10503--10511},
 numpages = {9},
 url = {http://dl.acm.org/citation.cfm?id=1539049.1539493},
 doi = {10.1016/j.eswa.2009.01.034},
 acmid = {1539493},
 publisher = {Pergamon Press, Inc.},
 address = {Tarrytown, NY, USA},
 keywords = {Intelligent surveillance, Multi-agent systems, Ontology design},
} 

@article{Rodriguez-Benitez:2009,
 author = {Rodr\'iguez-Ben\'itez, L. and Moreno-Garc\'ia, J. and Castro-S\'anchez, J. J. and Albusac, J. and Jim\'enez-Linares, L.},
 title = {Automatic objects behaviour recognition from compressed video domain},
 journal = {Image Vision Comput.},
 volume = {27},
 issue = {6},
 month = {May},
 year = {2009},
 issn = {0262-8856},
 pages = {648--657},
 numpages = {10},
 url = {http://dl.acm.org/citation.cfm?id=1523527.1523945},
 doi = {10.1016/j.imavis.2008.07.002},
 acmid = {1523945},
 publisher = {Butterworth-Heinemann},
 address = {Newton, MA, USA},
 keywords = {Behaviour models, Fuzzy logic, Linguistic labels, MPEG compressed video, Vehicles tracking},
} 

@article{Solana-Cipres:2009,
 author = {Solana-Cipr\'es, C. and Fern\'andez-Escribano, G. and Rodr\'iguez-Ben\'itez, L. and Moreno-Garc\'ia, J. and Jim\'enez-Linares, L.},
 title = {Real-time moving object segmentation in H.264 compressed domain based on approximate reasoning},
 journal = {Int. J. Approx. Reasoning},
 volume = {51},
 issue = {1},
 month = {December},
 year = {2009},
 issn = {0888-613X},
 pages = {99--114},
 numpages = {16},
 url = {http://dl.acm.org/citation.cfm?id=1655427.1655722},
 doi = {10.1016/j.ijar.2009.09.002},
 acmid = {1655722},
 publisher = {Elsevier Science Inc.},
 address = {New York, NY, USA},
 keywords = {Approximate reasoning, Compressed video segmentation, Dynamic fuzzy sets, H.264 advanced video coding, Moving object detection},
} 

@article{AlbusacVLCB09,
  author    = {Javier Albusac and
               David Vallejo and
               Luis Jim\'enez Linares and
               Jose Jesus C\'astro-Schez and
               Luis Rodr\'iguez Ben\'itez},
  title     = {Intelligent Surveillance Based on Normality Analysis to
               Detect Abnormal Behaviors},
  journal   = {IJPRAI},
  volume    = {23},
  number    = {7},
  year      = {2009},
  pages     = {1223-1244},
  ee        = {http://dx.doi.org/10.1142/S0218001409007612},
  bibsource = {DBLP, http://dblp.uni-trier.de}
}





%:%%%%%%%%% Para revisión FSS-hererog..

@inproceedings{valverdeK11,
  author    = {Jos{\'e} Mar\'{\i}a Gonz{\'a}lez Calabozo and
               Carmen Pel{\'a}ez-Moreno and
               Francisco J. Valverde-Albacete},
  title     = {Gene Expression Array Exploration Using $\mathcal\{K\}$-Formal
               Concept Analysis},
  booktitle = {ICFCA},
  year      = {2011},
  pages     = {119-134},
}

@article{valverdeINS11,
  author    = {Francisco J. Valverde-Albacete and
               Carmen Pel{\'a}ez-Moreno},
  title     = {Extending conceptualisation modes for generalised Formal
               Concept Analysis},
  journal   = {Inf. Sci.},
  volume    = {181},
  number    = {10},
  year      = {2011},
  pages     = {1888-1909},
  ee        = {http://dx.doi.org/10.1016/j.ins.2010.04.014},
  bibsource = {DBLP, http://dblp.uni-trier.de}
}


@inproceedings{BelohlavekA05,
	author = {R. B{\v e}lohl{\'a}vek and V. Vychodil},
 	Title = {Reducing the size of fuzzy concept lattices by hedges},
         Booktitle     = {The 2005 IEEE International Conference on Fuzzy Systems},
         year      = {2005},
        pages = {663--668},
	}
	


@inproceedings{BelohlavekB05,
	author = {R. B{\v e}lohl{\'a}vek  and  T. Funiokova  and V. Vychodil },
 	Title = {Galois connections with hedges},
         Booktitle     = {Proc. IFSA 2005 World Congress},
         year      = {2005},
volume = {II},
        publisher = {Springer},
        pages = {1250--1255},
	}


 

%:%%%%%%%%%%%%% de forest- rst2011


@inproceedings{Cerro:1986,
	author = {L. {Fari{\~n}as del Cerro} and H.\ Prade},
       editor    = {A. Di Nola and A.G.S. Ventre},
	Title = {Rough sets, twofold fuzzy sets and modal logic---Fuzziness in indiscernibility and partial information},
       Booktitle     = {The Mathematics of Fuzzy Systems},
      publisher = {Verlag TUV Rheinland},
      year      = {1986},
      pages = {103--120},
	}

@article{Morsi:1998,
author = {N. N.\ Morsi and  M. M.\ Yakout},
title = {Axiomatics for fuzzy rough sets},
journal = {Fuzzy sets and Systems},
volume = {100},
 pages = {327--342},
year = {1998},
}

 
@article{Nakamura:1988,
author = {A.\ Nakamura},
title = {Fuzzy rough sets},
journal = {Note on Multiple-Valued Logic in Japan},
volume = {9},
 pages = {1--8},
year = {1988},
}

	
@article{Nanda:1992,
author = {S.\ Nanda and S.\ Majumdar},
title = {Fuzzy rough sets},
journal = {Fuzzy sets and Systems},
volume = {45},
 pages = {157--160},
year = {1992},
}
 

%:%%%%% propios 2016-2019  Concept Lattices


@article{ins2018:cmr,
title = "Characterizing reducts in multi-adjoint concept lattices",
journal = "Information Sciences",
volume = "422",
pages = "364 - 376",
year = "2018",
issn = "0020-0255",
doi = "https://doi.org/10.1016/j.ins.2017.08.099",
url = "http://www.sciencedirect.com/science/article/pii/S0020025517302943",
author = "M. Eugenia Cornejo and Jes\'us Medina and Elo\'isa Ram\'irez-Poussa",
keywords = "Formal concept analysis, Reducts, Attribute reduction"
}

%:%%%%% propios 2009-2015  Concept Lattices


@article{knosys15:cmr,
title = "On the use of irreducible elements for reducing multi-adjoint concept lattices",
 author = {Cornejo, Maria Eugenia and Medina, Jes\'{u}s and Ram\'{\i}rez-Poussa, Eloisa},
journal = "Knowledge-Based Systems",
volume = "89",
pages = "192--202",
year = "2015",
doi = "DOI: 10.1016/j.knosys.2015.07.003",
}



@article{jrs2014:cmr,
title = "Fuzzy-attributes and a method to reduce concept lattices",
 author = {Cornejo, Maria Eugenia and Medina, Jes\'{u}s and Ram\'{\i}rez-Poussa, Eloisa},
journal = "Lecture Notes in Computer Science",
volume = "8536",
number = "0",
pages = "189 - 200",
year = "2014",
}

@article{ar:ins:2015,
title = "Attribute reduction in multi-adjoint concept lattices ",
journal = "Information Sciences ",
volume = "294",
pages = "41--56",
year = "2015",
note= "",
issn = "0020-0255",
doi = "http://dx.doi.org/10.1016/j.ins.2014.09.033",
url = "http://www.sciencedirect.com/science/article/pii/S0020025514009451",
 author = {Cornejo, Maria Eugenia and Medina, Jes\'{u}s and Ram\'{\i}rez-Poussa, Eloisa},
keywords = "Concept lattice theory",
keywords = "Irreducible element",
keywords = "Attribute reduction ",
abstract = "Abstract Knowledge reduction is one of the key issues in formal concept analysis and there have been many studies on this topic. The irreducible elements in a lattice are also very important, since they form the basic information of a relational system. Moreover, they are also important from the viewpoint of attribute reduction. Both topics are notably more complicated in a fuzzy setting since not only the size of the sets of attributes and objects influence the size of the fuzzy concept lattice, but the truth-value sets, where the sets of objects, attributes and the relation are evaluated, are important. This paper presents, in the general fuzzy framework of multi-adjoint concept lattices, a characterization of the meet-irreducible elements, from which a classification of attributes and its application to attribute reduction is introduced. "
}

@article{dual:mo2013,
title = "Dual multi-adjoint concept lattices ",
journal = "Information Sciences ",
volume = "225",
number = "0",
pages = "47--54",
year = "2013",
note= "",
issn = "0020-0255",
doi = "http://dx.doi.org/10.1016/j.ins.2012.10.030",
url = "http://www.sciencedirect.com/science/article/pii/S0020025512007001",
author = "J. Medina and M. Ojeda-Aciego",
keywords = "Concept lattices",
keywords = "Galois connection",
keywords = "Implication triples",
keywords = "Dual concept lattices "
}



@inproceedings{cmmse16Implications,
 author = {Cornejo, Maria Eugenia and Medina, Jes\'{u}s and Ram\'{\i}rez-Poussa, Eloisa},
	Booktitle = {International Conference on Computational and Mathematical Methods in Science and Engineering, CMMSE 2016},
	Volume ={II},
	Pages = {414--423},
	Title = {Computing the validity of attribute implications in multi-adjoint concept lattices},
	Year = {2016}}


	
@inproceedings{eusflat13:cmr,
 author = {Cornejo, Maria Eugenia and Medina, Jes\'{u}s and Ram\'{\i}rez-Poussa, Eloisa},
	Booktitle = {Intl Conference on Fuzzy Logic and Technology, EUSFLAT 2013},
	Pages = {125--131},
	Title = {Irreducible elements in multi-adjoint concept lattices},
	Year = {2013}}


@article{iwann13:cmr,
 author = {Cornejo, Maria Eugenia and Medina, Jes\'{u}s and Ram\'{\i}rez-Poussa, Eloisa},
 title = {On the Classification of Fuzzy-attributes in Multi-adjoint Concept Lattices},
journal = {Lecture Notes in Computer Science},
volume = {7903},
pages = {266--277},
year = {2013},
doi = {10.1007/978-3-642-38682-4_30},
}

@inproceedings{iwann13:cmrproc,
 author = {Cornejo, Maria Eugenia and Medina-Moreno, Jes\'{u}s and Ram\'{\i}rez, Eloisa},
 title = {On the Classification of Fuzzy-attributes in Multi-adjoint Concept Lattices},
 booktitle = {Proceedings of the 12th International Conference on Artificial Neural Networks: Advences in Computational Intelligence--Volume Part II},
 series = {IWANN'13},
 year = {2013},
 isbn = {978-3-642-38681-7},
 location = {Puerto de la Cruz, Tenerife, Spain},
 pages = {266--277},
 numpages = {12},
 url = {http://dx.doi.org/10.1007/978-3-642-38682-4_30},
 doi = {10.1007/978-3-642-38682-4_30},
 acmid = {2523970},
 publisher = {Springer-Verlag},
 address = {Berlin, Heidelberg},
 keywords = {attribute classification, formal concept analysis, fuzzy sets},
} 



@article{ijgs:medina14,
author = {D\'iaz-Moreno, J. C. and Medina, J. and Ojeda-Aciego, M.},
title = {On basic conditions to generate multi-adjoint concept lattices via {G}alois connections},
journal = {International Journal of General Systems},
volume = {43},
number = {2},
pages = {149--161},
year = {2014},
doi = {10.1080/03081079.2013.879302},
}


@article{art:deltasnuestro,
author = {Cornejo, M. Eugenia and Medina, Jes\'us and Ram\'irez-Poussa, Eloisa},
title = {On the use of thresholds in multi-adjoint concept lattices},
journal = {International Journal of Computer Mathematics},
volume = {92},
number = {9},
pages = {1855-1873},
year = {2015},
doi = {10.1080/00207160.2014.896078},
URL = { 
        http://dx.doi.org/10.1080/00207160.2014.896078
},
eprint = { 
        http://dx.doi.org/10.1080/00207160.2014.896078
 }
}



@inproceedings{cmmse13-cmr,
 author = {Cornejo, Maria Eugenia and Medina, Jes\'{u}s and Ram\'{\i}rez-Poussa, Eloisa},
	Booktitle = {International Conference on Computational and Mathematical Methods in Science and Engineering ({CMMSE} 2013)},
	Title = {Multi-adjoint concept lattices reduced by thresholds},
pages = {467--476},
        volume    = {II},
	Year = {2013},
        location  = {Cabo de Gata (Almería)},
	}  

@inproceedings{cmmse11-medina,
	Author = {J. Medina},
	Booktitle = {International Conference on Computational and Mathematical Methods in Science and Engineering ({CMMSE} 2011)},
	Title = {Towards dual multi-adjoint concept lattices},
pages = {797--805},
        volume    = {II},
	Year = {2011},
        location  = {Benidorm (Alicante)},
	}


 @inproceedings{cmmse10-mo,
	Author = {J. Medina and M. Ojeda-Aciego},
	Booktitle = {International Conference on Computational and Mathematical Methods in Science and Engineering ({CMMSE} 2010)},
	Title = {On multi-adjoint concept lattices based on heterogeneous conjunctors},
pages = {633--641},
	Year = {2010},
        location  = {Almería},
	}
	



 @inproceedings{iasted09-mo,
	Author = {J. Medina and M. Ojeda-Aciego},
	Booktitle = {13th  IASTED Int. Conference in Artificial Intelligence and Soft Computing},
	Title = {Taming non-commutativity in the framework of multi-adjoint concept  lattices},
pages = {99--106},
	Year = {2009},
        location  = {Palma de Mallorca},
	}
	

 

 @inproceedings{ifsa09-mo,
	Author = {J. Medina and M. Ojeda-Aciego},
	Booktitle = {Intl. Fuzzy Systems Association World Congress (IFSA'09)},
	Title = {On the representation theorem of multi-adjoint concept lattices},
pages = {1091--1095},
	Year = {2009},
        location  = {Lisboa  (Portugal)},
	}
	
@article{ChrisMedina14,
title = "Multi-adjoint fuzzy rough sets: Definition, properties and attribute selection ",
journal = "International Journal of Approximate Reasoning ",
volume = "55",
pages = "412--426",
year = "2014",
issn = "0888-613X",
doi = "http://dx.doi.org/10.1016/j.ijar.2013.09.007",
url = "http://www.sciencedirect.com/science/article/pii/S0888613X1300176X",
author = "Chris Cornelis and Jes\'us Medina and Nele Verbiest",
keywords = "Rough sets",
keywords = "Concept lattices",
keywords = "Fuzzy sets",
keywords = "Attribute selection",
keywords = "Data analysis",
keywords = "Decision reducts "
}



 @inproceedings{rst11-cmv,
	Author = {C. Cornelis and J. Medina and N. Verbiest},
	Booktitle = {Third International Workshop on
Rough Set Theory (RST 2011)},
	Title = {Multi-Adjoint Fuzzy Rough Sets},
pages = { },
	Year = {2011},
        location  = {Milán (Italia)},
	}
	
@article{ijar-cmv,
author = {C. Cornelis and J. Medina and N. Verbiest},
title = {Multi-adjoint fuzzy rough sets: Definition, properties and   
attribute selection},
journal = {International Journal of Approximate Reasoning},
volume = {55},
 pages = {412--426},
year = {2014},
}
 

%:%% Theory FCA

@article{YAO20221,
title = {Formal concept analysis, rough sets, and three-way decisions},
journal = {International Journal of Approximate Reasoning},
volume = {140},
pages = {1-6},
year = {2022},
issn = {0888-613X},
doi = {https://doi.org/10.1016/j.ijar.2021.09.011},
url = {https://www.sciencedirect.com/science/article/pii/S0888613X21001535},
author = {JingTao Yao and Jesús Medina and Yan Zhang and Dominik \'{S}l\c{e}zak},
abstract = {Formal concept analysis, rough sets, and three-way decisions are prominent theories and methods for data representation and analysis. They have been applied to data mining, machine learning, artificial intelligence as well as many other areas. This special issue contains thirty high quality state-of-art research that addresses theoretic and applicational aspects of formal concept analysis, rough sets, and three-way decisions.}
}


@article{qian2017,
title = "Constructing three-way concept lattices based on apposition and subposition of formal contexts ",
journal = "Knowledge-Based Systems ",
volume = "116",
number = "",
pages = "39 - 48",
year = "2017",
note= "",
issn = "0950-7051",
doi = "http://dx.doi.org/10.1016/j.knosys.2016.10.033",
url = "http://www.sciencedirect.com/science/article/pii/S0950705116304270",
author = "Ting Qian and Ling Wei and Jianjun Qi",
keywords = "Three-way concept lattice",
keywords = "Three-way decision",
keywords = "Apposition",
keywords = "Subposition ",
abstract = "Abstract Three-way concept analysis provides a new model to make three-way decisions. Its basic structure can be shown by the three-way concept lattices. Thus, how to construct three-way concept lattices is an important issue in the three-way concept analysis. This paper proposes approaches to create the three-way concept lattices of a given formal context. First, we can transform the given formal context and its complementary context into new formal contexts which are isomorphic to the given formal context and its complementary context respectively. And then, Type I-combinatorial context and Type II-combinatorial context are defined, which are apposition and subposition of these new formal contexts, respectively. Second, we prove that the concept lattice of Type I-combinatorial context is isomorphic to object-induced three-way concept lattice and the concept lattice of Type II-combinatorial context is isomorphic to attribute-induced three-way concept lattice of the given formal context. And then, the approaches of creating the three-way concept lattices are proposed based on the concept lattices of Type I-combinatorial context and Type I-combinatorial context. Finally, we give the corresponding algorithms of constructing three-way concept lattices based on the above approaches and conduct several experiments to illustrate the efficient of proposed algorithms. "
}



@article{yao2016,
title = "Lattice-theoretic contexts and their concept lattices via {G}alois ideals ",
journal = "Information Sciences ",
volume = "339",
number = "",
pages = "1--18",
year = "2016",
note= "",
issn = "0020-0255",
doi = "http://dx.doi.org/10.1016/j.ins.2015.12.028",
url = "http://www.sciencedirect.com/science/article/pii/S0020025515009172",
author = "Wei Yao and Sang-Eon Han and Rongxin Wang",
keywords = "Power context",
keywords = "Galois connection",
keywords = "Galois ideal",
keywords = "Lattice-theoretic context",
keywords = "Concept lattice",
keywords = "Formal fuzzy context ",
abstract = "Abstract This paper introduces a concept of lattice-theoretic contexts as well as their concept lattices. A lattice-theoretic context is a triple (G, M, I) with two complete lattices G, M and their Galois ideal I. A lattice-theoretic context and its concept lattice are a common generalization of classical FCA, PÃ³csâ™s formal fuzzy context, one-sided concept lattices, generalized concept lattices and L-fuzzy concept lattices (with hedges). When the lattices G, M are completely distributive, a reduction of the relation I in the lattice-theoretic context (G, M, I) can be obtained. Related algorithms to construct concept lattices of L-fuzzy contexts considered as lattice-theoretic contexts are presented. In the case of L being a completely distributive lattice, we can reduce the number of elements (objects or/and attributes) before computing the whole concept lattice. Then the related algorithm has lower complexity. "
}



%:%% Applications FCA


@Inbook{cornejoweather2022,
author="Cornejo, M. Eugenia
and Medina, Jes{\'u}s
and Rubio-Manzano, Clemente",
editor="Cornejo, M. Eugenia  
and K{\'o}czy, L{\'a}szl{\'o} T.
and Medina, Jes{\'u}s
and  Moreno-Garc\'ia J.",
title="Formal Analysis of Solar Power and Weather Data",
bookTitle="Computational Intelligence and Mathematics for Tackling Complex Problems 2",
year="2022",
publisher="Springer International Publishing",
address="Cham",
pages="81--89",
isbn="978-3-030-88817-6",
doi="https://doi.org/10.1007/978-3-030-88817-6_10",
url="https://doi.org/10.1007/978-3-030-88817-6_10"
}


@article{liao22,
author = {Liao, W. and Nie, X. and Zhang, Z.},
title = {Interval association of remote sensing ecological index in China based on concept lattice},
journal = {Environ Sci Pollut Res},
volume = {},
pages = {},
year = {2022},
keywords = {association rule mining, dropout analysis, educational data mining, formal concept analysis, massive online open course, temporal concept analysis},
doi = {https://doi.org/10.1007/s11356-021-17588-y},
}


 


@article{blundo2021,
author = {Blundo, Carlo and Fenza, Giuseppe and Fuccio, Graziano and Loia, Vincenzo and Orciuoli, Francesco},
title = {A time-driven FCA-based approach for identifying students' dropout in MOOCs},
journal = {International Journal of Intelligent Systems},
volume = {n/a},
pages = {},
year = {2021},
keywords = {association rule mining, dropout analysis, educational data mining, formal concept analysis, massive online open course, temporal concept analysis},
doi = {https://doi.org/10.1002/int.22414},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/int.22414},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/int.22414},
abstract = {Abstract In online learning, the dropout phenomenon is a relevant issue to address with practical solutions. Several data sets stimulate original, and resolutive data analysis approaches, demonstrating the importance of the dropout phenomenon. This study proposes a novel approach to predicting massive online open course (MOOC) students at risk of dropout stressing the need to consider the temporal dimension in the data log. The proposal aims to build a data-driven decision support system able to identify students at risk of dropout based on the conceptualization of such students' behavior and its evolution along the time dimension. The primary theoretical model behind the proposed method is the formal concept analysis, and its temporal extension (i.e., temporal concept analysis) for analyzing timestamped data and carrying out a timed lattice. The main result of the paper is a method to extract behavioral patterns of MOOC students at risk of dropout. Such patterns are defined as Time-based Behavior Rules extracted from the aforementioned timed lattice obtained through the preprocessing of MOOC platform log files. The resulting rule set can be easily integrated for implementing educational DSS, as shown in the last part of the paper. The conducted experiments reveal promising results in terms of F-score and students' monitoring time.}
}




@Inbook{aragonpatterns2022,
author="Arag{\'o}n, Roberto G.
and Cornejo, M. Eugenia
and Medina, Jes{\'u}s
and Ram{\'i}rez-Poussa, Elo{\'i}sa
and Rubio-Manzano, Clemente",
editor="Harmati, Istv{\'a}n {\'A}.
and K{\'o}czy, L{\'a}szl{\'o} T.
and Medina, Jes{\'u}s
and Ram{\'i}rez-Poussa, Elo{\'i}sa",
title="Formal Concept Analysis for Detecting Criminal Patterns",
bookTitle="Computational Intelligence and Mathematics for Tackling Complex Problems 3",
year="2022",
publisher="Springer International Publishing",
address="Cham",
pages="197--203",
abstract="This paper shows how fuzzy formal concept analysis can be applied to a real crimes dataset in order to extract patterns and knowledge from it. Different concepts and attribute implications have been selected and interpreted obtaining interesting consequences.",
isbn="978-3-030-74970-5",
doi="10.1007/978-3-030-74970-5_23",
url="https://doi.org/10.1007/978-3-030-74970-5_23"
}






@article{alcalde2019,
author = {Cristina Alcalde and Ana Burusco},
title = {Reduction of the size of {$L$}-fuzzy contexts. {A} tool for differential diagnoses of diseases},
journal = {International Journal of General Systems},
volume = {48},
number = {7},
pages = {692-712},
year  = {2019},
publisher = {Taylor & Francis},
doi = {10.1080/03081079.2019.1620740},

URL = { 
        https://doi.org/10.1080/03081079.2019.1620740
    
},
eprint = { 
        https://doi.org/10.1080/03081079.2019.1620740
    
}
,
    abstract = { ABSTRACTInformation extraction from an L-fuzzy context becomes a hard problem when we work with a large set of objects and/or attributes. The goal of this paper is to present two different and complementary techniques to reduce the size of the context. First, using overlap indexes, we will establish rankings among the elements of the context that will allow us to determine those that do not provide relevant information and eliminate them. Second, by means of Choquet integrals, we will aggregate some objects or attributes of the context in order to jointly use the provided information. One interesting application of the developed theory consists on helping in the differential diagnoses of diseases that share a large number of symptoms and, therefore, that are difficult of distinguish. }
}



@article{singh2018,
title = {Complex neutrosophic concept lattice and its applications to air quality analysis},
journal = {Chaos, Solitons \& Fractals},
volume = {109},
pages = {206-213},
year = {2018},
issn = {0960-0779},
doi = {https://doi.org/10.1016/j.chaos.2018.02.034},
url = {https://www.sciencedirect.com/science/article/pii/S0960077918300948},
author = {Prem Kumar Singh},
keywords = {Air Quality Index(AQI), Complex fuzzy sets, Complex neutrosophic set, Concept lattice, Formal Concept Analysis(FCA), Threeâ“way fuzzy concept lattice},
abstract = {In the current year, the precise measurement of uncertainty and fluctuation exists in a complex fuzzy attributes is addressed as computationally and mathematically expensive tasks with regard to its graphical analytics. To deal with this problem the calculus of complex neutrosophic sets are recently introduced to characterize the uncertainty and its changes based on its truth, indeterminacy, and falsity membershipâ“value, independently. This given a way to represent the given data sets in form of complex neutrosophic matrix for further analysis towards knowledge processing tasks. In this process, a major problem arises when an expert wants to find some of the interesting patterns in the given complex neutrosophic data sets to solve the particular problem. To resolve this issue, the current paper proposes a method for step by step demonstration to investigate the complex neutrosophic concepts and their graphical structure visualization based on their Lower Neighbors. One of the suitable examples of the proposed method is also given for precise measurement of uncertainty exists in Air Quality Index (AQI) and its pattern at given phase of time.}
}

@article{xie2018,
title = {Rule acquisition and optimal scale selection in multi-scale formal decision contexts and their applications to smart city},
journal = {Future Generation Computer Systems},
volume = {83},
pages = {564-581},
year = {2018},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2017.03.011},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X17303722},
author = {Junping Xie and Minhua Yang and Jinhai Li and Zhong Zheng},
keywords = {Multi-scale formal decision context, Concept lattice, Rule acquisition, Optimal scale selection},
abstract = {In order to enrich the existing rule acquisition theory in formal decision contexts, this study puts forward three new types of rules: decision association rules, non-redundant decision association rules and simplest decision association rules. Then, we analyze the relationship among these three types of rules, and develop methods to acquire them from single-scale formal decision contexts. Some numerical experiments are also conducted to compare the performance of the method of acquiring the simplest decision association rules with that of the existing one of acquiring the non-redundant decision rules. Moreover, the new three types of rules are employed to introduce three types of consistencies in multi-scale formal decision contexts. In addition, the notion of an optimal scale is defined by each type of consistency, and how to select an optimal scale is investigated as well. Finally, two applications in smart city for the proposed rule acquisition and optimal scale selection methods are applied to smart city.}
}


@article{madu2017,
title = "Urban sustainability management: A deep learning perspective ",
journal = "Sustainable Cities and Society ",
volume = "30",
number = "",
pages = "1 - 17",
year = "2017",
note= "",
issn = "2210-6707",
doi = "http://dx.doi.org/10.1016/j.scs.2016.12.012",
url = "http://www.sciencedirect.com/science/article/pii/S2210670716304590",
author = "Christian N. Madu and Chu-hua Kuei and Picheng Lee",
keywords = "Urban sustainability management",
keywords = "City carbon disclosure project (CDP)",
keywords = "Qualitative data mining",
keywords = "Formal concept analyses (FCA)",
keywords = "Deep learning ",
abstract = "Abstract This paper uses formal concept analyses (FCA) and qualitative data points obtained from City Carbon Disclosure Project (CDP) to identify expected economic opportunities, the types of urban sustainability development incentives, emissions reduction activities, and methodologies/guidelines adopted for the on-going implementation of the urban sustainability development initiatives. Our focus is on three continents namely Europe, Asia, and North America. A âœdeepâ learning perspective is used to evaluate textual data with depth of up to four layers. Association rules and concept lattice generation functions of \{FCA\} are employed and applied to support the learning process. Our empirical models show that the transportation sector is the focal point to reduce emissions in all the three continents. No trend was observed with respect to the methodologies and guidelines applied. There is a need to work interactively with the four layers of deep learning to establish new rules and guidelines for achieving reduction in emissions and urban sustainability transformations. "
}



@article{cigarran2016,
title = "A step forward for Topic Detection in Twitter: An FCA-based approach ",
journal = "Expert Systems with Applications ",
volume = "57",
number = "",
pages = "21 - 36",
year = "2016",
note= "",
issn = "0957-4174",
doi = "http://dx.doi.org/10.1016/j.eswa.2016.03.011",
url = "http://www.sciencedirect.com/science/article/pii/S0957417416301038",
author = "Juan Cigarr\'an and \'Angel Castellanos and Ana Garc\'ia-Serrano",
keywords = "Formal Concept Analysis",
keywords = "Stability",
keywords = "Topic Detection",
keywords = "Online Reputation Management ",
abstract = "Abstract The Topic Detection Task in Twitter represents an indispensable step in the analysis of text corpora and their later application in Online Reputation Management. Classification, clustering and probabilistic techniques have been traditionally applied, but they have some well-known drawbacks such as the need to fix the number of topics to be detected or the problem of how to integrate the prior knowledge of topics with the detection of new ones. This motivates the current work, where we present a novel approach based on Formal Concept Analysis (FCA), a fully unsupervised methodology to group similar content together in thematically-based topics (i.e., the \{FCA\} formal concepts) and to organize them in the form of a concept lattice. Formal concepts are conceptual representations based on the relationships between tweet terms and the tweets that have given rise to them. It allows, in contrast to other approaches in the literature, their clear interpretability. In addition, the concept lattice represents a formalism that describes the data, explores correlations, similarities, anomalies and inconsistencies better than other representations such as clustering models or graph-based representations. Our rationale is that these theoretical advantages may improve the Topic Detection process, making them able to tackle the problems related to the task. To prove this point, our FCA-based proposal is evaluated in the context of a real-life Topic Detection task provided by the Replab 2013 \{CLEF\} Campaign. To demonstrate the efficiency of the proposal, we have carried out several experiments focused on testing: (a) the impact of terminology selection as an input to our algorithm, (b) the impact of concept selection as the outcome of our algorithm, and; (c) the efficiency of the proposal to detect new and previously unseen topics (i.e., topic adaptation). An extensive analysis of the results has been carried out, proving the suitability of our proposal to integrate previous knowledge of prior topics without losing the ability to detect novel and unseen topics as well as improving the best Replab 2013 results. "
}


@article{du2014,
title = "An approach for selecting seed {URL}s of focused crawler based on user-interest ontology ",
journal = "Applied Soft Computing ",
volume = "14, Part C",
number = "",
pages = "663 - 676",
year = "2014",
note= "",
issn = "1568-4946",
doi = "http://dx.doi.org/10.1016/j.asoc.2013.09.007",
url = "http://www.sciencedirect.com/science/article/pii/S1568494613002974",
author = "YaJun Du and YuFeng Hai and ChunZhi Xie and XiaoMing Wang",
keywords = "Seed URLs",
keywords = "Formal concept analysis",
keywords = "User-interest ontology",
keywords = "Bipartite graph",
keywords = "Web crawler ",
abstract = "Abstract Seed \{URLs\} selection for focused Web crawler intends to guide related and valuable information that meets a user's personal information requirement and provide more effective information retrieval. In this paper, we propose a seed \{URLs\} selection approach based on user-interest ontology. In order to enrich semantic query, we first intend to apply Formal Concept Analysis to construct user-interest concept lattice with user log profile. By using concept lattice merger, we construct the user-interest ontology which can describe the implicit concepts and relationships between them more appropriately for semantic representation and query match. On the other hand, we make full use of the user-interest ontology for extracting the user interest topic area and expanding user queries to receive the most related pages as seed URLs, which is an entrance of the focused crawler. In particular, we focus on how to refine the user topic area using the bipartite directed graph. The experiment proves that the user-interest ontology can be achieved effectively by merging concept lattices and that our proposed approach can select high quality seed \{URLs\} collection and improve the average precision of focused Web crawler. "
}


@article{Valverde:2016,
title = "Supporting scientific knowledge discovery with extended, generalized Formal Concept Analysis ",
journal = "Expert Systems with Applications ",
volume = "44",
number = "",
pages = "198 - 216",
year = "2016",
note= "",
issn = "0957-4174",
doi = "http://dx.doi.org/10.1016/j.eswa.2015.09.022",
url = "http://www.sciencedirect.com/science/article/pii/S0957417415006442",
author = "Francisco J. Valverde-Albacete and Jos\'e Mar\'ia Gonz\'alez-Calabozo and Anselmo Pe{\~n}as and Carmen Pel\'aez-Moreno",
keywords = "Scientific knowledge discovery",
keywords = "Exploratory Data Analysis",
keywords = "Landscapes of Knowledge",
keywords = "Metaphor theory",
keywords = "Formal Concept Analysis",
keywords = "K -Formal Concept Analysis",
keywords = "Extended Formal Concept Analysis",
keywords = "Semiring theory",
keywords = "Confusion matrix",
keywords = "Relation extraction",
keywords = "Gene expression data ",
abstract = "Abstract In this paper we fuse together the Landscapes of Knowledge of Willeâ??s and Exploratory Data Analysis by leveraging Formal Concept Analysis (FCA) to support data-induced scientific enquiry and discovery. We use extended \{FCA\} first by allowing K -valued entries in the incidence to accommodate other, non-binary types of data, and second with different modes of creating formal concepts to accommodate diverse conceptualizing phenomena. With these extensions we demonstrate the versatility of the Landscapes of Knowledge metaphor to help in creating new scientific and engineering knowledge by providing several successful use cases of our techniques that support scientific hypothesis-making and discovery in a range of domains: semiring theory, perceptual studies, natural language semantics, and gene expression data analysis. While doing so, we also capture the affordances that justify the use of \{FCA\} and its extensions in scientific discovery. "
}


@article{Cattaneo:2016,
title = "On the connection of hypergraph theory with formal concept analysis and rough set theory ",
journal = "Information Sciences ",
volume = "330",
number = "",
pages = "342 - 357",
year = "2016",
issn = "0020-0255",
doi = "http://dx.doi.org/10.1016/j.ins.2015.09.054",
url = "http://www.sciencedirect.com/science/article/pii/S0020025515007136",
author = "Gianpiero Cattaneo and Giampiero Chiaselotti and Davide Ciucci and Tommaso Gentile",
keywords = "Rough sets",
keywords = "Formal concept analysis",
keywords = "Hypergraphs ",
abstract = "Abstract We present a unique framework for connecting different topics: hypergraphs from one side and Formal Concept Analysis and Rough Set Theory from the other. This is done through the formal equivalence among Boolean information tables, formal contexts and hypergraphs. Links with generic (i.e., not Boolean) information tables are established, through so-called nominal scaling. The particular case of k-uniform complete hypergraphs will then be studied. In this framework, we are able to solve typical problems of Rough Set Theory and Formal Concept Analysis using combinatorial techniques. More in detail, we will give a formula to compute the degree of dependency and the partial implication between two sets of attributes, compute the set of reducts and define the structure of the partitions generated by all the definable indiscernibility relations. "
}






%%%%%% CORDERO

@ARTICLE{cabrera18,
  author={I. P. {Cabrera} and P. {Cordero} and F. {García-Pardo} and M. {Ojeda-Aciego} and B. {De Baets}},
  journal={IEEE Transactions on Fuzzy Systems}, 
  title={Galois Connections Between a Fuzzy Preordered Structure and a General Fuzzy Structure}, 
  year={2018},
  volume={26},
  number={3},
  pages={1274-1287},
  doi={10.1109/TFUZZ.2017.2718495}}
  
  
@article{RodriguezJimenez2016,
title = "Concept lattices with negative information: A characterization theorem ",
journal = "Information Sciences ",
volume = "369",
number = "",
pages = "51-62",
year = "2016",
note= "",
issn = "0020-0255",
doi = "http://dx.doi.org/10.1016/j.ins.2016.06.015",
url = "http://www.sciencedirect.com/science/article/pii/S0020025516304364",
author = "J.M. Rodr\'iguez-Jim\'enez and P. Cordero and M. Enciso and S. Rudolph",
keywords = "Formal concept analysis",
keywords = "Lattice theory",
keywords = "Negative information ",
abstract = "Abstract Classical Formal Concept Analysis (FCA) extracts, represents and manages knowledge from positive information, i.e., its fundamental data model is a binary relation between a set of objects and attributes indicating the presence of a property in an object. However, some applications require to treat the absence of some property in an object as a negative information to be explicitly represented and managed, too. Although mixed (positive and negative) information has been addressed in the past in FCA, such approaches maintain the standard framework, which hides the specific semantics and avoids the further use of direct techniques and methods for mixed information. In this work, the foundations of \{FCA\} are extended and, in particular, mixed concept lattices are studied in depth. The main result of this work is a characterization theorem specifying in lattice-theoretic terms which lattices are isomorphic to a mixed concept lattice. "
}


@article {Cordero:16,
author = {Rodr\'iguez-Jim\'enez, Jose Manuel and Cordero, Pablo and Enciso, Manuel and Mora, Angel},
title = {Data mining algorithms to compute mixed concepts with negative attributes: an application to breast cancer data analysis},
journal = {Mathematical Methods in the Applied Sciences},
issn = {1099-1476},
url = {http://dx.doi.org/10.1002/mma.3814},
doi = {10.1002/mma.3814},
pages = {4829--4845},
volume = "39",
number = "16",
keywords = {knowledge discovery, formal concept analysis, negative attributes, medical issues},
year = {2016},
}


@article{pablo2015,
  author    = {Pablo Cordero and
               Manuel Enciso and
               Angel Mora and
               Manuel Ojeda{-}Aciego and
               Carlos Rossi},
  title     = {Knowledge discovery in social networks by using a logic-based treatment  of implications},
  journal   = {Knowledge-Based Systems},
  volume    = {87},
  pages     = {16--25},
  year      = {2015},
  url       = {http://dx.doi.org/10.1016/j.knosys.2015.07.018},
  doi       = {10.1016/j.knosys.2015.07.018},
  timestamp = {Mon, 14 Sep 2015 09:13:49 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/kbs/CorderoEMOR15},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@article{belohlavek2019,
title = "Factorization of matrices with grades via essential entries",
journal = "Fuzzy Sets and Systems",
volume = "360",
pages = "97--116",
year = "2019",
issn = "0165-0114",
doi = "https://doi.org/10.1016/j.fss.2018.07.004",
url = "http://www.sciencedirect.com/science/article/pii/S0165011418303865",
author = "Radim B{\v e}lohl{\'a}vek and Marketa Trneckova",
keywords = "Fuzzy logic, Matrix decomposition, Decomposition of fuzzy relations, Fuzzy Galois connection, Fuzzy concept lattice",
abstract = "We present new results regarding the problem of factorization of matrices with grades, or, equivalently, decomposition of fuzzy relations. In particular, we examine geometry of factorizations and the role of fuzzy concept lattices in factorizations of matrices with grades. The results make it possible to reduce input data and enable a more focused search for factors in the search space, and are intended to guide the design of greedy and other approximation algorithms for the decomposition problem, which itself is NP-hard. To demonstrate usefulness of these results, we propose a new factorization algorithm based on these results. Our experiments demonstrate improvements in the quality of factorizations due to the new approach. We conclude by presenting further research topics implied by our findings."
}

@article{rasouli2019,
title = "On residuated lattices with left and right internal state",
journal = "Fuzzy Sets and Systems",
volume = "373",
pages = "37 - 61",
year = "2019",
issn = "0165-0114",
doi = "https://doi.org/10.1016/j.fss.2019.03.001",
url = "http://www.sciencedirect.com/science/article/pii/S0165011419301678",
author = "Saeed Rasouli and Zeinab Zarin",
keywords = "Residuated lattice, State residuated lattice, Galois connection, State filter, State congruence, Heyting algebra, State coannihilator",
abstract = "In this paper, notions of left- and right-state operators on residuated lattices are introduced and some related properties of such operators are investigated. Filters and normal filters generated by a subset in a state residuated lattice are characterized and it is shown that the lattice of filters forms a frame. Subdirectly irreducible state residuated lattices are characterized. The notion of state coannihilator is introduced and a connection between them and Galois connection is established. Finally, it is shown that the set of state coannihilators forms a complete Boolean algebra."
}

@article{horn2019, title={Constructive {G}alois Connections}, volume={29}, DOI={10.1017/S0956796819000066}, journal={Journal of Functional Programming}, publisher={Cambridge University Press}, author={Darais, David and Horn, David Van}, year={2019}, pages={e11}}

@Inbook{kridlo2019,
author="Kr{\'i}dlo, O.
and Ojeda-Aciego, M.",
editor="Cornejo, Mar{\'i}a Eugenia
and K{\'o}czy, L{\'a}szl{\'o} T.
and Medina, Jes{\'u}s
and De Barros Ruano, Antonio Eduardo",
title="An Adjoint Pair for Intuitionistic L-Fuzzy Values",
bookTitle="Trends in Mathematics and Computational Intelligence",
year="2019",
publisher="Springer International Publishing",
address="Cham",
pages="167--173",
abstract="WeKr{\'i}dlo, O. continueOjeda-Aciego, M. our prospective study of the generalization of formal concept analysis in terms of intuitionistic L-fuzzy sets. The main contribution here is an adjoint pair in the set {\$}{\$}{\{}{\backslash}mathcal L{\}}{\_}{\backslash}mathrm{\{}ILF{\}}{\$}{\$}LILFof intuitionistic L-fuzzy values associated to a complete residuated lattice {\$}{\$}{\{}{\backslash}mathcal L{\}}{\$}{\$}L, which allows the definition of a pair of derivation operators which form an antitone Galois connection.",
isbn="978-3-030-00485-9",
doi="10.1007/978-3-030-00485-9_19",
url="https://doi.org/10.1007/978-3-030-00485-9_19"
}


@article{antoni2017,
title = "Representation of fuzzy subsets by {G}alois connections",
journal = "Fuzzy Sets and Systems",
volume = "326",
pages = "52 - 68",
year = "2017",
issn = "0165-0114",
doi = "https://doi.org/10.1016/j.fss.2017.05.020",
url = "http://www.sciencedirect.com/science/article/pii/S0165011417302294",
author = "Lubomir Antoni and Stanislav Kraj{\v c}i and Ondrej Kr\'idlo",
keywords = "Galois connections, Algebra, Fuzzy subsets, Hedges, Nestedness",
abstract = "There is a great deal of fuzziness in our everyday natural language, and thus fuzzy subsets have come to represent a direct generalisation of the indicator function of a classical subset. On the other hand, a Galois connection is given by two opposite order-inverting maps whose composition yields two closure operations between ordered sets. We present the one-to-one correspondence between a set of all fuzzy subsets and a set of all Galois connections. The essential correspondences are built with the help of Î±-cuts, which represent fuzzy subsets by means of classical sets. Moreover, we present a relationship between strong fuzzy negations in the lattices and Galois connections. The various extensions of fuzzy subsets from the point of view of nestedness and negations are recalled. Other fruitful properties and connections with related studies are included."
}
@article{ludomir14,
  author    = {L'ubom{\'{\i}}r Antoni and
               Stanislav Krajci and
               Ondrej Kridlo and
               Bohuslav Macek and
               Lenka Piskov{\'{a}}},
  title     = {On heterogeneous formal contexts},
  journal   = {Fuzzy Sets and Systems},
  volume    = {234},
  pages     = {22--33},
  year      = {2014},
  url       = {http://dx.doi.org/10.1016/j.fss.2013.04.008},
  doi       = {10.1016/j.fss.2013.04.008},
}


@article{kridlo:2016,
author = {Ondrej Kr\'idlo and Stanislav Kraj{\v c}i and Lubomir Antoni},
title = {Formal concept analysis of higher order},
journal = {International Journal of General Systems},
volume = {45},
number = {2},
pages = {116-134},
year = {2016},
doi = {10.1080/03081079.2015.1072924},
URL = { 
        http://dx.doi.org/10.1080/03081079.2015.1072924 
},
peprint = { 
        http://dx.doi.org/10.1080/03081079.2015.1072924   
}
,
    abstract = { The second-order formal context is a formal context such that its object and attribute sets are disjoint unions of object and attribute sets of external formal contexts. Every subset of object or attribute set will be evaluated from concept lattice of the corresponding external formal context. The paper provides a method how to compute such second-order formal concepts by using of bonds between external formal contexts or by using heterogeneous formal context methods. The last part of the paper shows how this structure generalizes homogeneous fuzzy formal context and its derivation operators. },
}


@article{Li:2016,
title = "Approximate concept construction with three-way decisions and attribute reduction in incomplete contexts ",
journal = "Knowledge-Based Systems ",
volume = "91",
pages = "165 - 178",
year = "2016",
issn = "0950-7051",
doi = "http://dx.doi.org/10.1016/j.knosys.2015.10.010",
url = "http://www.sciencedirect.com/science/article/pii/S0950705115003858",
author = "Meizheng Li and Guoyin Wang",
keywords = "Concept lattice",
keywords = "Approximate concept construction",
keywords = "Three-way decisions",
keywords = "Attribute reduction",
keywords = "Attribute characteristic ",
abstract = "Abstract Incomplete contexts are a kind of formal contexts in which the relationship between some objects and some attributes is unavailable or lost. Knowledge discovery in incomplete contexts is of interest because such databases are frequently encountered in the real world. This paper mainly focuses on two issues: approximate concept construction with three-way decisions and attribute reduction in incomplete contexts. The theory of three-way decisions is formulated based on the notions of acceptance, rejection and non-commitment. It is an extension of the commonly used binary-decision model with an added third option. Based on three-way decisions, we propose two models to construct approximate concepts in incomplete contexts, and the equivalence of the two is revealed. To simplify the representation of the approximate concept lattices, we further present the attribute reduction approaches. "
}


@article{Alcalde:2016,
title = "Evolution in time of {L}-fuzzy context sequences ",
journal = "Information Sciences ",
volume = "326",
number = "",
pages = "202 - 214",
year = "2016",
note= "",
issn = "0020-0255",
doi = "http://dx.doi.org/10.1016/j.ins.2015.07.050",
url = "http://www.sciencedirect.com/science/article/pii/S0020025515005587",
author = "Cristina Alcalde and Ana Burusco and Humberto Bustince and Aranzazu Jurio and Jose Antonio Sanz",
keywords = "L-fuzzy context",
keywords = "L-fuzzy concept",
keywords = "L-fuzzy context sequences",
keywords = "n-ary \{OWA\} operators ",
abstract = "Abstract In this work, we consider a complete lattice L and we study L-fuzzy context sequences which represent the evolution in time of an L-fuzzy context. To carry out this study, in the first part of the paper, we consider n-ary \{OWA\} operators in complete lattices, which enable us to make a general analysis and a temporal analysis at any moment in time of L-fuzzy context sequences. After that, evolution in time of the relationship between the objects and the attributes is considered. In particular, we analyze the concepts of Trend and Persistent formal contexts. Finally, we illustrate our results with an example where we consider the particular lattice L = J ( [ 0 , 1 ] ) . "
}

@article{Li20121,
title = "Combining concept lattice with call graph for impact analysis",
journal = "Advances in Engineering Software",
volume = "53",
number = "0",
pages = "1--13",
year = "2012",
note= "",
issn = "0965-9978",
doi = "10.1016/j.advengsoft.2012.07.001",
url = "http://www.sciencedirect.com/science/article/pii/S0965997812000956",
author = "Bixin Li and Xiaobing Sun and Hareton Leung",
keywords = "Formal concept analysis",
keywords = "Change impact analysis",
keywords = "Call graph",
keywords = "Impact factor",
keywords = "Hierarchical impact results",
keywords = "Case study",
abstract = "Software change impact analysis (CIA) is a key technique to identify unexpected and potential effects caused by software changes. Given a changed entity, most of current CIA techniques compute the change effect composed of some potentially impacted entities. The generated results are often of no help to the maintainers in starting the analysis of impacted entities. In this article, we combine concept lattice with call graph together to obtain a ranked list of potentially impacted methods from the proposed changed methods and/or classes. These impacted methods are ranked based on the hierarchical feature of concept lattice, represented by an impact factor, which can then be used to prioritize these methods to be inspected. Case studies based on four real-world programs show that our approach can improve the precision of the impact result without severely decreasing its recall, when compared with results from either concept lattice or call graph used independently. In addition, the predicted impacted methods with higher impact factor values are also shown to have higher probability to be affected by the changes. Our study also shows that our approach is better than the JRipples CIA approach in removing the false-positives, but at the cost of losing more false-negatives and much more time overhead."
}




@article {springerlink:10.1007/s13042-011-0054-8,
   author = {Yang, Xibei and Song, Xiaoning and Chen, Zehua and Yang, Jingyu},
   affiliation = {School of Computer Science and Engineering, Jiangsu University of Science and Technology, Zhenjiang, 212003 Peopleâ™s Republic of China},
   title = {On multigranulation rough sets in incomplete information system},
   journal = {International Journal of Machine Learning and Cybernetics},
   publisher = {Springer Berlin / Heidelberg},
   issn = {1868-8071},
   keyword = {Engineering},
   pages = {1-10},
   url = {http://dx.doi.org/10.1007/s13042-011-0054-8}

}

@inproceedings{dmr:estylf2012a,
	author = {{J. C.} D\'{i}az and J. Medina and R. Rodr\'iguez},
 	Title = {Un  algoritmo rápido para obtener retículos de conceptos utilizando el lenguaje de programación \emph{python}},
         Booktitle     = {XVI Congreso Español sobre Tecnologías y Lógica
Fuzzy, ESTYLF 2012},
        year      = {2012},
        pages = {14--19},
}

@article{Li-He-Zhu:2013,
author={Li,J. and He,J. and Zhu,J.},
year={2013},
title={An entropy-based weighted concept lattice for merging multi-source geo-ontologies},
journal={Entropy},
volume={15},
number={6},
pages={2303-2318},
url={www.scopus.com},
}
}


@article{Kang2013611,
title = "Rough set model based on formal concept analysis ",
journal = "Information Sciences ",
volume = "222",
number = "0",
pages = "611 - 625",
year = "2013",
issn = "0020-0255",
doi = "http://dx.doi.org/10.1016/j.ins.2012.07.052",
url = "http://www.sciencedirect.com/science/article/pii/S0020025512005245",
author = "Xiangping Kang and Deyu Li and Suge Wang and Kaishe Qu",
keywords = "\{FCA\}",
keywords = "Rough set theory",
keywords = "Rough concept lattice",
keywords = "Rugh concept",
keywords = "Decision dependency ",
abstract = "This paper proposes a rough set model based on formal concept analysis. In this model, a solution to an algebraic structure problem is first provided in an information system: a lattice structure is inferred from the information system and corresponding nodes are called rough concepts. How to deal with common problems in rough set theory based on rough concepts is then explored, such as upper and lower approximation operators, reducts and cores. Decision dependency has become a common form of knowledge representation owing to its properties of expressiveness and ease of understanding, so it has been widely used in practice. Finally, application of rough concepts to the extraction of decision dependencies from a decision table is studied; a complete and non-redundant set of decision dependencies can be obtained from a decision table. Examples demonstrate that application of the method presented in this paper is valid and practicable. The results not only provide a better understanding of rough set theory from the perspective of formal concept analysis, but also demonstrate a new way of combining rough set theory and formal concept analysis. "
}


@article{Formica2013,
year={2013},
issn={1387-3326},
journal={Information Systems Frontiers},
volume={15},
number={3},
doi={10.1007/s10796-011-9340-y},
title={Similarity reasoning for the semantic web based on fuzzy concept lattices: An informal approach},
url={http://dx.doi.org/10.1007/s10796-011-9340-y},
publisher={Springer US},
keywords={Semantic web; Similarity reasoning; Fuzzy formal concept analysis},
author={Formica, Anna},
pages={511-520},
language={English}
}

@article{Formica2012,
  author    = {Anna Formica},
  title     = {Semantic Web search based on rough sets and Fuzzy Formal Concept Analysis},
  journal   = {Knowlege-Based Systems},
  year      = {2012},
  volume    = {26},
  pages     = {40--47},
  url       = {http://dx.doi.org/10.1016/j.knosys.2011.06.018},
  doi       = {10.1016/j.knosys.2011.06.018},
  timestamp = {Sun, 16 Nov 2014 13:09:18 +0100},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/kbs/Formica12},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@article{Formica2010153,
author = {A.~Formica},
title = {Concept similarity in fuzzy formal concept analysis for semantic web},
journal = {International Journal of Uncertainty, Fuzziness and
  Knowlege-Based Systems},
volume = {18},
number = {2},
pages = {153--167},
year = {2010},
}

@article{Kumar2010787,
author = {C.~Kumar and S.~Srinivas},
title = {Mining associations in health care data using formal concept analysis
  and singular value decomposition},
journal = {Journal of Biological Systems},
volume = {18},
number = {4},
pages = {787--807},
year = {2010},
}
 

 
  @article{Poelmans2010139,
author = {J.~Poelmans and P.~Elzinga and  S.~Viaene and G.~Deden},
title = {Formal concept analysis in knowledge discovery: A survey},
journal = {Lecture Notes in Computer Science},
volume = {6208},
pages = {139--153},
year = {2010},
}
  
   @article{arevalo:2010,
author = {G.~Ar{\'e}valo and S.~Ducasse and S.~Gordillo and O.~Nierstraszn},
title = {Generating a catalog of unanticipated schemas in class hierarchies
  using formal concept analysis},
journal = {Information and Software Technology},
volume = {52},
number = {11},
pages = {1167--1187},
year = {2010},
}
  
@article{Galitsky20112016,
author = {B.~Galitsky and J.~De~La~Rosa},
title = {Concept-based learning of human behavior for customer relationship
  management},
journal = {Information Sciences},
volume = {181},
number = {10},
pages = {2016--2035},
year = {2011},
}
   
@article{Formica:2012,
title = "Semantic Web search based on rough sets and Fuzzy Formal Concept Analysis",
journal = "Knowledge-Based Systems",
volume = "26",
pages = "40--47",
year = "2012",
issn = "0950-7051",
doi = "10.1016/j.knosys.2011.06.018",
 url = "http://www.sciencedirect.com/science/article/pii/S095070511100133X",
author = "Anna Formica",
keywords = "Semantic Web",
keywords = "Formal Concept Analysis",
keywords = "Fuzzy information",
keywords = "Rough set theory",
keywords = "Formal concept",
abstract = "Fuzzy Formal Concept Analysis (FFCA) is a generalization of Formal Concept Analysis (FCA) for modeling uncertainty information. FFCA provides a mathematical framework which can support the construction of formal ontologies in the presence of uncertainty data for the development of the Semantic Web. In this paper, we show how rough set theory can be employed in combination with FFCA to perform Semantic Web search and discovery of information in the Web."
}



@article{Beydoun2009,
title = "Formal concept analysis for an e-learning semantic web",
journal = "Expert Systems with Applications",
volume = "36",
number = "8",
pages = "10952--10961",
year = "2009",
note= "",
issn = "0957-4174",
doi = "10.1016/j.eswa.2009.02.023",
url = "http://www.sciencedirect.com/science/article/pii/S095741740900150X",
author = "Ghassan   Beydoun",
keywords = "Semantic Web",
keywords = "E-learning",
keywords = "Formal concept analysis",
abstract = "We capture student interactions in an e-learning community to construct a semantic web (SW) to create a collective meta-knowledge structure guiding students as they search the existing knowledge corpus. We use formal concept analysis (FCA) as a knowledge acquisition tool to process the students virtual surfing trails to express and exploit the dependencies between web-pages to yield subsequent and more effective focused search results. We mirror social navigation and bypass the cumbersome manual annotation of webpages and at the same time paralleling social navigation for knowledge.

We present our system KAPUST2 (Keeper and Processor of User Surfing Trails) which constructs from captured students trails a conceptual lattice guiding student queries. We use KAPUST as an e-learning software for an undergraduate class over two semesters. We show how the lattice evolved over the two semesters, improving its performance by exploring the relationship between â˜kindsâ™ of research assignments and the e-learning semantic web development. Course instructors monitored the evolution of the lattice with interesting positive pedagogical consequences. These are reported as well in this paper."
}

%:%%% EXTRA PARA IJCM 2011
 
 @article{mgec-11,
author = {A.~Mora and I.~P. de~Guzm{\'a}n and M.~Enciso and P.~Cordero},
title = {Ideal non-deterministic operators as a formal framework to reduce the
  key finding problem},
journal = {International Journal    of Computer Mathematics},
volume = {88},
number = {9},
pages = {1860-1868},
year = {2011},
}

@article{KO-11,
author = {O.~Kr{\'\i}dlo and M.~Ojeda-Aciego},
title = {On {L}-fuzzy {C}hu correspondences},
journal = {International Journal    of Computer Mathematics},
volume = {88},
number = {9},
pages = {1808-1818},
year = {2011},
}
 
 

@article{li2010,
author = {Yang, Li and Xu, Yang},
title = {A decision method based on uncertainty reasoning of linguistic truth-valued concept lattice},
journal = {International Journal of General Systems},
volume = {39},
number = {3},
pages = {235-253},
year = {2010},
doi = {10.1080/03081070903552817},

URL = {http://www.tandfonline.com/doi/abs/10.1080/03081070903552817},
eprint = {http://www.tandfonline.com/doi/pdf/10.1080/03081070903552817},
abstract = { Decision making with linguistic information is a research hotspot now. This paper begins by establishing the theory basis for linguistic information processing and constructs the linguistic truth-valued concept lattice for a decision information system, and further utilises uncertainty reasoning to make the decision. That is, we first utilise the linguistic truth-valued lattice implication algebra to unify the different kinds of linguistic expressions; second, we construct the linguistic truth-valued concept lattice and decision concept lattice according to the concrete decision information system and third, we establish the internal and external uncertainty reasoning methods and talk about the rationality of them. We apply these uncertainty reasoning methods into decision making and present some generation methods of decision rules. In the end, we give an application of this decision method by an example. }
}




 @article{Villerd09,
author = {Villerd, Jean and Ranwez, Sylvie and Crampes, Michel and Carteret, David},
title = {Using concept lattices for visual navigation assistance in large databases},
journal = {International Journal of General Systems},
volume = {38},
number = {4},
pages = {405-425},
year = {2009},
doi = {10.1080/03081070902857829},

URL = {http://www.tandfonline.com/doi/abs/10.1080/03081070902857829},
eprint = {http://www.tandfonline.com/doi/pdf/10.1080/03081070902857829}
}


 @article{Belohlavek_ijgs2009,
author = {B{\v e}lohl{\'a}vek, Radim and {De Baets}, Bernard and Outrata, Jan and Vychodil, Vilem},
title = {Inducing decision trees via concept lattices},
journal = {International Journal of General Systems},
volume = {38},
number = {4},
pages = {455-467},
year = {2009},
doi = {10.1080/03081070902857563},

URL = {http://www.tandfonline.com/doi/abs/10.1080/03081070902857563},
eprint = {http://www.tandfonline.com/doi/pdf/10.1080/03081070902857563},
abstract = { We present a novel method for the construction of decision trees. The method utilises concept lattices in that certain formal concepts of the concept lattice associated to input data are used as nodes of the decision tree constructed from the data. The concept lattice provides global information about natural clusters in the input data, which we use for selection of splitting attributes. The usage of such global information is the main novelty of our approach. Experimental evaluation indicates good performance of our method. We describe the method, experimental results, and a comparison with standard methods on benchmark datasets. }
}







@article{Nguifo03,
author = {Nguifo, Engelbert   Mephu and Duquenne, Vincent and Liquie'RE, Michel},
title = {Introduction concept lattice-based theory, methods and tools for knowledge discovery in databases: Applications},
journal = {Applied Artificial Intelligence},
volume = {17},
number = {3},
pages = {177-180},
year = {2003},
doi = {10.1080/713827117},

URL = {http://www.tandfonline.com/doi/abs/10.1080/713827117},
eprint = {http://www.tandfonline.com/doi/pdf/10.1080/713827117},
abstract = { Concept or Galois Lattices (CL) provide a productive framework for a variety of problems that arise in Knowledge Discovery in Databases (KDD). This paper introduces this special issue of Applied Artificial Intelligence devoted to applications of Concept Lattices for KDD (CLKDD). The papers in this volume come from a call for papers issued after the first International Workshop on Concept Lattice-based Theory, Methods and Tools for KDD held in July 2001 at Stanford University. Another special issue devoted to algorithms and methods of CLKDD will appear in the Journal of Experimental and Theoretical Artificial Intelligence. }
}



@article{Alcalde2011,
title = "The use of linguistic variables and fuzzy propositions in the {L}-Fuzzy concept theory",
journal = "Computers  \& Mathematics with Applications",
volume = "62",
number = "8",
pages = "3111--3122",
year = "2011",
note= "",
issn = "0898-1221",
doi = "10.1016/j.camwa.2011.08.024",
url = "http://www.sciencedirect.com/science/article/pii/S0898122111006870",
author = "C. Alcalde and A. Burusco and R. Fuentes-Gonz{\'a}lez and I. Zubia",
keywords = "Formal concept analysis",
keywords = "Interval-valued linguistic variables",
keywords = "Interval-valued fuzzy propositions",
keywords = "Interval-valued   L  -Fuzzy contexts and subcontexts",
abstract = "The use of linguistic variables and fuzzy propositions in the interval-valued L -Fuzzy contexts can be an interesting tool to extract a more complete information from them. In this paper, we analyze three different situations. First, we obtain significant relations in order to study all the objects and attributes of the interval-valued L -Fuzzy context by means of the interval-valued L -Fuzzy concepts. After that, we show how to replace the erroneous values to be able to study in a suitable way the context. Finally, we use the linguistic labels to obtain a subcontext that represents our interest of study. We also show an experimental evaluation in the paper."
}

@article{Alcalde2009,
  author    = {Cristina Alcalde and
               Ana Burusco and
               Ram{\'o}n Fuentes-Gonz{\'a}lez and
               Itziar Zubia},
  title     = {Treatment of {L}-Fuzzy contexts with absent values},
  journal   = {Information Sciences},
  volume    = {179},
  number    = {1-2},
  year      = {2009},
  pages     = {1-15},
}

@article{Burusco2001,
title = "The study of the interval-valued contexts",
journal = "Fuzzy Sets and Systems",
volume = "121",
number = "3",
pages = "439 - 452",
year = "2001",
note= "",
issn = "0165-0114",
doi = "http://dx.doi.org/10.1016/S0165-0114(00)00059-2",
url = "http://www.sciencedirect.com/science/article/pii/S0165011400000592",
author = "A. Burusco and R. Fuentes-González",
keywords = "Data analysis methods",
keywords = "Information processing",
keywords = "-Fuzzy concepts",
keywords = "Interval-valued -Fuzzy concepts"
}

%:%%%%%%%% HEDGES

 
@article{takeuti87,
title = "Globalization of intuitionistic set theory",
journal = "Annals
of Pure and Applied Logic",
volume = "33",
pages = "195--211",
year = "1987",
author = "Takeuti, G. and Titani, S.",
}


@article{esteva2013,
title = "A logical approach to fuzzy truth hedges",
journal = "Information Sciences",
volume = "232",
pages = "366 - 385",
year = "2013",
issn = "0020-0255",
doi = "https://doi.org/10.1016/j.ins.2012.12.010",
url = "http://www.sciencedirect.com/science/article/pii/S0020025512007931",
author = "Francesc Esteva and Lluis Godo and Carles Noguera",
keywords = "Mathematical fuzzy logic, Standard completeness, Truth hedges, -Norm based logics",
abstract = "The starting point of this paper are the works of HÃ¡jek and Vychodil on the axiomatization of truth-stressing and-depressing hedges as expansions of HÃ¡jekâ™s BL logic by new unary connectives. They showed that their logics are chain-complete, but standard completeness was only proved for the expansions over GÃ¶del logic. We propose weaker axiomatizations over an arbitrary core fuzzy logic which have two main advantages: (i) they preserve the standard completeness properties of the original logic and (ii) any subdiagonal (resp. superdiagonal) non-decreasing function on [0,1] preserving 0 and 1 is a sound interpretation of the truth-stresser (resp. depresser) connectives. Hence, these logics accommodate most of the truth hedge functions used in the literature about of fuzzy logic in a broader sense."
}


@article{coniglio2019,
    author = {Coniglio, Marcelo E. and Fariñas Del Cerro, Luis and Newton, Marques Peron},
    title = "{Modal logic with non-deterministic semantics: Part I--Propositional case}",
    journal = {Logic Journal of the IGPL},
    year = {2019},
    month = {10},
    abstract = "{Dugundji proved in 1940 that most parts of standard modal systems cannot be characterized by a single finite deterministic matrix. In the eighties, Ivlev proposed a semantics of four-valued non-deterministic matrices (which he called quasi-matrices), in order to characterize a hierarchy of weak modal logics without the necessitation rule. In a previous paper, we extended some systems of Ivlevâ™s hierarchy, also proposing weaker six-valued systems in which the (T) axiom was replaced by the deontic (D) axiom. In this paper, we propose even weaker systems, by eliminating both axioms, which are characterized by eight-valued non-deterministic matrices. In addition, we prove completeness for those new systems. It is natural to ask if a characterization by finite ordinary (deterministic) logical matrices would be possible for all those Ivlev-like systems. We will show that finite deterministic matrices do not characterize any of them.}",
    issn = {1367-0751},
    doi = {10.1093/jigpal/jzz027},
    url = {https://doi.org/10.1093/jigpal/jzz027},
    eprint = {http://oup.prod.sis.lan/jigpal/advance-article-pdf/doi/10.1093/jigpal/jzz027/30101966/jzz027.pdf},
}



@article{Bartl2012,
title = "Bivalent and other solutions of fuzzy relational equations via linguistic hedges",
journal = "Fuzzy Sets and Systems",
volume = "187",
number = "1",
pages = "103--112",
year = "2012",
issn = "0165-0114",
doi = "10.1016/j.fss.2011.05.020",
url = "http://www.sciencedirect.com/science/article/pii/S0165011411002624",
author = "Eduard Bartl and Radim B{\v e}lohl{\'a}vek and Vilem Vychodil",
keywords = "Fuzzy logic",
keywords = "Fuzzy relation",
keywords = "Fuzzy relational equation",
keywords = "Linguistic hedge"
}




@article{BeVy:hedges,
  author    = {Radim B{\v e}lohl{\'a}vek and
               Vilem Vychodil},
  title     = {Formal concept analysis and linguistic hedges},
  journal   = {International Journal of General Systems},
  volume    = {41},
  number    = {5},
  year      = {2012},
  pages     = {503-532},
  ee        = {http://dx.doi.org/10.1080/03081079.2012.685936},
  bibsource = {DBLP, http://dblp.uni-trier.de}
}
 
 

@article{konecny2011,
title = "Isotone fuzzy {G}alois connections with hedges",
journal = "Information Sciences",
volume = "181",
number = "10",
pages = "1804--1817",
year = "2011",
issn = "0020-0255",
doi = "10.1016/j.ins.2010.11.011",
author = "Jan Konecny",
keywords = "Formal concept analysis",
keywords = "Fuzzy logic",
keywords = "Isotone Galois connections"
}



 
 @article{belohlavekhedges07,
author = {R. B{\v e}lohl{\'a}vek and V. Vychodil},
title = "Fuzzy Concept Lattices Constrained by Hedges",
journal = "Journal of Advanced Computational Intelligence and Intelligent Informatics",
volume = "11",
pages = "536--545",
year = "2007",
Abstract = {Utiliza solo dos hedges uno para objetos y otro para los atributos. La idea es disminuir los valores para tener menos conceptos},
}
   
    
 @article{belohlavekhedges06,
author = {R. B{\v e}lohl{\'a}vek and V. Vychodil},
title = "Thresholds and Shifted Attributes in Formal Concept Analysis of Data with Fuzzy Attributes",
journal = "Lecture Notes in Computer Science",
volume = "11",
pages = "117--130",
year = "2006",
Abstract = {Utiliza solo dos hedges uno para objetos y otro para los atributos. Es como el belohlavekhedges07 metiendo la umbralización como el articulo...  La idea final es disminuir los valores para tener menos conceptos},
}
    
    
    @article{hajek01,
title = "On very true ",
journal = "Fuzzy Sets and Systems ",
volume = "124",
number = "3",
pages = "329 - 333",
year = "2001",
issn = "0165-0114",
doi = "http://dx.doi.org/10.1016/S0165-0114(01)00103-8",
url = "http://www.sciencedirect.com/science/article/pii/S0165011401001038",
author = "Petr H\'ajek",
abstract = "The fuzzy truth value âœvery trueâ is formalized as a unary connective (hedge). A complete axiomatization is presented. "
}


    
%:%%%%%%%%%%%% GRANULARITY

@article{Kang2012FSS,
title = "Formal concept analysis based on fuzzy granularity base for different granulations",
journal = "Fuzzy Sets and Systems",
volume = "203",
number = "0",
pages = "33--48",
year = "2012",
issn = "0165-0114",
doi = "10.1016/j.fss.2012.03.003",
url = "http://www.sciencedirect.com/science/article/pii/S0165011412001157",
author = "Xiangping Kang and Deyu Li and Suge Wang and Kaishe Qu",
keywords = "Formal concept analysis",
keywords = "Granular computing",
keywords = "Fuzzy equivalence relation",
keywords = "Rule extraction",
keywords = "Decision inference",
abstract = "This paper introduces granular computing (GrC) into formal concept analysis (FCA). It provides a unified model for concept lattice building and rule extraction on a fuzzy granularity base for different granulations. One of the strengths of GrC is that larger granulations help to hide some specific details, whereas FCA in a GrC context can prevent losses due to concept lattice complexity. However, the number of superfluous rules increases exponentially with the scale of the decision context. To overcome this we present some inference rules and maximal rules and prove that the set of all these maximal rules is complete and nonredundant. Thus, users who want to obtain decision rules should generate maximal rules. Examples demonstrate that application of the method is valid and practicable. In summary, this approach utilizes FCA in a GrC context and provides a practical basis for data analysis and processing."
}

%:%%%%%%%%%%%%% ATTRIBUTE REDUCTION FCA 

@article{konecny2019,
title = "On attribute reduction in concept lattices: The polynomial time discernibility matrix-based method becomes the {CR}-method",
journal = "Information Sciences",
volume = "491",
pages = "48 - 62",
year = "2019",
issn = "0020-0255",
doi = "https://doi.org/10.1016/j.ins.2019.03.038",
url = "http://www.sciencedirect.com/science/article/pii/S0020025519302415",
author = "Jan Konecny and Petr Kraj{\v c}a",
keywords = "Classification of attributes, Formal concept analysis, Reduction in concept lattice, Discernibility matrix, Algorithm",
abstract = "We eliminate unnecessary computations of attribute discernibility sets in discernibility matrix-based methods (DM-methods) of attribute reduction in concept lattices. We obtain a polynomial time algorithm we call a Skim DM-method. The Skim DM-method however is merely slightly different from the standard clarification and reduction (CR-method). This result enables us to express a relationship of the CR-method and the DM-methods: the DM-methods are basically the CR-method with up to an exponential amount of unnecessary computations. Additionally, we experimentally evaluate the Skim DM-method in comparison with the CR-method."
}

@article{chen2019,
title = "A fast attribute reduction method for large formal decision contexts",
journal = "International Journal of Approximate Reasoning",
volume = "106",
pages = "1--17",
year = "2019",
issn = "0888-613X",
doi = "https://doi.org/10.1016/j.ijar.2018.12.002",
url = "http://www.sciencedirect.com/science/article/pii/S0888613X18301403",
author = "Jinkun Chen and Jusheng Mi and Bin Xie and Yaojin Lin",
keywords = "Attribute reduction, Concept lattices, Formal decision contexts, Graph theory",
abstract = "Attribute reduction in formal decision contexts is an important issue in formal concept analysis, which can help us to discover the knowledge hidden in formal decision contexts. However, most reduction methods in formal decision contexts are very time-consuming due to two main problems. The first is that one needs to construct a discernibility matrix after generating all the formal concepts of formal decision contexts. This is not an easy task because it requires much more storage space and computation time. Another problem is that most reduction methods are based on the Boolean reasoning and the computational complexity of which is exponential in the worst case. To overcome these problems, we propose a new attribute reduction method for formal decision contexts in this paper. A more simplified discernibility matrix which does not need to generate all the formal concepts is first constructed. It shows that the storage space and computation time are far less than the original method. Furthermore, different from the Boolean reasoning method, an approximation algorithm for obtaining a minimum reduct in formal decision contexts based on graph theory is designed. Finally, experiments are carried out to verify the effectiveness of the proposed method. The results, on 22 large data sets, demonstrate that the proposed method not only produces smaller subset of attributes but also has better performance in both storage space and speed."
}


@InProceedings{buruscoipmu2018,
author="Alcalde, Cristina
and Burusco, Ana",
editor="Medina, Jes{\'u}s
and Ojeda-Aciego, Manuel
and Verdegay, Jos{\'e} Luis
and Pelta, David A.
and Cabrera, Inma P.
and Bouchon-Meunier, Bernadette
and Yager, Ronald R.",
title="Study of the Relevance of Objects and Attributes of {L}-fuzzy Contexts Using Overlap Indexes",
booktitle="Information Processing and Management of Uncertainty in Knowledge-Based Systems. Theory and Foundations",
year="2018",
publisher="Springer International Publishing",
address="Cham",
pages="537--548",
abstract="Objects and attributes play an important role in an L-fuzzy context. From the point of view of the L-fuzzy concepts, some of them can be more relevant than others. Besides, the number of objects and attributes of the L-fuzzy context is one of the most important factors that influence in the size of the L-fuzzy concept lattice. In this paper, we define different rankings for the objects and the attributes according to their relevance in the L-fuzzy concept lattice and using different overlap indexes. These rankings can be useful for the reduction of the L-fuzzy context size.",
isbn="978-3-319-91473-2"
}


@article{konecny2018,
title = "On attribute reduction in concept lattices: Experimental evaluation shows discernibility matrix based methods inefficient",
journal = "Information Sciences",
volume = "467",
pages = "431 - 445",
year = "2018",
issn = "0020-0255",
doi = "https://doi.org/10.1016/j.ins.2018.08.004",
url = "http://www.sciencedirect.com/science/article/pii/S0020025518306091",
author = "Jan Konecny and Petr Kraj{\v c}a",
keywords = "Experimental evaluation, Formal concept analysis, Reduction in concept lattice, Discernibility matrix",
abstract = "In recent years, discernibility matrix based methods of attribute reduction in concept lattices (DM-methods) enjoyed an increase in attention and were applied in many extensions of formal concept analysis. In our previous paper, we pointed out that there exists an older method (CR-method) with theoretically lesser time complexity and we proposed a wrapping procedure to use the CR-method in any extension where the DM-methods are used. Now we evaluate the methods experimentally. Results of the evaluation assert our previous theoretical findings that the CR-method is strictly superior as it outperforms the DM-methods by several order of magnitude. To emphasize the poor performance of the DM-methods we introduce a new naÃ¯ve and deliberately slow algorithm called SIMPEL. Subsequently, we show that even its performance is not so bad in comparison with the DM-methods. Our conclusions are that it is inefficient to use the DM-methods for attribute reduction in concept lattices and that the CR-method should be used instead in practice."
}


@Inbook{Tilley2005,
author="Tilley, Thomas
and Cole, Richard
and Becker, Peter
and Eklund, Peter",
editor="Ganter, Bernhard
and Stumme, Gerd
and Wille, Rudolf",
title="A Survey of Formal Concept Analysis Support for Software Engineering Activities",
bookTitle="Formal Concept Analysis: Foundations and Applications",
year="2005",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="250--271",
isbn="978-3-540-31881-1",
doi="10.1007/11528784_13",
url="http://dx.doi.org/10.1007/11528784_13"
}




@article{Pacheco201769,
title = "Attribute clustering using rough set theory for feature selection in fault severity classification of rotating machinery ",
journal = "Expert Systems with Applications ",
volume = "71",
number = "",
pages = "69 - 86",
year = "2017",
issn = "0957-4174",
doi = "https://doi.org/10.1016/j.eswa.2016.11.024",
url = "http://www.sciencedirect.com/science/article/pii/S0957417416306595",
author = "Fannia Pacheco and Mariela Cerrada and René-Vinicio Sánchez and Diego Cabrera and Chuan Li and José Valente de Oliveira",
keywords = "Attribute clustering",
keywords = "Rough set",
keywords = "Feature selection",
keywords = "Fault severity classification",
keywords = "Rotating machinery ",
abstract = "Abstract Features extracted from real world applications increase dramatically, while machine learning methods decrease their performance given the previous scenario, and feature reduction is required. Particularly, for fault diagnosis in rotating machinery, the number of extracted features are sizable in order to collect all the available information from several monitored signals. Several approaches lead to data reduction using supervised or unsupervised strategies, where the supervised ones are the most reliable and its main disadvantage is the beforehand knowledge of the fault condition. This work proposes a new unsupervised algorithm for feature selection based on attribute clustering and rough set theory. Rough set theory is used to compute similarities between features through the relative dependency. The clustering approach combines classification based on distance with clustering based on prototype to group similar features, without requiring the number of clusters as an input. Additionally, the algorithm has an evolving property that allows the dynamic adjustment of the cluster structure during the clustering process, even when a new set of attributes feeds the algorithm. That gives to the algorithm an incremental learning property, avoiding a retraining process. These properties define the main contribution and significance of the proposed algorithm. Two fault diagnosis problems of fault severity classification in gears and bearings are studied to test the algorithm. Classification results show that the proposed algorithm is able to select adequate features as accurate as other feature selection and reduction approaches. "
}




@article{Cornejo2017,
title = "Attribute and size reduction mechanisms in multi-adjoint concept lattices ",
journal = "Journal of Computational and Applied Mathematics ",
volume = "318",
number = "",
pages = "388--402",
year = "2017",
issn = "0377-0427",
doi = "https://doi.org/10.1016/j.cam.2016.07.012",
url = "http://www.sciencedirect.com/science/article/pii/S0377042716303314",
author = "M. Eugenia Cornejo and Jes\'us Medina and Elo\'isa Ram\'irez-Poussa",
keywords = "Fuzzy sets",
keywords = "Formal concept analysis",
keywords = "Concept lattice reduction ",
abstract = "Abstract Attribute reduction and size reduction in concept lattices are key research topics in Formal Concept Analysis (FCA). This paper combines both strategies in the multi-adjoint concept lattice framework in order to simplify the information provided by the original context. Specifically, we present three procedures which merge the attribute reduction and the size reduction by means of an irreducible alpha-cut concept lattice, analyzing the obtained properties. "
}



@article{Singh2014437,
title = "Bipolar fuzzy graph representation of concept lattice ",
journal = "Information Sciences ",
volume = "288",
number = "",
pages = "437 - 448",
year = "2014",
issn = "0020-0255",
doi = "https://doi.org/10.1016/j.ins.2014.07.038",
url = "http://www.sciencedirect.com/science/article/pii/S0020025514007476",
author = "Prem Kumar Singh and Ch. Aswani Kumar",
keywords = "Bipolar fuzzy graph",
keywords = "Bipolar information",
keywords = "Formal concept analysis",
keywords = "Fuzzy concept lattice",
keywords = "Fuzzy formal concept ",
abstract = "Abstract Formal Concept Analysis (FCA) is a mathematical framework for knowledge processing tasks. \{FCA\} has been successfully incorporated into fuzzy setting and its extension (interval-valued fuzzy set) for handling vagueness and impreciseness in data. However, the analysis in such settings is restricted to unipolar space. Recently, some applications of bipolar information are shown in bipolar fuzzy graph, lattice theory as well as in FCA. The adequate analysis of bipolar information using \{FCA\} requires incorporation of bipolar fuzzy set and an appropriate lattice structure. For this purpose, we propose an algorithm for generating the bipolar fuzzy formal concepts, a method for cut of bipolar fuzzy formal context and its implications with illustrative examples. "
}

@article{Singh2017,
title = "Complex vague set based concept lattice ",
journal = "Chaos, Solitons \& Fractals ",
volume = "96",
number = "",
pages = "145 - 153",
year = "2017",
note = "",
issn = "0960-0779",
doi = "https://doi.org/10.1016/j.chaos.2017.01.019",
url = "http://www.sciencedirect.com/science/article/pii/S0960077917300255",
author = "Prem Kumar Singh",
keywords = "Complex vague set",
keywords = "Concept lattice",
keywords = "Formal concept analysis",
keywords = "Formal fuzzy concept",
keywords = "Vague graph",
keywords = "Knowledge representation ",
abstract = "Abstract Recently, the calculus of concept lattice is extended from unipolar to bipolar fuzzy space for precise measurement of vagueness in the attributes based on their acceptation and rejection part. These extensions still unable to highlight the uncertainty in vague attributes and measurement of fluctuation at given phase of time. To conquer this problem, current paper proposed a method for adequate analysis of vagueness and uncertainty in data with fuzzy attributes using the amplitude and phase term of a defined complex vague set based concept lattice. In addition, the analysis derived from the proposed method is compared with \{CVSS\} method through an illustrative example. "
}

@Article{Singh2016,
author="Singh, Prem Kumar
and Kumar, Cherukuri Aswani",
title="Concept lattice reduction using different subset of attributes as information granules",
journal="Granular Computing",
year="2016",
pages="1--15",
abstract="In recent years, the output of formal concept analysis has been widely spread in various research fields for knowledge processing tasks. In this process, a major issues arises when large number of formal concepts are generated from the given context. Available approaches lacks in user required dynamic reduction of concept lattice based on shape and size of the given problem. To overcome this problem, the current paper proposes a method to control the size of concept lattice based on user defined subset of attributes (or objects). Further the proposed method provides a way to select some of the important concepts generated from chosen subset of attributes. For this purpose properties of Shannon entropy is utilized by the proposed method to select some of the important concepts at different granulation of their computed weight. The analysis derived from the proposed method is also compared with recently published granulation tree method with an empirical analysis.",
issn="2364-4974",
doi="10.1007/s41066-016-0036-z",
url="http://dx.doi.org/10.1007/s41066-016-0036-z"
}


@Article{Singh2016b,
author="Singh, Prem Kumar
and Aswani Kumar, C.
and Li, Jinhai",
title="Knowledge representation using interval-valued fuzzy formal concept lattice",
journal="Soft Computing",
year="2016",
volume="20",
number="4",
pages="1485--1502",
abstract="Formal concept analysis (FCA) is a mathematical framework for data analysis and processing tasks. Based on the lattice and order theory, FCA derives the conceptual hierarchies from the relational information systems. From the crisp setting, FCA has been extended to fuzzy environment. This extension is aimed at handling the uncertain and vague information represented in the form of a formal context whose entries are the degrees from the scale [0, 1]. The present study analyzes the fuzziness in a given many-valued context which is transformed into a fuzzy formal context, to provide an insight into generating the fuzzy formal concepts from the fuzzy formal context. Furthermore, considering that a major problem in FCA with fuzzy setting is to reduce the number of fuzzy formal concepts thereby simplifying the corresponding fuzzy concept lattice structure, the current paper solves the problem by linking an interval-valued fuzzy graph to the fuzzy concept lattice. For this purpose, we propose an algorithm for generating the interval-valued fuzzy formal concepts. To measure the weight of fuzzy formal concepts, an algorithm is proposed using Shannon entropy. The knowledge represented by formal concepts using interval-valued fuzzy graph is compared with entropy-based-weighted fuzzy concepts at chosen threshold.",
issn="1433-7479",
doi="10.1007/s00500-015-1600-1",
url="http://dx.doi.org/10.1007/s00500-015-1600-1"
}

@incollection{Skowron1992DMFIS,
  title={The discernibility matrices and functions in information systems},
  author={Skowron, Andrzej and Rauszer, Cecylia},
  booktitle={Intelligent decision support},
  pages={331--362},
  year={1992},
  publisher={Springer}
}


@article{Zhao2007,
title = "Data analysis based on discernibility and indiscernibility ",
journal = "Information Sciences ",
volume = "177",
number = "22",
pages = "4959 - 4976",
year = "2007",
note= "",
issn = "0020-0255",
doi = "https://doi.org/10.1016/j.ins.2007.06.031",
url = "http://www.sciencedirect.com/science/article/pii/S0020025507003271",
author = "Yan Zhao and Yiyu Yao and Feng Luo",
keywords = "Rough sets",
keywords = "Indiscernibility and discernibility relations",
keywords = "Indiscernibility and discernibility matrices",
keywords = "Reducts ",
abstract = "Rough set theory models similarities and differences of objects based on the notions of indiscernibility and discernibility. With respect to any subset of attributes, one can define two pairs of dual relations: the strong indiscernibility and weak discernibility relations, and the weak indiscernibility and strong discernibility relations. The similarities of objects are examined by the indiscernibility relations, and the differences by the discernibility relations, respectively. Alternatively, one can construct an indiscernibility matrix to represent the family of strong indiscernibility or weak discernibility relations. One also can construct a discernibility matrix to represent the family of strong discernibility or weak indiscernibility relations. The consideration of the matrix-counterpart of relations, and the relation-counterpart of matrices, brings more insights into rough set theory. Based on indiscernibility and discernibility, three different types of reducts can be constructed, keeping the indiscernibility, discernibility, and indiscernibility-and-discernibility relations, respectively. Although the indiscernibility reducts have been intensively studied in the literature, the other two types of reducts are relatively new and require more attention. The existing methods for constructing the indiscernibility reducts also can be applied to construct the other two types of reducts. An empirical experiment for letter recognition is reported for demonstrating the usefulness of the discussed relations and reducts. "
}

@article{Dias2017,
title = "A methodology for analysis of concept lattice reduction ",
journal = "Information Sciences ",
volume = "396",
number = "",
pages = "202 - 217",
year = "2017",
note= "",
issn = "0020-0255",
doi = "https://doi.org/10.1016/j.ins.2017.02.037",
url = "http://www.sciencedirect.com/science/article/pii/S0020025517305388",
author = "Sergio M. Dias and Newton J. Vieira",
keywords = "Formal concept analysis",
keywords = "Lattice reduction",
keywords = "Proper implications ",
abstract = "Abstract Formal concept analysis (FCA) is a mathematical theory of data analysis with applications in many areas. The problem of obtaining a concept lattice of an appropriate size was identified in several applications as one of the most important problems of FCA. In order to deal with this problem several techniques with different characteristics were proposed for concept lattice reduction. However, there are currently no adequate methods to assess what types of knowledge transformations can result from a reduction. A methodology for analysis of concept lattice reduction is presented here. It is based on the use of sets of proper implications holding in the original and reduced formal contexts or concept lattices. Working with both sets of implications, the methodology is able to show what is preserved, eliminated, inserted or transformed by a reduction technique. Three classes of reduction techniques are analyzed from the standpoint of the methodology in order to highlight techniques of each class have in common with respect to the transformations performed. Such analysis is followed by specific examples in each class."
}

@article{Shao2014,
title = "Relations between granular reduct and dominance reduct in formal contexts ",
journal = "Knowledge-Based Systems ",
volume = "65",
number = "",
pages = "1 - 11",
year = "2014",
note= "",
issn = "0950-7051",
doi = "https://doi.org/10.1016/j.knosys.2014.03.006",
url = "http://www.sciencedirect.com/science/article/pii/S0950705114000896",
author = "Ming-Wen Shao and Yee Leung",
keywords = "Attribute reduction",
keywords = "Concept lattice",
keywords = "Dominance relation",
keywords = "Formal concept analysis",
keywords = "Rough set ",
abstract = "Abstract One of the key issues of knowledge discovery and data mining is knowledge reduction. Attribute reduction of formal contexts based on the granules and dominance relation are first reviewed in this paper. Relations between granular reduts and dominance reducts are investigated with the aim to establish a bridge between the two reduction approaches. We obtain meaningful results showing that granule-based and dominance-relation-based attribute reducts and attribute characteristics are identical. Utilizing dominance reducts and attribute characteristics, we can obtain all granular reducts and attribute characteristics by the proposed approach. In addition, we establish relations between dominance classes and irreducible elements, and present some judgment theorems with respect to the irreducible elements. "
}


@article{Kumar2012,
author = { Ch. Aswani Kumar },
title = {FUZZY CLUSTERING-BASED FORMAL CONCEPT ANALYSIS FOR ASSOCIATION RULES MINING},
journal = {Applied Artificial Intelligence},
volume = {26},
number = {3},
pages = {274-301},
year = {2012},
doi = {10.1080/08839514.2012.648457},
abstract = { Formal Concept Analysis (FCA), in which data is represented as a formal context, offers a framework for Association Rules Mining (ARM) by handling functional dependencies in the data. However, with the size of the formal context, the number of rules grows exponentially. In this article, we apply Fuzzy K-Means clustering on the data set to reduce the formal context and FCA on the reduced data set for mining association rules. With experiments on two real-world healthcare data sets, we offer the evidence for performance of FKM-based FCA in mining association rules. }
}


@article{Kwon:2011,
author = {Kwon, Ohbyung and Lee, Yonnim and Sarangib, Debashis},
title = {A {G}alois Lattice Approach to a Context-aware Privacy Negotiation Service},
journal = {Expert Syst. Appl.},
issue_date = {September, 2011},
volume = {38},
number = {10},
month = sep,
year = {2011},
issn = {0957-4174},
pages = {12619--12629},
numpages = {11},
url = {http://dx.doi.org/10.1016/j.eswa.2011.04.050},
doi = {10.1016/j.eswa.2011.04.050},
acmid = {1994841},
publisher = {Pergamon Press, Inc.},
address = {Tarrytown, NY, USA},
keywords = {Agent technology, Concept lattice, Context-aware service, Privacy negotiation, Privacy ontology},
}

@article{Madeira2004, 
author = {Madeira, Sara C. and Oliveira, Arlindo L.}, 
title = {Biclustering Algorithms for Biological Data Analysis: A Survey}, 
journal = {IEEE/ACM Trans. Comput. Biol. Bioinformatics}, 
issue_date = {January 2004}, 
volume = {1}, 
number = {1}, 
month = jan, 
year = {2004}, 
issn = {1545-5963}, 
pages = {24--45}, 
numpages = {22}, 
url = {http://dx.doi.org/10.1109/TCBB.2004.2}, 
doi = {10.1109/TCBB.2004.2}, 
acmid = {1024313}, 
publisher = {IEEE Computer Society Press}, 
address = {Los Alamitos, CA, USA}, 
keywords = {Biclustering, simultaneous clustering, coclustering, subspace clustering, bidimensional clustering, direct clustering, block clustering, two-way clustering, two-mode clustering, two-sided clustering, microarray data analysis, biological data analysis, gene expression data.},
}


@article{Kaytoue2011,
title = "Mining gene expression data with pattern structures in formal concept analysis ",
journal = "Information Sciences ",
volume = "181",
number = "10",
pages = "1989 - 2001",
year = "2011",
issn = "0020-0255",
doi = "https://doi.org/10.1016/j.ins.2010.07.007",
url = "http://www.sciencedirect.com/science/article/pii/S0020025510003257",
author = "Mehdi Kaytoue and Sergei O. Kuznetsov and Amedeo Napoli and SÃ©bastien Duplessis",
keywords = "Formal concept analysis",
keywords = "Conceptual scaling",
keywords = "Numerical data",
keywords = "Pattern structures",
keywords = "Gene expression data ",
abstract = "This paper addresses the important problem of efficiently mining numerical data with formal concept analysis (FCA). Classically, the only way to apply \{FCA\} is to binarize the data, thanks to a so-called scaling procedure. This may either involve loss of information, or produce large and dense binary data known as hard to process. In the context of gene expression data analysis, we propose and compare two FCA-based methods for mining numerical data and we show that they are equivalent. The first one relies on a particular scaling, encoding all possible intervals of attribute values, and uses standard \{FCA\} techniques. The second one relies on pattern structures without a priori transformation, and is shown to be more computationally efficient and to provide more readable results. Experiments with real-world gene expression data are discussed and give a practical basis for the comparison and evaluation of the methods. "
}


    
%:%%%%%%%%%%%%% ATTRIBUTE REDUCTION FCA and ROUGH SETS

@Inbook{cornejolinguistic2022,
author="Cornejo, M. Eugenia
and Medina, Jes{\'u}s
and Rubio-Manzano, Clemente",
editor="Harmati, Istv{\'a}n {\'A}.
and K{\'o}czy, L{\'a}szl{\'o} T.
and Medina, Jes{\'u}s
and Ram{\'i}rez-Poussa, Elo{\'i}sa",
title="Linguistic Descriptions of Data Via Fuzzy Formal Concept Analysis",
bookTitle="Computational Intelligence and Mathematics for Tackling Complex Problems 3",
year="2022",
publisher="Springer International Publishing",
address="Cham",
pages="119--125",
abstract="In this paper, a new approach for automatically generating linguistic descriptions by using residuated formal concept analysis is introduced and detailed. The main idea is to create a linguistic description from a database which has been previously transformed into a fuzzy formal context via a set of linguistic variables. From the obtained context, linguistic descriptions can be automatically generated through the information provided by the meet-irreducible concepts.",
isbn="978-3-030-74970-5",
doi="10.1007/978-3-030-74970-5_14",
url="https://doi.org/10.1007/978-3-030-74970-5_14"
}




@article{QIAN201838,
title = "Local rough set: A solution to rough data analysis in big data",
journal = "International Journal of Approximate Reasoning",
volume = "97",
pages = "38 - 63",
year = "2018",
issn = "0888-613X",
doi = "https://doi.org/10.1016/j.ijar.2018.01.008",
url = "http://www.sciencedirect.com/science/article/pii/S0888613X17304826",
author = "Yuhua Qian and Xinyan Liang and Qi Wang and Jiye Liang and Bing Liu and Andrzej Skowron and Yiyu Yao and Jianmin Ma and Chuangyin Dang",
keywords = "Rough set theory, Local rough set, Concept approximation, Attribute reduction, Limited labeled data",
abstract = "As a supervised learning method, classical rough set theory often requires a large amount of labeled data, in which concept approximation and attribute reduction are two key issues. With the advent of the age of big data however, labeling data is an expensive and laborious task and sometimes even infeasible, while unlabeled data are cheap and easy to collect. Hence, techniques for rough data analysis in big data using a semi-supervised approach, with limited labeled data, are desirable. Although many concept approximation and attribute reduction algorithms have been proposed in the classical rough set theory, quite often, these methods are unable to work well in the context of limited labeled big data. The challenges to classical rough set theory can be summarized with three issues: limited labeled property of big data, computational inefficiency and over-fitting in attribute reduction. To address these three challenges, we introduce a theoretic framework called local rough set, and develop a series of corresponding concept approximation and attribute reduction algorithms with linear time complexity, which can efficiently and effectively work in limited labeled big data. Theoretical analysis and experimental results show that each of the algorithms in the local rough set significantly outperforms its original counterpart in classical rough set theory. It is worth noting that the performances of the algorithms in the local rough set become more significant when dealing with larger data sets."
}


@article{XIE2018443,
title = "A novel incremental attribute reduction approach for dynamic incomplete decision systems",
journal = "International Journal of Approximate Reasoning",
volume = "93",
pages = "443 - 462",
year = "2018",
issn = "0888-613X",
doi = "https://doi.org/10.1016/j.ijar.2017.12.002",
url = "http://www.sciencedirect.com/science/article/pii/S0888613X17302918",
author = "Xiaojun Xie and Xiaolin Qin",
keywords = "Rough set, Attribute reduction, Dynamic data, Incomplete decision system",
abstract = "Attribute reduction is an important process in data mining and knowledge discovery. In dynamic data environments, the attribute reduction problem has three issues: variation of object sets, variation of attribute sets and variation of attribute values. For the first two issues, a few achievements have been made. For variation of the attribute values, current attribute reduction approaches are not efficient, because the method becomes a non-incremental or inefficient one in some cases. In order to address this, we first introduce the concept of an inconsistency degree in an incomplete decision system and prove that the attribute reduction based on the inconsistency degree is equivalent to that based on the positive region. Then, three update strategies of inconsistency degree for dynamic incomplete decision systems are provided. Finally, the framework of the incremental attribute reduction algorithm is proposed. Experiments on different data sets from UCI show the accuracy and feasibility of the proposed incremental reduction algorithms."
}

@article{huang2018,
title = "Inclusion measure-based multi-granulation decision-theoretic rough sets in multi-scale intuitionistic fuzzy information tables",
journal = "Information Sciences",
year = "2018",
issn = "0020-0255",
doi = "https://doi.org/10.1016/j.ins.2018.08.061",
url = "http://www.sciencedirect.com/science/article/pii/S0020025518306790",
author = "Bing Huang and Wei-Zhi Wu and Jinjiang Yan and Huaxiong Li and Xianzhong Zhou",
keywords = "Decision-theoretic rough sets, Intuitionistic fuzzy sets, Multi-granulation rough sets, Multi-scale information table, Optimal scale selection, Reduction",
abstract = "Multi-granulation rough sets (MGRSs) and decision-theoretic rough sets (DTRSs) are important and popular extended types of Pawlakâ™s classical rough set model. Multi-granulation DTRSs (MG-DTRSs), which combine these two generalized rough set models, have been investigated in depth in recent years to handle noisy distributed data. However, this combination cannot be used to acquire knowledge from multi-scale information systems, in which an object may take on different values under the same attribute depending on the scale used to measure it. Two novel types of MG-DTRSs in multi-scale intuitionistic fuzzy (IF) information tables have been developed on the basis of IF inclusion measures in this study to solve this problem. First, we introduce a type of inclusion measure between two IF sets and present the concept of inclusion measure-based DTRSs in multi-scale IF information tables. Second, we present the inclusion measure-based optimistic and pessimistic MG-DTRSs in multi-scale IF information tables, examine their properties, and analyze the three-way decision method based on the presented models. Third, we define the optimal scale selection and present the two optimal scale selection algorithms based on MG-DTRSs in multi-scale IF information tables. Fourth, we provide the reducts of the optimal scales based on MG-DTRSs in multi-scale IF information tables, examine the discernibility function reduction method, and devise two algorithms for computing an optimal approximation scale reduct. Finally, we discuss several possible generalizations related to MG-DTRSs in multi-scale IF information tables. This study provides an MG-DTRS method for acquiring knowledge from multi-scale IF information tables."
}

@article{yao2017601,
title = "Class-specific attribute reducts in rough set theory",
journal = "Information Sciences",
volume = "418-419",
pages = "601 - 618",
year = "2017",
issn = "0020-0255",
doi = "https://doi.org/10.1016/j.ins.2017.08.038",
url = "http://www.sciencedirect.com/science/article/pii/S002002551730885X",
author = "Yiyu Yao and Xianyong Zhang",
keywords = "Classification-based attribute reduct, Class-specific attribute reduct, Rough set, Three-way classification, Three-way decision, Feature selection",
abstract = "The concept of attribute reducts plays a fundamental role in rough set analysis. There are at least two possibilities to define an attribute reduct. A classification-based or global attribute reduct is a minimal subset of condition attributes that preserves the positive region of the decision classification, namely, the positive regions of all decision classes, in a decision table. A class-specific, class-dependent, or local attribute reduct is a minimal subset of condition attributes that preserves the positive region of a particular decision class. While a classification-based reduct may not work equally well for every decision class, a class-specific attribute reduct is optimally tailored to a particular decision class. However, studies in rough set theory are dominated by classification-based reducts; there is very limited investigation on class-specific reducts. An objective of this paper is to draw attention to class-specific reducts. We systematically compare the two types of reducts and investigate their relationships with respect to both individual reducts and families of all reducts. It is possible to derive a class-specific reduct from a classification-based reduct and to derive a classification-based reduct from a family of class-specific reducts. The families of all class-specific reducts provide a pair of lower and upper bounds of the family of all classification-based reducts. Based on a three-way classification of attributes into the pair-wise disjoint sets of core, marginal, and nonuseful attributes, we examine relationships between the corresponding classes of classification-based and class-specific attributes. The union of the sets of class-specific core attributes is the set of classification-based core attributes. It is only possible to obtain an upper bound for the set of classification-based marginal attributes and a lower bound for the set of classification-based nonuseful attributes from the family of the class-specific corresponding sets of attributes."
}

 @inproceedings{fuzzieee17:redobject,
	Author = {J. Medina and E. Ramírez-Poussa},
	Booktitle = {{IEEE} Intl. Conf. on Fuzzy 
Systems ({FUZZ-IEEE} 2017)},
	Title = {Towards attribute reduction in object-oriented concept lattices},
       location  = {Naples, Italy)},
	Year = {2017}	}

@inproceedings{escim16:join,
	author = { J. Medina and E. Ramírez-Poussa},
         editor    = {J. Kacprzyk and L. Koczy and J. Medina},
 	Title = {Characterizing the Join Irreducible Elements of Multi-adjoined
Object-oriented Fuzzy Concept Lattices},
         Booktitle     = {8th European Symposium on Computational Intelligence  and Mathematices (ESCIM 2016)},
        location  = {Sofia, Bulgary},
        year      = {2016},
        pages = {98--103},
	}
	
	
 



@article{Elloumi2004,
title = "A multi-level conceptual data reduction approach based on the Lukasiewicz implication ",
journal = "Information Sciences ",
volume = "163",
number = "4",
pages = "253 - 262",
year = "2004",
issn = "0020-0255",
doi = "http://dx.doi.org/10.1016/j.ins.2003.06.013",
url = "http://www.sciencedirect.com/science/article/pii/S0020025503004262",
author = "Samir Elloumi and Jihad Jaam and Ahmed Hasnah and Ali Jaoua and Ibtissem Nafkha",
keywords = "Fuzzy data reduction",
keywords = "Lukasiewicz implication",
keywords = "Fuzzy Galois connection",
keywords = "Precision level ",
abstract = "Starting from fuzzy binary data represented as tables in the fuzzy relational database, in this paper, we use fuzzy formal concept analysis to reduce the tables size to only keep the minimal rows in each table, without losing knowledge (i.e., association rules extracted from reduced databases are identical at given precision level). More specifically, we develop a fuzzy extension of a previously proposed algorithm for crisp data reduction without loss of knowledge. The fuzzy Galois connection based on the Lukasiewicz implication is mainly used in the definition of the closure operator according to a precision level, which makes data reduction sensitive to the variation of this precision level. "
}


 
@Article{kewenli2017,
author="Li, Kewen
and Shao, Ming-Wen
and Wu, Wei-Zhi",
title="A data reduction method in formal fuzzy contexts",
journal="International Journal of Machine Learning and Cybernetics",
year="2017",
month="Aug",
day="01",
volume="8",
number="4",
pages="1145--1155",
abstract="As a basic operation in data mining and knowledge discovery, data reduction can reduce the volume of the data and simplify the representation of knowledge. In this paper we propose a method of attribute reduction in a formal fuzzy context based on the notion of ``one-sided fuzzy concept''. According to the importance of attributes, we classify the attributes into three types: core attributes, relatively necessary attributes and unnecessary attributes, which are also referred to the attribute characteristics. We propose judgment theorems and the corresponding algorithms for computing the three types of attribute sets. Moreover, a straightforward attribute reduction method by virtue of attribute characteristics is formulated. We show that the computation of formal concepts on the reduced data set is made more efficient, and yet produces the same lattice structure and conceptual hierarchy as the ones derived from the original formal context.",
issn="1868-808X",
doi="10.1007/s13042-015-0485-8",
url="https://doi.org/10.1007/s13042-015-0485-8"
}



@article{Chen201516,
title = "Relations of reduction between covering generalized rough sets and concept lattices ",
journal = "Information Sciences ",
volume = "304",
number = "",
pages = "16--27",
year = "2015",
note= "",
issn = "0020-0255",
doi = "http://dx.doi.org/10.1016/j.ins.2014.11.053",
url = "http://www.sciencedirect.com/science/article/pii/S0020025514011888",
author = "Jinkun Chen and Jinjin Li and Yaojin Lin and Guoping Lin and Zhouming Ma",
keywords = "Concept lattices",
keywords = "Covering generalized rough sets",
keywords = "Formal contexts",
keywords = "Intersection reduction ",
abstract = "Abstract The reduction theory plays an important role in data analysis. This paper studies the relation between the reduction of a covering and the attribute reduction of a concept lattice. The reduction of a covering from the perspective of concept lattices is investigated. Conversely, the attribute reduction of a formal context is studied in the framework of covering generalized rough sets. The results in this paper show that the reduction of a covering can be viewed as the attribute reduction of a derivative formal context. Moreover, every reduct of a given formal context can be seen as the reduct of an induced covering. As an application of the theoretical results, an approach to the attribute reduction of concept lattices based on covering generalized rough sets is proposed. Furthermore, experiments are given to show the effectiveness of the proposed method. "
}


 



@article{pocs2012,
title = "Note on generating fuzzy concept lattices via {G}alois connections ",
journal = "Information Sciences ",
volume = "185",
number = "1",
pages = "128--136",
year = "2012",
note= "",
issn = "0020-0255",
doi = "http://dx.doi.org/10.1016/j.ins.2011.09.021",
url = "http://www.sciencedirect.com/science/article/pii/S0020025511004786",
author = "Jozef P\'ocs",
keywords = "Galois connection",
keywords = "Fuzzy concept lattice",
keywords = "Generalized concept lattice "
}







@article{pocs2013,
title = "Representation of fuzzy concept lattices in the framework of classical {FCA}",
journal = "Journal of Applied Mathematics",
volume = "2013",
pages = " 1--7",
year = "2013",
author = "Peter Butka and Jozef P\'ocs and Jana P\'osov\'a",
}

@article{butka2014,
title = "On equivalence of conceptual scaling and generalized one-sided concept lattices ",
author = "Peter Butka and Jozef P\'ocs and Jana P\'osov\'a",
journal = "Information Sciences ",
volume = "259",
number = "0",
pages = "57--70",
year = "2014",
note= "",
issn = "0020-0255",
doi = "http://dx.doi.org/10.1016/j.ins.2013.08.047",
url = "http://www.sciencedirect.com/science/article/pii/S0020025513006208",
keywords = "Formal concept analysis",
keywords = "Scaling",
keywords = "Generalized one-sided concept lattice",
keywords = "Galois connection ",
abstract = "Abstract The methods of conceptual scaling and generalized one-sided concept lattices represent different possibilities on how to deal with many-valued contexts. We briefly describe these methods and prove that they are equivalent. In particular, we show that the application of these two approaches to a given many-valued context yields the same closure system on the set of all objects. Based on this equivalence, we propose a possible attribute reduction of one-sided formal contexts. "
}




@article{pocs13,
  author    = {Peter Butka and
               Jozef P{\'{o}}cs},
  title     = {Generalization of One-Sided Concept Lattices},
  journal   = {Computing and Informatics},
  volume    = {32},
  number    = {2},
  pages     = {355--370},
  year      = {2013},
  url       = {http://www.cai.sk/ojs/index.php/cai/article/view/1625},
  timestamp = {Sat, 29 Jun 2013 19:15:03 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/cai/ButkaP13},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}


@article{ar:li2012,
author = "	Jinhai Li and  Changlin Mei and Yuejin Lv",
title = "Knowledge reduction in real decision formal contexts",
journal = "Information Sciences",
volume = "189",
pages = "191--207",
year = "2012",
}


@article{Yao2011,
title = "Attribute reduction based on generalized fuzzy evidence theory in fuzzy decision systems",
journal = "Fuzzy Sets and Systems",
volume = "170",
number = "1",
pages = "64--75",
year = "2011",
issn = "0165-0114",
doi = "10.1016/j.fss.2011.01.008",
url = "http://www.sciencedirect.com/science/article/pii/S0165011411000492",
author = "Yan-Qing Yao and Ju-Sheng Mi and Zhou-Jun Li",
keywords = "Fuzzy decision systems",
keywords = "Attribute reduction",
keywords = "Generalized fuzzy evidence theory",
keywords = "Reducts",
abstract = "Attribute reduction is viewed as an important issue in data mining and knowledge representation. This paper studies attribute reduction in fuzzy decision systems based on generalized fuzzy evidence theory. The definitions of several kinds of attribute reducts are introduced. The relationships among these reducts are then investigated. In a fuzzy decision system, it is proved that the concepts of fuzzy positive region reduct, lower approximation reduct and generalized fuzzy belief reduct are all equivalent, the concepts of fuzzy upper approximation reduct and generalized fuzzy plausibility reduct are equivalent, and a generalized fuzzy plausibility consistent set must be a generalized fuzzy belief consistent set. In a consistent fuzzy decision system, an attribute set is a generalized fuzzy belief reduct if and only if it is a generalized fuzzy plausibility reduct. But in an inconsistent fuzzy decision system, a generalized fuzzy belief reduct is not a generalized fuzzy plausibility reduct in general."
}



@article{camwa-medina,
title = "Relating attribute reduction in formal, object-oriented and property-oriented concept lattices",
journal = "Computers \& Mathematics with Applications",
volume = "64",
number = "6",
pages = "1992--2002",
year = "2012",
note= "",
issn = "0898-1221",
doi = "10.1016/j.camwa.2012.03.087",
url = "http://www.sciencedirect.com/science/article/pii/S0898122112002921",
author = "Jes\'us Medina",
keywords = "Galois connection",
keywords = "Formal concept analysis",
keywords = "Property-oriented and object-oriented concept lattices",
keywords = "Attribute reduction"
}

@article{Li2017,
title = "Comparison of reduction in formal decision contexts ",
journal = "International Journal of Approximate Reasoning ",
volume = "80",
number = "",
pages = "100 - 122",
year = "2017",
note= "",
issn = "0888-613X",
doi = "http://dx.doi.org/10.1016/j.ijar.2016.08.007",
url = "//www.sciencedirect.com/science/article/pii/S0888613X16301360",
author = "Jinhai Li and Cherukuri Aswani Kumar and Changlin Mei and Xizhao Wang",
keywords = "Formal concept analysis",
keywords = "Formal decision context",
keywords = "Rule acquisition",
keywords = "Reduction",
keywords = "Comparison ",
abstract = "Abstract In formal concept analysis, many reduction methods have recently been proposed for formal decision contexts, and each of them was to reduce formal decision contexts with a particular purpose. However, little attention has been paid to the comparison of their differences from various aspects. In fact, this problem is very important because it can provide evidence to select an appropriate reduction method for a given specific case. To address this problem, our study mainly focuses on clarifying the relationship among the existing reduction methods in formal decision contexts. Firstly, we give a rule-based review of the existing reduction methods, revealing the type of rules that each of them can preserve. Secondly, we analyze the relationship among the consistencies introduced by the existing reduction methods. More specifically, Wei's first consistency (see [39]) is stronger than others, while her second one is weaker than the remainder except Wu's consistency (see [43]). Finally, we make a comparison of the existing reductions, concluding that Li's reduction (see [14]) maintaining the non-redundant decision rules of a formal decision context is coarser than others. The results obtained in this paper are beneficial for users to select an appropriate reduction method for meeting their requirements. "
}



@article{Dias2015,
title = "Concept lattices reduction: Definition, analysis and classification ",
journal = "Expert Systems with Applications ",
volume = "42",
number = "20",
pages = "7084 - 7097",
year = "2015",
note= "",
issn = "0957-4174",
doi = "http://dx.doi.org/10.1016/j.eswa.2015.04.044",
url = "//www.sciencedirect.com/science/article/pii/S0957417415002869",
author = "SÃ©rgio M. Dias and Newton J. Vieira",
keywords = "Formal concept analysis",
keywords = "Concept lattices",
keywords = "Reduction ",
abstract = "Abstract Formal concept analysis (FCA) is currently considered an important formalism for knowledge representation, extraction and analysis with applications in different areas. A problem identified in several applications is the computational cost due to the large number of formal concepts generated. Even when that number is not very large, the essential aspects, those effectively needed, can be immersed in a maze of irrelevant details. In fact, the problem of obtaining a concept lattice of appropriate complexity and size is one of the most important problems of FCA. In literature, several different approaches to control the complexity and size of a concept lattice have been described, but so far they have not been properly analyzed, compared and classified. We propose the classification of techniques for concept lattice reduction in three groups: redundant information removal, simplification, and selection. The main techniques to reduce concept lattice are analyzed and classified based on seven dimensions, each one composed of a set of characteristics. Considerations are made about the applicability and computational complexity of approaches of different classes. "
}




@article{ZS,
author = {Shmuely, Z.},
title = {The structure of {G}alois connections},
journal = {Pacific Journal of Mathematics},
volume = {54},
number = 2,
pages = {209--225},
year = {1974},
}



@article{icfca-multi-mor,
author = {J. Medina and M. Ojeda-Aciego and J. Ruiz-Calvi{\~{n}}o},
title = {Concept-forming operators on multilattices},
journal = {Lecture Notes in Computer Science},
volume = {7880},
pages = {203--215},
year = {2013},
}



@inproceedings{cla2012-mrc,
	author = {J. Medina and J. Ruiz-Calvi{\~{n}}o},
 	Title = {Fuzzy formal concept analysis via multilattices: first prospects and results},
         Booktitle     = {The 9th International Conference on Concept Lattices and Their Applications  (CLA 2012)},
        year      = {2012},
        pages = {69--79},
	}


@inproceedings{mo:cla2010,
	author = {J. Medina and   M. Ojeda-Aciego},
 	Title = {Towards attribute reduction
in multi-adjoint concept lattices},
         Booktitle     = {The 7th International Conference on Concept Lattices and Their Applications},
        year      = {2010},
        pages = {92--103},
	}


@article{Li2010497,
title = "Attribute reduction in fuzzy concept lattices based on the {T}-implication",
journal = "Knowledge-Based Systems",
volume = "23",
number = "6",
pages = "497--503",
year = "2010",
note= "",
issn = "0950-7051",
doi = "10.1016/j.knosys.2010.03.006",
url = "http://www.sciencedirect.com/science/article/pii/S0950705110000419",
author = "Lifeng Li and Jianke Zhang",
keywords = "Fuzzy databases",
keywords = "Fuzzy formal context",
keywords = "Fuzzy concept lattice",
keywords = "Attribute reduction",

Abstract = {Este es el que revisé para FSS},
}

@article{Kumar2010,
title = "Concept lattice reduction using fuzzy K-Means clustering",
journal = "Expert Systems with Applications",
volume = "37",
number = "3",
pages = "2696--2704",
year = "2010",
note= "",
issn = "0957-4174",
doi = "10.1016/j.eswa.2009.09.026",
url = "http://www.sciencedirect.com/science/article/pii/S0957417409008070",
author = "Ch. Aswani Kumar and S. Srinivas",
keywords = "Concept lattice",
keywords = "Formal concept analysis",
keywords = "Fuzzy <span style='font-style: italic'>K</span>-Means clustering",
keywords = "Singular value decomposition",
abstract = "During the design of concept lattices, complexity plays a major role in computing all the concepts from the huge incidence matrix. Hence for reducing the size of the lattice, methods based on matrix decompositions like SVD are available in the literature. However, SVD computation is known to have large time and memory requirements. In this paper, we propose a new method based on Fuzzy K-Means clustering for reducing the size of the concept lattices. We demonstrate the implementation of proposed method on two application areas: information retrieval and information visualization."
}




@article{Wei2010,
title = "Relation between concept lattice reduction and rough set reduction",
journal = "Knowledge-Based Systems",
volume = "23",
number = "8",
pages = "934--938",
year = "2010",
note= "",
issn = "0950-7051",
doi = "10.1016/j.knosys.2010.07.001",
url = "http://www.sciencedirect.com/science/article/pii/S0950705110001073",
author = "Ling Wei and Jian-Jun Qi",
keywords = "Rough set",
keywords = "Concept lattice",
keywords = "Reduction",
keywords = "Consistent set",
keywords = "Formal concept analysis",
Abstract = {Parece similar al que envié al CAMWA, hay que mirar para comprobarlo},
}


 @article{zhang08,
author = {W.X. Zhang and L. Wei and J.J. Qi},
title = {Attribute Reduction in Concept Lattice Based on Discernibility Matrix},
journal = {Lecture Notes in Computer Science},
volume = {3642},
pages = {157--165},
year = {2005},
Abstract = {Reduction de atributos  en classical utilizando discernibility sets, pero necesita calcular todos los conceptos},
}

@article{liu-mi08,
author = {Jing Liu and Ju-Sheng Mi},
title = {A Novel Approach to Attribute Reduction in
Formal Concept Lattices},
journal = {Lecture Notes in Computer Science},
volume = {5009},
pages = {426--433},
year = {2008},
Abstract = {Mejora a zhang08, pero sigue  necesitando calcular todos los conceptos},
}

 @article{li08,
author = {Fachao Li and Chao Gao  and Chenxia Jin},
title = {Attribute Reduction Based on the Fuzzy Information
Filter Operators},
journal = {Lecture Notes in Computer Science},
volume = {5227},
pages = {367--375},
year = {2008},
Abstract = {Reduction de atributos  en classical rough sets},
}

@article{yao-ar-08,
author = {Yiyu Yao and Yan Zhao},
title = {Attribute Reduction in Decision-Theoretic Rough Set Models},
journal = {Information Sciences},
volume = {178},
number = {17},
pages = {3356--3373},
year = {2008},
Abstract = {Reduction de atributos  en classical rough sets, con aplicaciones},
}


    
 @article{wang08,
author = {Xia Wang  and  Wenxiu Zhang},
title = {Relations of attribute reduction between object and property oriented
concept lattices},
journal = {Knowledge-Based Systems},
volume = {21},
pages = {398--403},
year = 2008},
Abstract = {Reduction de atributos  en object and property oriented
concept lattices(en generalizaci\'on fuzzy de rough sets)},
}
   
    
 @article{liured:2007,
author = {Min Liu and Mingwen Shao and  Wenxiu Zhang and Cheng Wu},
title = {Reduction method for concept lattices based on rough set theory and
its application},
journal = {Computers and Mathematics with Applications},
volume = {53},
pages = {1390--1410},
year = 2007},
Abstract = {Reduction de atributos  en object and property oriented
concept lattices},
}
   
    
 @article{chrisAS10,
author = {Chris Cornelis and Richard Jensen and Germ\'an Hurtado and  Dominik \'{S}l\c{e}zak},
title = {Attribute selection with fuzzy decision reducts},
journal = {Information Sciences},
volume = {180},
pages = {209--224},
year = 2010},
}

@ARTICLE{Chris07,
author={Martine De Cock and Chris Cornelis and Etienne E. Kerre},
journal={Fuzzy Systems, IEEE Transactions on},
title={Fuzzy Rough Sets: The Forgotten Step},
year={2007},
month={feb. },
volume={15},
number={1},
pages={121--130},
abstract={Traditional rough set theory uses equivalence relations to compute lower and upper approximations of sets. The corresponding equivalence classes either coincide or are disjoint. This behaviour is lost when moving on to a fuzzy T-equivalence relation. However, none of the existing studies on fuzzy rough set theory tries to exploit the fact that an element can belong to some degree to several "soft similarity classes" at the same time. In this paper we show that taking this truly fuzzy characteristic into account may lead to new and interesting definitions of lower and upper approximations. We explore two of them in detail and we investigate under which conditions they differ from the commonly used definitions. Finally we show the possible practical relevance of the newly introduced approximations for query refinement},
keywords={equivalence classes;fuzzy T-equivalence relation;fuzzy rough sets;query refinement;soft similarity classes;approximation theory;equivalence classes;fuzzy set theory;fuzzy systems;rough set theory;},
doi={10.1109/TFUZZ.2006.889762},
ISSN={1063-6706},}

@article{Jensen20115871,
title = "Fuzzy-rough nearest neighbour classification and prediction",
journal = "Theoretical Computer Science",
volume = "412",
number = "42",
pages = "5871--5884",
year = "2011",
issn = "0304-3975",
doi = "10.1016/j.tcs.2011.05.040",
url = "http://www.sciencedirect.com/science/article/pii/S0304397511004580",
author = "Richard Jensen and Chris Cornelis",
keywords = "Fuzzy-rough sets",
keywords = "Classification",
keywords = "Prediction",
keywords = "Nearest neighbours"
}



@inproceedings{Skowron:1992,
	author = {A. Skowron and  C. Rauszer},
         editor    = {R. S{\l}owi\'{n}ski},
 	Title = {The discernibility matrices and functions in information systems},
         Booktitle     = {Intelligent Decision Support: Handbook
of Applications and Advances of the Rough Sets Theory},
        publisher = {Kluwer Academic Publishers},
        location  = {Dordrecht, Netherlands},
        year      = {1992},
        pages = {331--362},
	}

 @article{jensen:2007,
author = {R. Jensen and Q. Shen},
title = {Fuzzy-rough sets assisted attribute selection},
journal = {IEEE Transactions on Fuzzy Systems},
volume = {15},
number ={1},
pages = {73--89},
year = 2007},
}

 @article{jensen:2009,
author = {R. Jensen and  Q. Shen},
title = {New approaches to fuzzy-rough feature selection},
journal = {IEEE Transactions on Fuzzy Systems},
volume = {17},
number ={4},
pages = {824--838},
year = 2009},
}

%:%%%%%%%%%%%%%  ATTRIBUTE IMPLICATIONS

@article{ojedahernandez2022,
title = {Quasi-closed elements in fuzzy posets},
journal = {Journal of Computational and Applied Mathematics},
volume = {404},
pages = {113390},
year = {2022},
issn = {0377-0427},
doi = {https://doi.org/10.1016/j.cam.2021.113390},
url = {https://www.sciencedirect.com/science/article/pii/S0377042721000091},
author = {Manuel Ojeda-Hernández and Inma P. Cabrera and Pablo Cordero},
keywords = {Quasi-closed element, Fuzzy poset, Closure operator},
abstract = {We generalize the notion of quasi-closed element to fuzzy posets in two stages: First, in the crisp style in which each element in a given universe either is quasi-closed or not. Second, in the graded style by defining degrees to which an element is quasi-closed. We discuss the different possible definitions and comparing them with each other. Finally, we show that the most general one has good properties to be used when we have a complete fuzzy lattice as a frame.}
}


@article{bertet2010,
title = {The multiple facets of the canonical direct unit implicational basis},
journal = {Theoretical Computer Science},
volume = {411},
number = {22},
pages = {2155-2166},
year = {2010},
issn = {0304-3975},
doi = {https://doi.org/10.1016/j.tcs.2009.12.021},
url = {https://www.sciencedirect.com/science/article/pii/S0304397510000034},
author = {K. Bertet and B. Monjardet},
keywords = {Implicational system, Closure operator, Closure system, Canonical direct unit basis, Lattice, Horn Boolean function},
abstract = {The notion of dependencies between ?attributes? arises in many areas such as relational databases, data analysis, data-mining, formal concept analysis, knowledge structures ?. Formalization of dependencies leads to the notion of so-called full implicational systems (or full family of functional dependencies) which is in one-to-one correspondence with the other significant notions of closure operator and of closure system. An efficient generation of a full implicational system (or a closure system) can be performed from equivalent implicational systems and in particular from the bases for such systems, for example, the so-called canonical basis. This paper shows the equality between five other bases originating from different works and satisfying various properties (in particular they are unit implicational systems). The three main properties of this unique basis are the directness, canonical and minimal properties, whence the name canonical direct unit implicational basis given to this unit implicational system. The paper also gives a nice characterization of this canonical basis and makes precise its link with the prime implicants of the Horn function associated to a closure operator. It concludes that it is necessary to compare more closely related works made independently, and with a different terminology, in order to take advantage of the really new results in these works.}
}

@ARTICLE{F77,
  author={R. {Fagin}},
  journal={IBM Journal of Research and Development}, 
  title={Functional Dependencies in a Relational Database and Propositional Logic}, 
  year={1977},
  volume={21},
  number={6},
  pages={534-544},
  doi={10.1147/rd.216.0534}}
  
  
@InProceedings{A74,
author="W. W. Armstrong",
title="Dependency structures of data base relationships",
booktitle="Proc. IFIP Congress",
year="1974",
pages="580--583",
}


@InProceedings{Ganter1984,
author="Ganter, Bernhard",
editor="Kwuida, L{\'e}onard
and Sertkaya, Bar{\i}{\c{s}}",
title="Two Basic Algorithms in Concept Analysis",
booktitle="Formal Concept Analysis",
year="2010",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="312--340",
abstract="We describe two algorithms for closure systems. The purpose of the first is to produce all closed sets of a given closure operator. The second constructs a minimal family of implications for the ''logic'' of a closure system. These algorithms then are applied to problems in concept analysis: Determining all concepts of a given context and describing the dependencies between attributes. The problem of finding all concepts is equivalent, e.g., to finding all maximal complete bipartite subgraphs of a bipartite graph.",
isbn="978-3-642-11928-6"
}


@InProceedings{DU87,
author="Duquenne, Vincent",
editor="Cellier, Peggy
and Distel, Felix
and Ganter, Bernhard",
title="Contextual Implications between Attributes and Some Representation Properties for Finite Lattices",
booktitle="Formal Concept Analysis",
year="2013",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="1--27",
abstract="In the starting paper on Formal Concept Analysis (see WILLE (1982)), it is claimed that the aim of this young discipline is to ''Restructure Lattice Theory'', using an approach which ''goes back to the origin of the lattice concept in the nineteenth-century attempts to formalize logic, where a fundamental step was a reduction of a concept to its ''extent''. We propose to make the reduction less abstract by retaining in some measure ''the intent'' of a concept''.",
isbn="978-3-642-38317-5"
}




@article{DisjunctiveINS2021,
title = {Disjunctive attribute dependencies in formal concept analysis under the epistemic view of formal contexts},
journal = {Information Sciences},
 volume    = {561},
  pages     = {31--51},
  year      = {2021},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2020.12.085},
url = {https://www.sciencedirect.com/science/article/pii/S0020025521000177},
author = {Didier Dubois and Jesús Medina and Henri Prade and Eloísa Ramírez-Poussa},
keywords = {Galois connection, Formal concept analysis, Object-oriented concept lattices, Attribute implication},
abstract = {This paper considers an epistemic interpretation of formal contexts, interpreting blank entries in the context matrix as absence of information, which is in agreement with the usual focus on the extraction of implications between attributes. After recalling non-classical connections induced by rough sets and possibility theory in formal concept analysis (FCA), and the standard theory of attribute implications in FCA, this paper presents the notion of disjunctive attribute implications, which reflect additional information that can be extracted from an epistemic context. We show that they can be computed like standard attribute implications from the complementary context. The paper also recalls the logic of classical attribute implications, relying on works pertaining to functional dependencies in database theory, and proposes a dual logic for disjunctive attribute implications. A method for extracting the latter kind of rules from a formal context is proposed, using a counterpart of pseudo-intents. Lastly, the paper outlines a generalization of both conjunctive and disjunctive attribute implications under the form of rules, with a conjunction of conditions in the body and a disjunction of conditions in the head, that hold in a formal context under the epistemic view.}
}


@article{cordero2020,
  author    = {Pablo Cordero and
               Manuel Enciso and
               Angel Mora and
               Vil{\'{e}}m Vychodil},
  title     = {Parameterized simplification logic {I:} {R}easoning with implications
               and classes of closure operators},
  journal   = {International Journal of General Systems},
  volume    = {49},
  number    = {7},
  pages     = {724--746},
  year      = {2020},
  url       = {https://doi.org/10.1080/03081079.2020.1831484},
  doi       = {10.1080/03081079.2020.1831484},
}


@InProceedings{szathmary2009,
author="Szathmary, Laszlo
and Valtchev, Petko
and Napoli, Amedeo
and Godin, Robert",
editor="Adams, Niall M.
and Robardet, C{\'e}line
and Siebes, Arno
and Boulicaut, Jean-Fran{\c{c}}ois",
title="Efficient Vertical Mining of Frequent Closures and Generators",
booktitle="Advances in Intelligent Data Analysis VIII",
year="2009",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="393--404",
abstract="The effective construction of many association rule bases requires the computation of both frequent closed and frequent generator itemsets (FCIs/FGs). However, only few miners address both concerns, typically by applying levelwise breadth-first traversal. As depth-first traversal is known to be superior, we examine here the depth-first FCI/FG-mining. The proposed algorithm, Touch, deals with both tasks separately, i.e., uses a well-known vertical method, Charm, to extract FCIs and a novel one, Talky-G, to extract FGs. The respective outputs are matched in a post-processing step. Experimental results indicate that Touch is highly efficient and outperforms its levelwise competitors.",
isbn="978-3-642-03915-7"
}


@InProceedings{nehme2005,
author="Nehm{\'e}, Kamal
and Valtchev, Petko
and Rouane, Mohamed H.
and Godin, Robert",
editor="Ganter, Bernhard
and Godin, Robert",
title="On Computing the Minimal Generator Family for Concept Lattices and Icebergs",
booktitle="Formal Concept Analysis",
year="2005",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="192--207",
abstract="Minimal generators (or mingen) constitute a remarkable part of the closure space landscape since they are the antipodes of the closures, i.e., minimal sets in the underlying equivalence relation over the powerset of the ground set. As such, they appear in both theoretical and practical problem settings related to closures that stem from fields as diverging as graph theory, database design and data mining. In FCA, though, they have been almost ignored, a fact that has motivated our long-term study of the underlying structures under different perspectives. This paper is a two-fold contribution to the study of mingen families associated to a context or, equivalently, a closure space. On the one hand, it sheds light on the evolution of the family upon increases in the context attribute set (e.g., for purposes of interactive data exploration). On the other hand, it proposes a novel method for computing the mingen family that, although based on incremental lattice construction, is intended to be run in a batch mode. Theoretical and empirical evidence witnessing the potential of our approach is provided.",
isbn="978-3-540-32262-7"
}


@article{estrelladbasis2017,
author = {Estrella Rodr\'iguez-Lorenzo and Kira Adaricheva and Pablo Cordero and Manuel Enciso and Angel Mora},
title = {Formation of the D-basis from implicational systems using Simplification logic},
journal = {International Journal of General Systems},
volume = {46},
number = {5},
pages = {547-568},
year  = {2017},
publisher = {Taylor & Francis},
doi = {10.1080/03081079.2017.1349632},
URL = {https://doi.org/10.1080/03081079.2017.1349632},
eprint = {https://doi.org/10.1080/03081079.2017.1349632},
    abstract = { Sets of implications defining closure systems are used as a standard way to represent knowledge, and the search of implicational systems satisfying some criteria constitutes one of the most active topics in the study of closure systems and their applications. Here, we focus on the generation of the D-basis, known to be an ordered direct basis, allowing a very efficient attribute closure computation. We operate with the aggregated D-basis and provide an algorithm to get it from an arbitrary implicational set. The method has been designed on the interrelation between minimal covers and minimal generators, and it is inspired by the inference system of the Simplification Logic. Moreover, we develop an experiment to show the better performance of the new method compared to the earlier version of the algorithm. }
}


@article{adaricheva2013,
title = "Ordered direct implicational basis of a finite closure system",
journal = "Discrete Applied Mathematics",
volume = "161",
number = "6",
pages = "707 - 723",
year = "2013",
issn = "0166-218X",
doi = "https://doi.org/10.1016/j.dam.2012.08.031",
url = "http://www.sciencedirect.com/science/article/pii/S0166218X12003319",
author = "K. Adaricheva and J.B. Nation and R. Rand",
keywords = "Closure operator, System of implications, Lattice of closed sets, Horn formula, Horn Boolean function, Forward chaining, Linclosure, Direct basis, Canonical basis",
abstract = "The closure system on a finite set is a unifying concept in logic programming, relational databases and knowledge systems. It can also be presented in the terms of finite lattices, and the tools of economic description of a finite lattice have long existed in lattice theory. We present this approach by defining the D-basis and introducing the concept of an ordered direct basis of an implicational system. A direct basis of a closure operator, or an implicational system, is a set of implications that allows one to compute the closure of an arbitrary set by a single iteration. This property is preserved by the D-basis at the cost of following a prescribed order in which implications will be attended. In particular, using an ordered direct basis allows to optimize the forward chaining procedure in logic programming that uses the Horn fragment of propositional logic. One can extract the D-basis from any direct unit basis Î£ in time polynomial in the size s(Î£), and it takes only linear time of the cardinality of the D-basis to put it into a proper order. We produce examples of closure systems on a 6-element set, for which the canonical basis of Duquenne and Guigues is not ordered direct."
}
 
@article{guigues86,
author = {J.-L. Guigues and V. Duquenne},
title = {Familles minimales d'implications informatives résultant d'un tableau de données binaires},
journal = {Mathématiques
et Sciences Humaines},
volume = {95}, 
pages = {5-18},
year  = {1986},
}

@article{bazin16,
author = {Alexandre Bazin and Jean-Gabriel Ganascia},
title = {Computing the {D}uquenne-{G}uigues basis: an algorithm for choosing the order},
journal = {International Journal of General Systems},
volume = {45},
number = {2},
pages = {57-85},
year  = {2016},
publisher = {Taylor & Francis},
doi = {10.1080/03081079.2015.1072922},

URL = { 
        https://doi.org/10.1080/03081079.2015.1072922
    
},
eprint = { 
        https://doi.org/10.1080/03081079.2015.1072922
    
}
,
    abstract = { This paper presents an algorithm for choosing the order in which pseudo-intents are enumerated when computing the Duquenneâ“Guigues basis of a formal context. Sets are constructed through the use of a spanning tree to ensure they are all found once. The time and space complexities of the algorithm are empirically evaluated using, respectively, the number of logical closures and the number of sets in memory as measures. It is found that only the space complexity depends on the enumeration order. }
}



@article{disj-dmpr21,
title = {Disjunctive attribute dependencies in formal concept analysis under the epistemic view of formal contexts},
journal = {Information Sciences},
year = {2021},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2020.12.085},
url = {https://www.sciencedirect.com/science/article/pii/S0020025521000177},
author = {Didier Dubois and Jes\'us Medina and Henri Prade and Elo\'isa Ram\'irez-Poussa},
keywords = {Galois connection, Formal concept analysis, Object-oriented concept lattices, Attribute implication},
abstract = {This paper considers an epistemic interpretation of formal contexts, interpreting blank entries in the context matrix as absence of information, which is in agreement with the usual focus on the extraction of implications between attributes. After recalling non-classical connections induced by rough sets and possibility theory in formal concept analysis (FCA), and the standard theory of attribute implications in FCA, this paper presents the notion of disjunctive attribute implications, which reflect additional information that can be extracted from an epistemic context. We show that they can be computed like standard attribute implications from the complementary context. The paper also recalls the logic of classical attribute implications, relying on works pertaining to functional dependencies in database theory, and proposes a dual logic for disjunctive attribute implications. A method for extracting the latter kind of rules from a formal context is proposed, using a counterpart of pseudo-intents. Lastly, the paper outlines a generalization of both conjunctive and disjunctive attribute implications under the form of rules, with a conjunction of conditions in the body and a disjunction of conditions in the head, that hold in a formal context under the epistemic view.}
}


@article{ait17,
author = {Ait-Yakoub, Zina and Djouadi, Yassine and Dubois, Didier and Prade, Henri},
title = {Asymmetric Composition of Possibilistic Operators in Formal Concept Analysis: Application to the Extraction of Attribute Implications from Incomplete Contexts},
journal = {International Journal of Intelligent Systems},
volume = {32},
number = {12},
pages = {1285-1311},
doi = {10.1002/int.21900},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/int.21900},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/int.21900},
abstract = {Abstract Formal concept analysis theory (FCA) classically relies on the use of the Galois powerset operator. Formal similarities between possibility theory and formal concept analysis have led to the use of possibilistic operators in FCA, which were ignored before. In this paper, an approach based on the use of asymmetric composition of the two most usual possibilistic operators is proposed. It enables us to complement the stem base, by deriving attribute implications with disjunctions on both sides of the implications. Besides, the approach is also generalized to incomplete contexts involving explicit positive and negative information. We outline the potential application of these results to the completion of TBoxes in description logic.},
year = {2017}
}


@article{bartl19,
title = "L-Concept lattices with positive and negative attributes: Modeling uncertainty and reduction of size",
journal = "Information Sciences",
volume = "472",
pages = "163 - 179",
year = "2019",
issn = "0020-0255",
doi = "https://doi.org/10.1016/j.ins.2018.08.057",
url = "http://www.sciencedirect.com/science/article/pii/S0020025518306753",
author = "Eduard Bartl and Jan Konecny",
keywords = "Fuzzy logic, Formal concept analysis, Negative information, Uncertainty, Linguistic hedges, Factorization by similarity",
abstract = "In our previous works, we introduced an extension of formal fuzzy concept analysis where attributes were considered as a positive and negative information based on user input. In the present paper, we show that the extension is naturally capable to model uncertainty and we describe a general method to increase that uncertainty in a parametric way. Furthermore, we demonstrate that two methods of concept lattice size reduction, which were thoroughly studied in formal fuzzy concept analysis, become instances of the general method when adapted to our extension."
}


@article{bartl16,
title = "L-concept analysis with positive and negative attributes",
journal = "Information Sciences",
volume = "360",
pages = "96 - 111",
year = "2016",
issn = "0020-0255",
doi = "https://doi.org/10.1016/j.ins.2016.04.012",
url = "http://www.sciencedirect.com/science/article/pii/S0020025516302419",
author = "Eduard Bartl and Jan Konecny",
keywords = "Antitone concept-forming operator, Concept lattice, Formal concept analysis, Galois connection, If-then rules, Isotone concept-forming operator",
abstract = "We describe an extension of formal fuzzy concept analysis allowing a user to choose which attributes are viewed as positive and which are viewed as negative. The two sets are then handled using a combination of previously studied antitone concept-forming operators and isotone concept-forming operators, respectively. The two main outputs of formal concept analysis, namely concept lattices and attribute implications, in the setting of positive and negative attributes are presented. An analogy of the main theorem of concept lattices and a relationship between the new concept lattice and the previously studied concept lattices is showed. We introduce basic syntactic and semantic notions for attribute implications called fuzzy containment implications. We consider two settings, one where the sets of positive and negative attributes are crisp sets, and a generalization, where the two sets are fuzzy sets."
}


@article{estrella17,
title = "Canonical dichotomous direct bases",
journal = "Information Sciences",
volume = "376",
pages = "39 - 53",
year = "2017",
issn = "0020-0255",
doi = "https://doi.org/10.1016/j.ins.2016.10.004",
url = "http://www.sciencedirect.com/science/article/pii/S0020025516311586",
author = "Estrella Rodr\'iguez-Lorenzo and Pablo Cordero and Manuel Enciso and \'Angel Mora",
keywords = "Implicational systems, Closure systems, Formal concept analysis, Direct bases",
abstract = "Closure systems are usually characterized in terms of implications. The directness property of implicational systems is a key issue in their computational usability. In this work we focus on this property, studying its connection with the structure of implicational systems and the design of methods for transforming any implicational system into an equivalent direct implicational system. We introduce a new paradigm based on the bipartition of the implicational sets into two components, according to their behavior wrt the closure. In addition, we present the notions of two new direct bases, named DD-basis and canonical DD-basis, also providing two methods to compute each of them. The advantages of the dichotomous approach will be shown both from the theoretical and empirical points of view."
}


@article{baixeries18,
title = "Characterizing approximate-matching dependencies in formal concept analysis with pattern structures",
journal = "Discrete Applied Mathematics",
volume = "249",
pages = "18 - 27",
year = "2018",
issn = "0166-218X",
doi = "https://doi.org/10.1016/j.dam.2018.03.073",
url = "http://www.sciencedirect.com/science/article/pii/S0166218X18301811",
author = "Jaume Baixeries and Victor Codocedo and Mehdi Kaytoue and Amedeo Napoli",
keywords = "Functional dependencies, Similarity, Tolerance relation, Formal concept analysis, Pattern structures, Attribute implications",
abstract = "Functional dependencies (FDs) provide valuable knowledge on the relations between attributes of a data table. A functional dependency holds when the values of an attribute can be determined by another. It has been shown that FDs can be expressed in terms of partitions of tuples that are in agreement w.r.t. the values taken by some subsets of attributes. To extend the use of FDs, several generalizations have been proposed. In this work, we study approximate-matching dependencies that generalize FDs by relaxing the constraints on the attributes, i.e. agreement is based on a similarity relation rather than on equality. Such dependencies are attracting attention in the database field since they allow uncrisping the basic notion of FDs extending its application to many different fields, such as data quality, data mining, behavior analysis, data cleaning or data partition, among others. We show that these dependencies can be formalized in the framework of Formal Concept Analysis (FCA) using a previous formalization introduced for standard FDs. Our new results state that, starting from the conceptual structure of a pattern structure, and generalizing the notion of relation between tuples, approximate-matching dependencies can be characterized as implications in a pattern concept lattice. We finally show how to use basic FCA algorithms to construct a pattern concept lattice that entails these dependencies after a slight and tractable binarization of the original data."
}


@Inbook{Medina2010,
author="Medina, Raoul
and Nourine, Lhouari",
editor="Kwuida, L{\'e}onard
and Sertkaya, Bar{\i}{\c{s}}",
title="Conditional Functional Dependencies: An FCA Point of View",
bookTitle="Formal Concept Analysis: 8th International Conference, ICFCA 2010, Agadir, Morocco, March 15-18, 2010. Proceedings",
year="2010",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="161--176",
abstract="Conditional Functional Dependencies (CFDs) are Functional Dependencies (FDs) that hold on a fragment relation of the original relation. In [17], the hierarchy between CFDs, association rules and some other dependencies have been shown.",
isbn="978-3-642-11928-6",
doi="10.1007/978-3-642-11928-6_12",
url="https://doi.org/10.1007/978-3-642-11928-6_12"
}


@inproceedings{escimspringer:aimplic,
author="Li{\~{n}}eiro-Barea, Valent{\'i}n
and Medina, Jes{\'u}s
and Medina-Bulo, Inmaculada",
editor="K{\'o}czy, L{\'a}szl{\'o} T.
and Medina, Jes{\'u}s",
title="Generating Fuzzy Attribute Rules Via Fuzzy Formal Concept Analysis",
bookTitle="Interactions Between Computational Intelligence and Mathematics",
year="2018",
  series    = {Studies in Computational Intelligence},
publisher="Springer International Publishing",
address="Cham",
pages="105--119",
abstract="Extracting knowledge from databases is a procedure which interest has increased in a wide variety of areas like stock market, medicine or census data, to name a few. A compact representation of this knowledge is given by rules. Formal concept analysis plays an important role in this area. This paper introduces a new kind of attribute implications considering the fuzzy notions of support and confidence and is also focused on the particular case in which the set of attributes are intensions. Moreover, an application to clustering for size reduction of concept lattices is included.",
isbn="978-3-319-74681-4",
doi="10.1007/978-3-319-74681-4_7",
url="https://doi.org/10.1007/978-3-319-74681-4_7"
}




@inproceedings{escim:aimplications,
	author = {V. Li{\~{n}}eiro-Barea and J. Medina and I. Medina-Bulo},
         editor    = {J. Kacprzyk and L. Koczy and J. Medina},
 	Title = {Towards generating fuzzy rules via Fuzzy Formal Concept Analysis},
         Booktitle     = {7th European Symposium on Computational Intelligence  and Mathematices (ESCIM 2015)},
        location  = {Cádiz, Spain},
        year      = {2015},
        pages = {60--65},
	}
	
@article{belohlavek16,
author = {Radim  B{\v e}lohl{\'a}vek and
               Vil{\'{e}}m Vychodil},
title = {Attribute dependencies for data with grades {I}},
journal = {International Journal of General Systems},
volume = {45},
number = {7-8},
pages = {864-888},
year  = {2016},
publisher = {Taylor & Francis},
doi = {10.1080/03081079.2016.1205711},
}

 @article{belohlavekAI2017,
  author    = {Radim Belohl{\'{a}}vek and
               Vil{\'{e}}m Vychodil},
  title     = {Attribute dependencies for data with grades {II},},
  journal   = {Int. J. General Systems},
  volume    = {46},
  number    = {1},
  pages     = {66--92},
  year      = {2017},
  doi       = {10.1080/03081079.2016.1205712},
 }

@article{Cordero201651,
title = "Automated prover for attribute dependencies in data with grades ",
journal = "International Journal of Approximate Reasoning ",
volume = "70",
number = "",
pages = "51--67",
year = "2016",
note= "",
issn = "0888-613X",
doi = "http://dx.doi.org/10.1016/j.ijar.2015.12.007",
url = "http://www.sciencedirect.com/science/article/pii/S0888613X15001851",
author = "Radim  B{\v e}lohl{\'a}vek and Pablo Cordero and Manuel Enciso and \'Angel Mora and Vilem Vychodil",
keywords = "Attribute implication",
keywords = "Functional dependency",
keywords = "Fuzzy logic",
keywords = "Ordinal data",
keywords = "Ordinary and graded completeness",
keywords = "Similarity ",
abstract = "Abstract We present a new axiomatization of logic for dependencies in data with grades, which includes ordinal data and data over domains with similarity relations, and an efficient reasoning method that is based on the axiomatization. The logic has its ordinary-style completeness characterizing the ordinary, bivalent entailment as well as the graded-style completeness characterizing the general, possibly intermediate degrees of entailment. A core of the method is a new inference rule, called the rule of simplification, from which we derive convenient equivalences that allow us to simplify sets of dependencies while retaining semantic closure. The method makes it possible to compute a closure of a given collection of attributes with respect to a collection of dependencies, decide whether a given dependency is entailed by a given collection of dependencies, and more generally, compute the degree to which the dependency is entailed by a collection of dependencies. We also present an experimental evaluation of the presented method. " 
}


@article{Vychodil201690,
title = "Computing sets of graded attribute implications with witnessed non-redundancy ",
journal = "Information Sciences ",
volume = "351",
number = "",
pages = "90 - 100",
year = "2016",
note= "",
issn = "0020-0255",
doi = "http://dx.doi.org/10.1016/j.ins.2016.03.004",
url = "http://www.sciencedirect.com/science/article/pii/S0020025516301451",
author = "Vilem Vychodil",
keywords = "Redundancy",
keywords = "Attribute implication",
keywords = "Residuated lattice",
keywords = "Fuzzy logic",
keywords = "Pseudo intent ",
abstract = "Abstract In this paper we extend our previous results on sets of graded attribute implications with witnessed non-redundancy. We assume finite residuated lattices as structures of truth degrees and use arbitrary idempotent truth-stressing linguistic hedges as parameters which influence the semantics of graded attribute implications. In this setting, we introduce algorithm which transforms any set of graded attribute implications into an equivalent non-redundant set of graded attribute implications with saturated consequents whose non-redundancy is witnessed by antecedents of the formulas. As a consequence, we solve the open problem regarding the existence of general systems of pseudo-intents which appear in formal concept analysis of object-attribute data with graded attributes and linguistic hedges. Furthermore, we show a polynomial-time procedure for determining bases given by general systems of pseudo-intents from sets of graded attribute implications which are complete in data. "
}





@article{hill16,
author = {Jennifer Hill and Helen Walkington and Derek France},
title = {Graduate attributes: implications for higher education practice and policy},
journal = {Journal of Geography in Higher Education},
volume = {40},
number = {2},
pages = {155-163},
year = {2016},
doi = {10.1080/03098265.2016.1154932},
URL = {         http://dx.doi.org/10.1080/03098265.2016.1154932},
eprint = {        http://dx.doi.org/10.1080/03098265.2016.1154932}
}



@article{Kuhr20151,
title = "Fuzzy logic programming reduced to reasoning with attribute implications ",
journal = "Fuzzy Sets and Systems ",
volume = "262",
number = "",
pages = "1 - 20",
year = "2015",
issn = "0165-0114",
doi = "http://dx.doi.org/10.1016/j.fss.2014.04.013",
url = "http://www.sciencedirect.com/science/article/pii/S0165011414001882",
author = "Tomas Kuhr and Vilem Vychodil",
keywords = "Logic programming",
keywords = "Attribute implications",
keywords = "Functional dependencies",
keywords = "Ordinal scales",
keywords = "Residuated lattices",
keywords = "Least model property ",
abstract = "Abstract We present a link between two types of logic systems for reasoning with graded ifâ“then rules: the system of fuzzy logic programming (FLP) in sense of VojtÃ¡Å¡ and the system of fuzzy attribute logic (FAL) in sense of Belohlavek and Vychodil. We show that each finite theory consisting of formulas of \{FAL\} can be represented by a definite program so that the semantic entailment in \{FAL\} can be characterized by correct answers for the program. Conversely, we show that for each definite program there is a collection of formulas of \{FAL\} so that the correct answers can be represented by the entailment in FAL. Using the link, we can transport results from \{FAL\} to \{FLP\} and vice versa which gives us, e.g., a syntactic characterization of correct answers based on Pavelka-style Armstrong-like axiomatization of FAL. We further show that entailment in \{FLP\} is reducible to reasoning with Boolean attribute implications and elaborate on related issues including properties of least models. "
}





@article{glodeanu16,
author = {Cynthia Vera Glodeanu},
title = {Knowledge discovery in data sets with graded attributes},
journal = {International Journal of General Systems},
volume = {45},
number = {2},
pages = {232-249},
year = {2016},
doi = {10.1080/03081079.2015.1072929},
}



@article{RodriguezJimenez2014,
title = "Negative Attributes and Implications in Formal Concept Analysis ",
journal = "Procedia Computer Science ",
volume = "31",
number = "",
pages = "758 - 765",
year = "2014",
issn = "1877-0509",
doi = "http://dx.doi.org/10.1016/j.procs.2014.05.325",
url = "http://www.sciencedirect.com/science/article/pii/S187705091400502X",
author = "J.M. Rodr\'iguez-Jim\'enez and P. Cordero and M. Enciso and A. Mora",
keywords = "Formal concept analysis",
keywords = "attribute implications",
keywords = "data mining",
keywords = "negative attributes. ",
abstract = "Abstract The mining of negative attributes from datasets has been studied in the last decade to obtain additional and useful information. There exists an exhaustive study around the notion of negative association rules between sets of attributes. However, in Formal Concept Analysis, the needed theory for the management of negative attributes is in an incipient stage. In this work we present an algorithm, based on the NextClosure algorithm, that allows to obtain mixed implications. The proposed algorithm returns a feasible and complete basis of mixed implications by performing a reduced number of requests to the formal context. "
}



@article{Ren2014,
title = "Rule Acquisition in Formal Decision Contexts Based on Formal, Object-Oriented and Property-Oriented Concept Lattices",
journal = "The Scientific World Journal",
volume = "2014",
pages = "1-10",
year = "2014",
doi = "http://dx.doi.org/10.1155/2014/685362 ",
author = "Yue Ren and Jinhai Li and {Ch. Aswani Kumar}  and Wenqi Liu "
}

@inproceedings{CorderoEMO13,
  author    = {Pablo Cordero and
               Manuel Enciso and
               Angel Mora and
               Manuel Ojeda-Aciego},
  title     = {Computing Left-Minimal Direct Basis of implications},
  booktitle = {CLA},
  year      = {2013},
  pages     = {293-298},
  ee        = {http://ceur-ws.org/Vol-1062/paper_short4.pdf},
  crossref  = {DBLP:conf/cla/2013},
  bibsource = {DBLP, http://dblp.uni-trier.de}
}

@proceedings{DBLP:conf/cla/2013,
  editor    = {Manuel Ojeda-Aciego and
               Jan Outrata},
  title     = {Proceedings of the Tenth International Conference on Concept
               Lattices and Their Applications, La Rochelle, France, October
               15-18, 2013},
  booktitle = {CLA},
  publisher = {CEUR-WS.org},
  series    = {CEUR Workshop Proceedings},
  volume    = {1062},
  year      = {2013},
  ee        = {http://ceur-ws.org/Vol-1062},
  bibsource = {DBLP, http://dblp.uni-trier.de}
}



@article{BeCor12,
year={2012},
volume={7647},
journal={Lecture Notes in Computer Science},
doi={10.1007/978-3-642-34620-0_36},
title={An Efficient Reasoning Method for Dependencies over Similarity and Ordinal Data},
author={B{\v e}lohl{\'a}vek, Radim and Cordero, Pablo and Enciso, Manuel and Mora, Angel and Vychodil, Vilem},
pages={408-419}
}
 

@inproceedings{BelohlavekICFCA2006,
 author = {B{\v e}lohl\'{a}vek, Radim and Vychodil, Vil{\'e}m},
 title = {Attribute implications in a fuzzy setting},
 booktitle = {Proceedings of the 4th international conference on Formal Concept Analysis},
 series = {ICFCA'06},
 year = {2006},
 isbn = {3-540-32203-5, 978-3-540-32203-0},
 location = {Dresden, Germany},
 pages = {45--60},
 numpages = {16},
 url = {http://dx.doi.org/10.1007/11671404_3},
 doi = {10.1007/11671404_3},
 acmid = {2180245},
 publisher = {Springer-Verlag},
 address = {Berlin, Heidelberg},
 keywords = {attribute implication, concept lattice, functional dependency, fuzzy logic},
} 

 
 
%:%%%%%%%%%%%%% DEPENDENCIAS FUNCIONALES
 @article{estrella18,
title = "Direct-optimal basis computation by means of the fusion of simplification rules",
journal = "Discrete Applied Mathematics",
volume = "249",
pages = "106 - 119",
year = "2018",
issn = "0166-218X",
doi = "https://doi.org/10.1016/j.dam.2017.12.031",
url = "http://www.sciencedirect.com/science/article/pii/S0166218X1730611X",
author = "Estrella Rodr\'iguez-Lorenzo and Karell Bertet and Pablo Cordero and Manuel Enciso and \'Angel Mora",
keywords = "Direct-optimal basis, Closure, Simplification Logic",
abstract = "The importance of the computation of direct bases of implications has been motivated by several authors in different areas. They emphasize the use of direct bases in several problems, where a large number of closures are needed. The more efficient the basis computation is, the better performance the methods solving these problems has. Here, we propose a new method, named SLgetdo, to calculate the direct-optimal basis. The main characteristic of SLgetdoÂ is the full integration of simplification paradigm, providing a limited rise of the implicational set throughout its execution. We have showed the better behavior of SLgetdoÂ in an empirical experiment. The general conclusion is that it improves the performance of previous methods, providing a better management of time and space resources."
}
 
 
  @article{CorderoMGE08,
author = {P. Cordero and  A. Mora and  {I. P.} de Guzmán  and M. Enciso},
title = {Non-deterministic ideal operators: An adequate tool for 
formalization in data bases},
journal = {Discrete Applied Mathematics},
volume = {156},
pages = {911--923},
year = 2008},
}
    
    @article{AguileraCEMG04,
author = {G. Aguilera and P. Cordero and M. Enciso and A. Mora and {I. P.} de Guzmán},
title = {A non-explosive treatment of functional 
dependencies using rewriting logic},
journal = {Lecture Notes in Computer Science},
volume = {3171},
pages = {31--40},
year = 2004},
Abstract = {In SBIA},
}

    @article{MoraECG03,
author = {A. Mora and  M. Enciso and P. Cordero  and {I. P.} de Guzmán},
title = {An efficient preprocessing transformation for functional 
dependencies sets based on the substitution paradigm},
journal = {Lecture Notes in Computer Science},
volume = {3040},
pages = {136--146},
year = 2003},
Abstract = {In CAEPIA},
}

 
%:%%%%%%%%% CATEGORY viewpoint


 @inproceedings{Pierce:categories,
	Author = {C.-S. Pierce},
	Booktitle = {Proceedings of the American Academy of Arts and Sciences 7(1868)},
	Title = {On a new list of categories},
pages = {287--298},
	Year = {1867},
	}
	

  
  

@article{Guo2014885,
title = "A categorical representation of algebraic domains based on variations of rough approximable concepts ",
journal = "International Journal of Approximate Reasoning ",
volume = "55",
number = "3",
pages = "885--895",
year = "2014",
note= "",
issn = "0888-613X",
doi = "http://dx.doi.org/10.1016/j.ijar.2013.09.008",
url = "http://www.sciencedirect.com/science/article/pii/S0888613X13001783",
author = "Lankun Guo and Qingguo Li and Mengqiao Huang",
keywords = "Rough approximable concept",
keywords = "Rough pseudo-concept",
keywords = "Hyper-context",
keywords = "Hyper-concept",
keywords = "Algebraic domain "
}

@article{Diker201346,
title = "Categories of rough sets and textures ",
journal = "Theoretical Computer Science ",
volume = "488",
number = "0",
pages = "46--65",
year = "2013",
note= "",
issn = "0304-3975",
doi = "http://dx.doi.org/10.1016/j.tcs.2012.12.020",
url = "http://www.sciencedirect.com/science/article/pii/S0304397512011231",
author = "Murat Diker",
keywords = "Approximation operator",
keywords = "Dagger category",
keywords = "Direlation",
keywords = "Rough set",
keywords = "Symmetric monoidal category",
keywords = "Texture space "
}



 


%:%%%%%%%%%%%% FUZZY SETS

@article{DeKerf1975,
title = "A bibliography on fuzzy sets ",
journal = "Journal of Computational and Applied Mathematics ",
volume = "1",
number = "3",
pages = "205 - 212",
year = "1975",
note= "",
issn = "0377-0427",
doi = "http://dx.doi.org/10.1016/0771-050X(75)90036-4",
url = "http://www.sciencedirect.com/science/article/pii/0771050X75900364",
author = "Joseph L.F. De Kerf"
}


@article{Sadatrasoul2016,
title = "Numerical solution of two-dimensional nonlinear Hammerstein fuzzy integral equations based on optimal fuzzy quadrature formula ",
journal = "Journal of Computational and Applied Mathematics ",
volume = "292",
number = "",
pages = "430 - 446",
year = "2016",
note= "",
issn = "0377-0427",
doi = "http://dx.doi.org/10.1016/j.cam.2015.07.023",
url = "http://www.sciencedirect.com/science/article/pii/S0377042715003854",
author = "S.M. Sadatrasoul and R. Ezzati",
keywords = "Two dimensional Hammerstein fuzzy integral equations (2DHFIE)",
keywords = "Optimal quadrature formula",
keywords = "Banach fixed point theorem",
keywords = "The method of successive approximations",
keywords = "Iterative method ",
abstract = "Abstract In this paper, our aim is to provide an efficient iterative method of successive approximations to approximate solution of linear and nonlinear two-dimensional Hammerstein fuzzy integral equations by defining and developing an optimal quadrature formula for classes of two-dimensional fuzzy-number-valued functions of Lipschitz type. After the introduction of the optimal formula, we prove the convergence of the method of successive approximations used to approximate the solution of two-dimensional Hammerstein fuzzy integral equations and investigate the numerical stability of the presented method with respect to the choice of the first iteration. Finally, some illustrative numerical experiments confirm the theoretical results and demonstrate the accuracy of the method. "
}

 
@article{tutuncu2015,
title = "An Aggregated Fuzzy Naive Bayes Data Classifier",
journal = "Journal of Computational and Applied Mathematics ",
volume = "286",
number = "",
pages = "17 - 27",
year = "2015",
note= "",
issn = "0377-0427",
doi = "http://dx.doi.org/10.1016/j.cam.2015.02.004",
url = "http://www.sciencedirect.com/science/article/pii/S0377042715000655",
author = "G. Yazg? Tütüncü and Necla Kayaalp",
keywords = "Decision analysis",
keywords = "Fuzzy sets",
keywords = "Fuzzy classification",
keywords = "Naive Bayes classification",
keywords = "Fuzzy function principle ",
abstract = "Abstract In this study, an Aggregated Fuzzy Naive Bayes Classifier is proposed for decision-making problems where both linguistic and numerical information are available. In the solution process of such problems, all attributes are considered as fuzzy numbers and a procedure based on 2-tuple fuzzy linguistic representation model is generated for combining them. This procedure and subsequent Fuzzy Naive Bayes classification are performed based on arithmetic operations defined by Chenâ™s function principle. The proposed method was demonstrated on 2 well-known examples from the literature in which both numerical and linguistic attributes were considered. The results show that the proposed Aggregated Fuzzy NaÃ¯ve Bayes Classifier is notably efficient in decision-making where the attributes are in more realistic forms. "
}


@article{Eryilmaz2015,
title = "Stress strength reliability in the presence of fuzziness ",
journal = "Journal of Computational and Applied Mathematics ",
volume = "282",
number = "",
pages = "262 - 267",
year = "2015",
note= "",
issn = "0377-0427",
doi = "http://dx.doi.org/10.1016/j.cam.2014.12.047",
url = "http://www.sciencedirect.com/science/article/pii/S0377042715000163",
author = "Serkan Eryilmaz and G. YazgÄ± TÃ¼tÃ¼ncÃ¼",
keywords = "Estimation",
keywords = "Fuzzy reliability",
keywords = "System signature ",
abstract = "Abstract This paper investigates the stressâ“strength reliability in the presence of fuzziness. The fuzzy membership function is defined as a function of the difference between stress and strength values, and the fuzzy reliability of single unit and multicomponent systems are calculated. The inclusion of fuzziness in the stressâ“strength interference enables the user to make more sensitive analysis. Illustrations are presented for various stress and strength distributions. "
}



%:%%%%%%%%%%%% SOFT SETS

@article{Feng2010,
title = "An adjustable approach to fuzzy soft set based decision making ",
journal = "Journal of Computational and Applied Mathematics ",
volume = "234",
number = "1",
pages = "10 - 20",
year = "2010",
note= "",
issn = "0377-0427",
doi = "http://dx.doi.org/10.1016/j.cam.2009.11.055",
url = "http://www.sciencedirect.com/science/article/pii/S0377042709008024",
author = "Feng Feng and Young Bae Jun and Xiaoyan Liu and Lifeng Li",
keywords = "Soft set",
keywords = "Fuzzy soft set",
keywords = "Level soft set",
keywords = "Threshold",
keywords = "Comparison table",
keywords = "Choice value",
keywords = "Score",
keywords = "Decision making ",
abstract = "Molodtsovâ™s soft set theory was originally proposed as a general mathematical tool for dealing with uncertainty. Recently, decision making based on (fuzzy) soft sets has found paramount importance. This paper aims to give deeper insights into decision making based on fuzzy soft sets. We discuss the validity of the Royâ“Maji method and show its true limitations. We point out that the choice value designed for the crisp case is no longer fit to solve decision making problems involving fuzzy soft sets. By means of level soft sets, we present an adjustable approach to fuzzy soft set based decision making and give some illustrative examples. Moreover, the weighted fuzzy soft set is introduced and its application to decision making is also investigated. "
}

@article{Kong2011,
title = "Application of fuzzy soft set in decision making problems based on grey theory ",
journal = "Journal of Computational and Applied Mathematics ",
volume = "236",
number = "6",
pages = "1521 - 1530",
year = "2011",
note= "",
issn = "0377-0427",
doi = "http://dx.doi.org/10.1016/j.cam.2011.09.016",
url = "http://www.sciencedirect.com/science/article/pii/S037704271100495X",
author = "Zhi Kong and Lifu Wang and Zhaoxia Wu",
keywords = "Fuzzy-soft set",
keywords = "Choice value",
keywords = "Grey theory",
keywords = "Grey relational analysis",
keywords = "Decision-making problem ",
abstract = "There are many uncertain problems in practical production and life which need decisions made with soft sets and fuzzy soft sets. However, the basis of evaluation of the decision method is single and simple, the same decision problem can obtain different results from using a different evaluation basis. In this paper, in order to obtain the right result, we discuss fuzzy soft set decision problems. A new algorithm based on grey relational analysis is presented. The evaluation bases of the new algorithm are multiple. There is more information in a decision result based on multiple evaluation bases, which is more easily accepted and logical to oneâ™s thinking. For the two cases examined, the results show that the new algorithm is efficient for solving decision problems. "
}

%:%%%%%%%%% FCA y ROUGH SETS


@InProceedings{bmr:IPMU18,
  author    = {Ben{\'i}tez-Caballero, M. Jos{\'e} and Medina, Jes{\'u}s and Ram{\'i}rez-Poussa, Elo{\'i}sa},
  booktitle = {Information Processing and Management of Uncertainty in Knowledge-Based Systems. Theory and Foundations},
  title     = {{F}{C}{A} Attribute Reduction in Information Systems},
  editor    = {Medina, Jes{\'u}s and Ojeda-Aciego, Manuel and Verdegay, Jos{\'e} Luis and Pelta, David A. and Cabrera, Inma P. and Bouchon-Meunier, Bernadette and Yager, Ronald R.},
  isbn      = {978-3-319-91473-2},
  pages     = {549--561},
  publisher = {Springer International Publishing},
  abstract  = {One of the main targets in formal concept analysis (FCA) and in rough set theory (RST) is the reduction of redundant information. Feature selection mechanisms have been studied separately in many works. In this paper, we analyse the result of applying the reduction mechanisms given in FCA to RST, and give interpretations of such reductions.},
  address   = {Cham},
  year      = {2018},
}



@article{sci:benitez19,
author="Ben{\'i}tez-Caballero, M. Jos{\'e}
and Medina, Jes{\'u}s
and Ram{\'i}rez-Poussa, Elo{\'i}sa",
title="Unifying reducts in formal concept analysis and rough set theory",
bookTitle="Trends in Mathematics and Computational Intelligence",
journal="Studies in Computational Intelligence",
volume = "796",
year = "2019",
pages="89--95",
abstract="AttributeBen{\'i}tez-Caballero, M. Jos{\'e} reductionMedina, Jes{\'u}s isRam{\'i}rez-Poussa, Elo{\'i}sa a fundamental part in different mathematical tools devoted to data analysis, such as, Rough Set Theory and Formal Concept Analysis. These last mathematical theories are closely related and, in this paper, we establish connections between attribute reduction in both frameworks. Mainly, we have introduced a sufficient and necessary condition in order to ensure that the reducts in both theories coincide.",
isbn="978-3-030-00485-9",
doi="10.1007/978-3-030-00485-9_10",
url="https://doi.org/10.1007/978-3-030-00485-9_10"
}


@article{Zhang2016326,
title = "Construction method of concept lattice based on improved variable precision rough set ",
journal = "Neurocomputing ",
volume = "188",
number = "",
pages = "326 - 338",
year = "2016",
issn = "0925-2312",
doi = "http://dx.doi.org/10.1016/j.neucom.2015.05.136",
url = "http://www.sciencedirect.com/science/article/pii/S0925231215018524",
author = "Ruiling Zhang and Shengwu Xiong and Zhong Chen",
keywords = "Concept lattice",
keywords = "Variable precision rough set",
keywords = "Formal context",
keywords = "Attribute reduction",
keywords = "Rule acquisition ",
abstract = "Abstract This paper mainly focuses on how to construct concept lattice effectively and efficiently based on improved variable precision rough set. On the basis of preprocessing formal concept, one algorithm that can determine the value range of variable precision parameter Î² according to the approximate classification quality is proposed. An improved Î²-upper and lower distribution attribute reduction algorithm is also proposed based on the improved variable precision rough set, the algorithm can be used for attribute reduction on the original data of the concept lattice, and to eliminate the redundant knowledge or noises of the formal context. For the reduced formal context, the paper combines the concept construction algorithm with an improved rule acquisition algorithm seamlessly, and proposes a novel approach of concept lattice construction based on improved variable precision rough set. Finally, a concept lattice generation prototype system is developed, this paper also performs comprehensive experiments, and the effectiveness of the improved algorithm is proved through the experimental results. "
}


@article{Yao2016442,
title = "Rough-set concept analysis: Interpreting RS-definable concepts based on ideas from formal concept analysis ",
journal = "Information Sciences ",
volume = "346-347",
number = "",
pages = "442-462",
year = "2016",
note= "",
issn = "0020-0255",
doi = "http://dx.doi.org/10.1016/j.ins.2016.01.091",
url = "http://www.sciencedirect.com/science/article/pii/S0020025516300330",
author = "Yiyu Yao",
keywords = "Concept lattice",
keywords = "Extension",
keywords = "Intension",
keywords = "Rough set",
keywords = "Rough-set concept analysis",
keywords = "Formal concept analysis ",
abstract = "Abstract Based on ideas from formal concept analysis, this paper interprets the notions of RS-definable concepts (i.e., rough-set definable concepts) and the Boolean algebra of RS-definable concepts. We explicitly represent a RS-definable concept as a pair of an extension and an intension, where the extension is a set of objects and the intension is a family of sets of attribute-value pairs called avp-sets. An object in the extension satisfies at least one avp-set in the intension and each avp-set in the intension is satisfied by only objects in the extension. The two-directional connections produce an atomic Boolean algebra of RS-definable concepts, corresponding to the lattice of formal concepts in formal concept analysis. The Boolean algebra of RS-definable concepts is used to define and interpret a subset of objects through a pair of lower and upper approximations. The new formulation emphasizes on an in-depth conceptual understanding of rough-set concept analysis. "
}


%:%%%%%%%%% ROUGH SETS

@article{dubois90rfs,
author = { DIDIER   DUBOIS  and  HENRI   PRADE },
title = {ROUGH FUZZY SETS AND FUZZY ROUGH SETS},
journal = {International Journal of General Systems},
volume = {17},
number = {2-3},
pages = {191-209},
year  = {1990},
publisher = {Taylor & Francis},
doi = {10.1080/03081079008935107},
URL = {https://doi.org/10.1080/03081079008935107},
eprint = {https://doi.org/10.1080/03081079008935107},
abstract = { The notion of a rough set introduced by Pawlak has often been compared to that of a fuzzy set, sometimes with a view to prove that one is more general, or, more useful than the other. In this paper we argue that both notions aim to different purposes. Seen this way, it is more natural to try to combine the two models of uncertainty (vagueness and coarseness) rather than to have them compete on the same problems. First, one may think of deriving the upper and lower approximations of a fuzzy set, when a reference scale is coarsened by means of an equivalence relation. We then come close to Caianiello's C-calculus. Shafer's concept of coarsened belief functions also belongs to the same line of thought. Another idea is to turn the equivalence relation into a fuzzy similarity relation, for the modeling of coarseness, as already proposed by Farinas del Cerro and Prade. Instead of using a similarity relation, we can start with fuzzy granules which make a fuzzy partition of the reference scale. The main contribution of the paper is to clarify the difference between fuzzy sets and rough sets, and unify several independent works which deal with similar ideas in different settings or notations. }
}


@article{DESA2018,
title = "Preference rules for label ranking: Mining patterns in multi-target relations",
journal = "Information Fusion",
volume = "40",
pages = "112 - 125",
year = "2018",
issn = "1566-2535",
doi = "https://doi.org/10.1016/j.inffus.2017.07.001",
url = "http://www.sciencedirect.com/science/article/pii/S1566253517304311",
author = " Cl{\'a}udio Rebelo de S{\'a} and Paulo Azevedo and Carlos Soares and Al{\'i}pio M{\'a}rio Jorge  and Arno Knobbe",
keywords = "Label ranking, Association rules, Pairwise comparisons",
abstract = "In this paper, we investigate two variants of association rules for preference data, Label Ranking Association Rules and Pairwise Association Rules. Label Ranking Association Rules (LRAR) are the equivalent of Class Association Rules (CAR) for the Label Ranking task. In CAR, the consequent is a single class, to which the example is expected to belong to. In LRAR, the consequent is a ranking of the labels. The generation of LRAR requires special support and confidence measures to assess the similarity of rankings. In this work, we carry out a sensitivity analysis of these similarity-based measures. We want to understand which datasets benefit more from such measures and which parameters have more influence in the accuracy of the model. Furthermore, we propose an alternative type of rules, the Pairwise Association Rules (PAR), which are defined as association rules with a set of pairwise preferences in the consequent. While PAR can be used both as descriptive and predictive models, they are essentially descriptive models. Experimental results show the potential of both approaches."
}

 
@article{YADAV2018,
title = "OOIMASP: Origin based association rule mining with order independent mostly associated sequential patterns",
journal = "Expert Systems with Applications",
volume = "93",
pages = "62 - 71",
year = "2018",
issn = "0957-4174",
doi = "https://doi.org/10.1016/j.eswa.2017.10.015",
url = "http://www.sciencedirect.com/science/article/pii/S0957417417306899",
author = "Deepak Yadav and C. Ravindranath Chowdary",
keywords = "Association rule mining, Mostly associated sequential patterns, Unbiased support, Unbiased confidence",
abstract = "Efficient mining of association rules on a transaction dataset is an interesting and a challenging problem. The state-of-the-art MASP algorithm is dependent on the order of items in the transaction. We propose OOIMASP algorithm, which has two novel properties- 1) order independence and 2) it takes into consideration the origin of items to calculate unbiased support and unbiased confidence values. Order dependence is one of the drawbacks of MASP. OOIMASP addresses this issue by rearranging the items in transactions using a greedy frequency based approach. We compare the performance of our system with MASP on five synthetic data sets and three public data sets. The results show that our proposed approach outperforms the MASP in both the comparison metrics, i.e., the number of association rules generated and the length of the longest association rule. Both these metrics are important to evaluate the performance of an algorithm. On an average, OOIMASP algorithm generates 632 longer rules and 457 more association rules than MASP algorithm. The disadvantage of the proposed algorithm is, it requires more computational resources in terms of time, approximately 5 times more than MASP. We claim that the extra information extracted using our method compensates for the increase in time complexity as compared to MASP. The proposed method produces multiple trees which can be very useful in the visual analysis of data."
}


@article{reglas3,
title = "Three-way decisions with probabilistic rough sets",
journal = "Information Sciences",
volume = "180",
number = "3",
pages = "341 - 353",
year = "2010",
issn = "0020-0255",
doi = "https://doi.org/10.1016/j.ins.2009.09.021",
url = "http://www.sciencedirect.com/science/article/pii/S0020025509004253",
author = "Yiyu Yao",
keywords = "Decision-theoretic rough sets, Probabilistic rough sets, Three-way decisions, Hypothesis testing, Bayesian decision procedure, Classification",
abstract = "The rough set theory approximates a concept by three regions, namely, the positive, boundary and negative regions. Rules constructed from the three regions are associated with different actions and decisions, which immediately leads to the notion of three-way decision rules. A positive rule makes a decision of acceptance, a negative rule makes a decision of rejection, and a boundary rule makes a decision of abstaining. This paper provides an analysis of three-way decision rules in the classical rough set model and the decision-theoretic rough set model. The results enrich the rough set theory by ideas from Bayesian decision theory and hypothesis testing in statistics. The connections established between the levels of tolerance for errors and costs of incorrect decisions make the rough set theory practical in applications."
}


@article{barbary18,
author = {El Barbary, O. G. and Salama, A. S. and Atlam, El Sayed},
title = {Granular information retrieval using neighborhood systems},
journal = {Mathematical Methods in the Applied Sciences},
volume = {41},
number = {15},
pages = {5737-5753},
keywords = {document classification, granular computing, information retrieval, mixed neighborhood systems, rough sets, topological near open sets},
doi = {https://doi.org/10.1002/mma.4610},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/mma.4610},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/mma.4610},
abstract = {With the rapid growth of the amount of information stored on networks such as the internet, it is more difficult for information seekers to retrieve relevant information. This paper illustrates the design and improvement of a near neighborhood approach of information retrieval system to facilitate domain specific search. In exacting, a novel model depending on the notion of neighborhood system designed to rank documents according the searchers specific granularity requirements. The initial experiments confirm that our approach outperforms a classical vector-based information retrieval system. Our research work opens the door to the design and development of the next generation of internet search engines to alleviate the problem of information overload using more topological concepts.},
year = {2018}
}



@InProceedings{ben2020,
author="Ben\'itez-Caballero, M. Jos\'e
and Medina, Jes\'us
and Ram\'irez-Poussa, Elo\'isa",
editor="Lesot, Marie-Jeanne
and Vieira, Susana
and Reformat, Marek Z.
and Carvalho, Jo\~ao Paulo
and Wilbik, Anna
and Bouchon-Meunier, Bernadette
and Yager, Ronald R.",
title="Towards a Classification of Rough Set Bireducts",
booktitle="Information Processing and Management of Uncertainty in Knowledge-Based Systems",
year="2020",
publisher="Springer International Publishing",
address="Cham",
pages="759--770",
abstract="Size reduction mechanisms are very important in several mathematical fields. In rough set theory, bireducts arose to reduce simultaneously the set of attributes and the set of objects of the considered dataset, providing subsystems with the minimal sets of attributes that connect the maximum number of objects preserving the information of the original dataset. This paper presents the main properties of bireducts and how they can be used for removing inconsistencies.",
isbn="978-3-030-50153-2"
}


@InProceedings{szelag16,
author="Szel{\c{a}}g, Marcin
and Greco, Salvatore
and S{\l}owi{\'{n}}ski, Roman",
editor="Flores, V{\'i}ctor
and Gomide, Fernando
and Janusz, Andrzej
and Meneses, Claudio
and Miao, Duoqian
and Peters, Georg
and {\'{S}}l{\c{e}}zak, Dominik
and Wang, Guoyin
and Weber, Richard
and Yao, Yiyu",
title="Similarity-Based Classification with Dominance-Based Decision Rules",
booktitle="Rough Sets",
year="2016",
publisher="Springer International Publishing",
address="Cham",
pages="355--364",
abstract="We consider a similarity-based classification problem where a new case (object) is classified based on its similarity to some previously classified cases. In this process of case-based reasoning (CBR), we adopt the Dominance-based Rough Set Approach (DRSA), that is able to handle monotonic relationship ``the more similar is object y to object x with respect to the considered features, the closer is y to x in terms of the membership to a given decision class X''. At the level of marginal similarity concerning single features, we consider this similarity in ordinal terms only. The marginal similarities are aggregated within induced decision rules describing monotonic relationship between comprehensive similarity of objects and their similarities with respect to single features.",
isbn="978-3-319-47160-0"
}


@article {madrid20,
      author = "Nicolás Madrid and Jesús Medina and Eloísa Ramírez-Poussa",
      title = "Rough sets based on Galois connections",
      journal = "International Journal of Applied Mathematics and Computer Science",
      year = "2020",
      publisher = "Sciendo",
      address = "Berlin",
      volume = "30",
      number = "2",
      doi = "https://doi.org/10.34768/amcs-2020-0023",
      pages=      "299--313",
      url = "https://content.sciendo.com/view/journals/amcs/30/2/article-p299.xml"
}


@book{pawlak1,
author = {Pawlak, Zdzislaw},
title = {Rough Sets: Theoretical Aspects of Reasoning About Data},
year = {1992},
isbn = {0792314727},
publisher = {Kluwer Academic Publishers},
address = {Norwell, MA, USA},
}


@article{pawlak82,
title = {Rough sets},
journal = {International Journal of Computer and Information Science},
volume = {11},
pages = {341-356},
year = {1982},
author = {Z. Pawlak}
}


@article{pawlak81,
title = "Information systems theoretical foundations",
journal = "Information Systems",
volume = "6",
number = "3",
pages = "205 - 218",
year = "1981",
note= "",
issn = "0306-4379",
doi = "http://dx.doi.org/10.1016/0306-4379(81)90023-5",
url = "http://www.sciencedirect.com/science/article/pii/0306437981900235",
author = "Z. Pawlak",
abstract = "Some basic concepts concerning information systems are defined and investigated. With every information system a query language is associated and its syntax and semantics is formally defined. Some elementary properties of the query language are stated. The presented approach leads to a new information systems organization. The presented idea was implemented and the implementation shows many advantages compared with other methods."
}


@article{pawlak07,
title = "Rough sets and Boolean reasoning",
journal = "Information Sciences",
volume = "177",
number = "1",
pages = "41 - 73",
year = "2007",
issn = "0020-0255",
doi = "http://dx.doi.org/10.1016/j.ins.2006.06.007",
url = "http://www.sciencedirect.com/science/article/pii/S0020025506001502",
author = "Zdzis{\l}aw Pawlak and Andrzej Skowron",
keywords = "Boolean reasoning",
keywords = "Approximate Boolean reasoning",
keywords = "(In)discernibility",
keywords = "Rough sets",
keywords = "Reducts",
keywords = "Decision rules",
keywords = "Classifiers",
keywords = "Discretization",
keywords = "Symbolic value grouping",
keywords = "Association rules",
keywords = "Conflict analysis",
abstract = "In this article, we discuss methods based on the combination of rough sets and Boolean reasoning with applications in pattern recognition, machine learning, data mining and conflict analysis."
}

@InProceedings{pawlak01,
author="Pawlak, Zdzis{\l}aw",
editor="Ziarko, Wojciech
and Yao, Yiyu",
title="Rough Sets and Decision Algorithms",
booktitle="Rough Sets and Current Trends in Computing",
year="2001",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="30--45",
abstract="Rough set based data analysis starts from a data table, called an in formation system. The information system contains data about objects of interest characterized in terms of some attributes. Often we distinguish in the information system condition and decision attributes. Such information system is called a decision table. The decision table describes decisions in terms of conditions that must be satisfied in order to carry out the decision specified in the decision table. With every decision table a set of decision rules, called a decision algorithm can be associated. It is shown that every decision algorithm reveals some well known probabilistic properties, in particular it satisfies the Total Probability Theorem and the Bayes' Theorem. These properties give a new method of drawing conclusions from data, without referring to prior and posterior probabilities, inherently associated with Bayesian reasoning.",
isbn="978-3-540-45554-7"
}



@InBook{GrB2004,
  pages     = {78--95},
  title     = {Data with Missing Attribute Values: Generalization of Indiscernibility Relation and Rule Induction},
  publisher = {Springer Berlin Heidelberg},
  year      = {2004},
  author    = {Grzyma\l{}a-Busse, Jerzy W.},
  address   = {Berlin, Heidelberg},
  isbn      = {978-3-540-27794-1},
  booktitle = {Transactions on Rough Sets I: James F. Peters - Andrzej Skowron, Editors-in-Chief},
  doi       = {10.1007/978-3-540-27794-1_3},
  url       = {http://dx.doi.org/10.1007/978-3-540-27794-1_3},
}


@Article{Stefan2001,
  author    = {Stefanowski, Jerzy and Tsoukiàs, Alexis},
  title     = {Incomplete Information Tables and Rough Classification},
  journal   = {Computational Intelligence},
  year      = {2001},
  volume    = {17},
  number    = {3},
  pages     = {545--566},
  issn      = {1467-8640},
  doi       = {10.1111/0824-7935.00162},
  keywords  = {incomplete information, rough sets, fuzzy sets, similarity relation, valued tolerance relation, decision rules},
  publisher = {Blackwell Publishers Inc},
  url       = {http://dx.doi.org/10.1111/0824-7935.00162},
}


@Article{Orlowska1984,
 author  = {Ewa Or\l{}owska and Zdzis?aw Pawlak},
 title   = {Representation of nondeterministic information},
 journal = {Theoretical Computer Science},
 year    = {1984},
 volume  = {29},
 number  = {1},
 pages   = {27 - 39},
 issn    = {0304-3975},
 doi     = {http://dx.doi.org/10.1016/0304-3975(84)90010-0},
 url     = {http://www.sciencedirect.com/science/article/pii/0304397584900100},
}

@Article{Lipski:1981,
 author     = {Lipski,Jr., Witold},
 title      = {On Databases with Incomplete Information},
 journal    = {J. ACM},
 year       = {1981},
 volume     = {28},
 number     = {1},
 pages      = {41--70},
 month      = jan,
 issn       = {0004-5411},
 acmid      = {322239},
 address    = {New York, NY, USA},
 doi        = {10.1145/322234.322239},
 issue_date = {Jan. 1981},
 numpages   = {30},
 publisher  = {ACM},
 url        = {http://doi.acm.org.bibezproxy.uca.es:2048/10.1145/322234.322239},
}

@Article{Lipski:1979,
 author     = {Lipski,Jr., Witold},
 title      = {On Semantic Issues Connected with Incomplete Information Databases},
 journal    = {ACM Trans. Database Syst.},
 year       = {1979},
 volume     = {4},
 number     = {3},
 pages      = {262--296},
 month      = sep,
 issn       = {0362-5915},
 acmid      = {320088},
 address    = {New York, NY, USA},
 doi        = {10.1145/320083.320088},
 issue_date = {Sept. 1979},
 keywords   = {database, incomplete information, model logic, null values, query language semantics, relational model},
 numpages   = {35},
 publisher  = {ACM},
 url        = {http://doi.acm.org.bibezproxy.uca.es:2048/10.1145/320083.320088},
}

@Article{DaiFFS2013,
  author   = {Jianhua Dai and Haowei Tian},
  title    = {Fuzzy rough set model for set-valued data},
  journal  = {Fuzzy Sets and Systems},
  year     = {2013},
  volume   = {229},
  pages    = {54 - 68},
  note     = {Theme: Computer Science},
  issn     = {0165-0114},
  doi      = {https://doi.org/10.1016/j.fss.2013.03.005},
  url      = {http://www.sciencedirect.com/science/article/pii/S0165011413001231},
  keywords = {Set-valued data, Fuzzy rough set model, Discernibility matrix, Discernibility function, Attribute reduction},
}


%% Rules rough sets.

@article{Huang2017,
 author = {Huang, Yanyong and Li, Tianrui and Luo, Chuan and Fujita, Hamido and Horng, Shi-jinn},
 title = {Matrix-based Dynamic Updating Rough Fuzzy Approximations for Data Mining},
 journal = {Knowledge-Based Systems},
 issue_date = {March 2017},
 volume = {119},
 number = {C},
 month = mar,
 year = {2017},
 issn = {0950-7051},
 pages = {273--283},
 numpages = {11},
 url = {https://doi.org/10.1016/j.knosys.2016.12.015},
 doi = {10.1016/j.knosys.2016.12.015},
 acmid = {3062068},
 publisher = {Elsevier Science Publishers B. V.},
 address = {Amsterdam, The Netherlands, The Netherlands},
 keywords = {Incremental learning, Matrix, Rough approximations, Rough fuzzy set},
} 


@article{bai14,
author = {Bai, H. and  Ge, Y. and  Wang, J. and  Li, D. and Liao, Y. and Zheng, X.},
title = {A method for extracting rules from spatial data based on rough fuzzy sets},
journal = {Knowledge-Based Systems},
volume = {57},
pages = {28--40},
year = 2014,
}



%%%
@article{Yang201736,
title = "On some types of fuzzy covering-based rough sets ",
journal = "Fuzzy Sets and Systems ",
volume = "312",
number = "",
pages = "36 - 65",
year = "2017",
issn = "0165-0114",
doi = "https://doi.org/10.1016/j.fss.2016.10.009",
url = "http://www.sciencedirect.com/science/article/pii/S0165011416303396",
author = "Bin Yang and Bao Qing Hu",
keywords = "Fuzzy sets",
keywords = "Fuzzy Î²-covering",
keywords = "Fuzzy covering-based rough sets",
keywords = "Fuzzy Î²-neighborhood",
keywords = "Fuzzy complementary Î²-neighborhood ",
abstract = "Abstract Fuzzy coverings are a natural extension of the coverings by replacing crisp sets with fuzzy sets. Recently, an excellent introduction to the definition of a fuzzy Î²-covering is due to Ma and two fuzzy covering-based rough set models are presented. In this paper, by introducing some new definitions of fuzzy Î²-covering approximation spaces, the properties of fuzzy Î²-covering approximation spaces and Ma's fuzzy covering-based rough set models are studied. Furthermore, three new types of fuzzy covering-based rough set models as generalizations of Ma's models are first proposed in this paper. First, some properties of fuzzy Î²-covering and its fuzzy Î²-neighborhood family are proposed. We present a necessary and sufficient condition for fuzzy Î²-neighborhood family induced by a fuzzy Î²-covering to be equal to the fuzzy Î²-covering itself. Then we study the characterizations of Ma's fuzzy covering-based rough set models and give a necessary and sufficient condition for two fuzzy Î²-coverings to generate the same fuzzy covering lower approximation or the same fuzzy covering upper approximation. Finally, this paper proposes three new types of fuzzy covering-based rough set models by introducing a new notion of a fuzzy complementary Î²-neighborhood. "
}



@article{Ge20171,
title = "The rough membership functions on four types of covering-based rough sets and their applications ",
journal = "Information Sciences ",
volume = "390",
number = "",
pages = "1 - 14",
year = "2017",
note= "",
issn = "0020-0255",
doi = "https://doi.org/10.1016/j.ins.2017.01.032",
url = "http://www.sciencedirect.com/science/article/pii/S0020025517301822",
author = "Xun Ge and Pei Wang and Ziqiu Yun",
keywords = "Rough membership function",
keywords = "Covering-based rough set",
keywords = "Incomplete decision table",
keywords = "Probabilistic rough set",
keywords = "Fuzzy set ",
abstract = "Abstract Pawlakâ™s rough membership functions not only give numerical characterizations of Pawlakâ™s rough set approximations, but also establishes the relationships between Pawlakâ™s rough sets and fuzzy sets or probabilistic rough sets. However, it is noteworthy that Pawlakâ™s rough membership functions have limitations when handling incomplete data that exist widely in the real world. As will be shown in this paper, one way to overcome this is to construct rough membership functions for covering-based rough sets. In this paper, we first use an example in evidence-based medicine to illustrate how to use Pawlakâ™s rough membership function on numerically characterizing decisions under the circumstances where data are complete. Then, we construct covering-based rough membership functions for four types of covering-based rough sets which were examined by Zhu and Wang (in \{IEEE\} Transactions on Knowledge and Data Engineering 19(8)(2007) 1131-1144 and Information Sciences 201(2012) 80-92), and use them to characterize these covering-based rough sets numerically. Finally, we present theoretical backgrounds for these covering-based rough membership functions, and illustrate how to apply them on numerically characterizing decisions under the circumstances where data are incomplete. "
}



@article{wang2013,
title = "Fuzzy rough sets based on generalized residuated lattices ",
journal = "Information Sciences ",
volume = "248",
number = "0",
pages = "31--49",
year = "2013",
note= "",
issn = "0020-0255",
doi = "http://dx.doi.org/10.1016/j.ins.2013.03.051",
url = "http://www.sciencedirect.com/science/article/pii/S0020025513002673",
author = "Chun Yong Wang and Bao Qing Hu",
keywords = "Generalized L-fuzzy rough set",
keywords = "Generalized residuated lattice",
keywords = "L-fuzzy relation",
keywords = "L-topology",
keywords = "Pseudo-t-norm ",
abstract = "Abstract This paper is devoted to propose generalized L-fuzzy rough sets as a further generalization of the notion of L-fuzzy rough sets. A quadruple of approximation operators are defined to suit the situation when generalized residuated lattices are non-commutative. Generalized L-fuzzy rough sets are characterized from both constructive and axiomatic approaches. In the constructive approach, various classes of generalized L-fuzzy rough sets are investigated. Moreover, the relationship between generalized L-fuzzy rough sets and L-topologies on an arbitrary universe is discussed with generalized lower and upper sets. As an application of generalized L-fuzzy rough sets, fuzzy rough sets are proposed and studied on the unit interval [0,&#xa0;1], which are based on generalized residuated lattices induced by left-continuous pseudo-t-norms. "
}






@inbook{chris08,
title = {Fuzzy Rough Sets: From Theory into Practice},
author = {Cornelis, Chris and De Cock, Martine and Radzikowska, Anna Maria},
publisher = {John Wiley & Sons, Ltd},
isbn = {9780470724163},
url = {http://dx.doi.org/10.1002/9780470724163.ch24},
doi = {10.1002/9780470724163.ch24},
pages = {533--552},
keywords = {fuzzy rough set seminal research theory, generalized approximation space rough sets, fuzzy rough sets--theory to practice, loose approximation operators, fuzzy T -equivalence relation, query refinement application, popular Web search engine query refinement, query expansion},
booktitle = {Handbook of Granular Computing},
year = {2008},
abstract = {This chapter contains sections titled:

* Introduction
* Preliminaries
* Fuzzy Rough Sets
* Application to Query Refinement
* Summary
* Acknowledgment
* References},
}



 
 @inproceedings{cedi-medina,
	Author = {J. Medina},
	Booktitle = {III Simposio sobre Lógica Fuzzy y Soft Computing
 (LFSC 2010)},
	Title = {Multi-Adjoint Viewpoint on Property/Object-Oriented   Concept Lattices},
pages = {398--403},
	Year = {2010},
	}

%:RSKT2010.	
  @article{rskt-medina,
	Author = {J. Medina},
	Journal = {Lecture Notes in Artificial Intelligence}, 
	Title = {Towards multi-adjoint property-oriented concept lattices},
	Year = {2010},
	  volume = {6401},
	   pages = {159--166},
	}

  @article{ins-medina,
	Author = {Jes\'us Medina},
	Journal = {Information Sciences}, 
	Title = {Multi-adjoint property-oriented and object-oriented  concept lattices},
	  volume = {190},
	   pages = {95--106},
	Year = {2012},
         doi ={10.1016/j.ins.2011.11.016},
 	}


 
 
 
 @article{lai2009,
author = "H. Lai and D. Zhang",
title = "Concept lattices of fuzzy contexts: Formal concept analysis vs. rough set theory",
journal = "International Journal of Approximate Reasoning",
volume = "50",
number = "5",
pages = "695--707",
year = "2009",
note= "",
issn = "0888-613X",
doi = "10.1016/j.ijar.2008.12.002",
keywords = "Formal concept analysis",
keywords = "Rough set theory",
keywords = "Concept lattice",
keywords = "Complete residuated lattice",
keywords = "Fuzzy closure system",
keywords = "Fuzzy opening system",
keywords = "The law of double negation"
}
 
 @article{Radzikowska2002,
author = "Anna Maria Radzikowska and Etienne E. Kerre",
title = "A comparative study of fuzzy rough sets",
journal = "Fuzzy Sets and Systems",
volume = "126",
number = "2",
pages = "137--155",
year = "2002",
note= "",
issn = "0165-0114",
doi = "DOI: 10.1016/S0165-0114(01)00032-X",
url = "http://www.sciencedirect.com/science/article/B6V05-452D8XD-1/2/c548656a44484908fe85f0ad50fd70bd",
keywords = "Fuzzy set theory",
keywords = "Rough set theory",
keywords = "Fuzzy implicator",
keywords = "Fuzzy rough set"
}

@article{yao2004,
author = "Y. Y. Yao",
title = "A Comparative Study of Formal Concept Analysis and Rough Set Theory in Data Analysis ",
journal = "Lecture Notes in Artificial Intelligence",
volume = "3066",
pages = "59--68",
year = "2004",
}

%Inclusión por artículo con Chris en IJAR

@article{1-Ma2013,
title = "Axiomatic characterizations of dual concept lattices ",
journal = "International Journal of Approximate Reasoning ",
volume = "54",
number = "5",
pages = "690--697",
year = "2013",
note= "",
issn = "0888-613X",
doi = "http://dx.doi.org/10.1016/j.ijar.2013.01.007",
url = "http://www.sciencedirect.com/science/article/pii/S0888613X13000091",
author = "Jian-Min Ma and Wen-Xiu Zhang",
keywords = "Formal context",
keywords = "Concept lattice",
keywords = "Generalized concept system",
keywords = "Set-theoretic operator",
keywords = "Dual operator "
}

 
@article{2-Li2013,
title = "Incomplete decision contexts: Approximate concept construction, rule acquisition and knowledge reduction ",
journal = "International Journal of Approximate Reasoning ",
volume = "54",
number = "1",
pages = "149--165",
year = "2013",
note= "",
issn = "0888-613X",
doi = "http://dx.doi.org/10.1016/j.ijar.2012.07.005",
url = "http://www.sciencedirect.com/science/article/pii/S0888613X12001387",
author = "Jinhai Li and Changlin Mei and Yuejin Lv",
keywords = "Formal concept analysis",
keywords = "Rough set theory",
keywords = "Incomplete context",
keywords = "Incomplete decision context",
keywords = "Rule acquisition",
keywords = "Knowledge reduction "
}

@article{3-Shen2013,
title = "The concept lattice functors ",
journal = "International Journal of Approximate Reasoning ",
volume = "54",
number = "1",
pages = "166--183",
year = "2013",
note= "",
issn = "0888-613X",
doi = "http://dx.doi.org/10.1016/j.ijar.2012.07.002",
url = "http://www.sciencedirect.com/science/article/pii/S0888613X12001351",
author = "Lili Shen and Dexue Zhang",
keywords = "Formal concept analysis",
keywords = "Rough set theory",
keywords = "Concept lattice",
keywords = "Unital quantale",
keywords = "Complete <span style='font-style: italic'>L</span>-lattice",
keywords = "<span style='font-style: italic'>L</span>-closure space "
}


@article{5-GanterK08,
  author    = {Bernhard Ganter and
               Sergei O. Kuznetsov},
  title     = {Scale Coarsening as Feature Selection},
  journal = {Lecture Notes in Computer Science},
  volume    = {4933},
  year      = {2008},
  pages     = {217-228},
}



@article{6-GanterM09,
  author    = {Bernhard Ganter and
               Christian Meschke},
  title     = {A Formal Concept Analysis Approach to Rough Data Tables},
  journal = {Lecture Notes in Computer Science},
  pages     = {117-126},
  volume    = {5908},
  year      = {2009},
}


%:%%%%%%%%% OPTIMIZATION AND FRE



@article{HUNG2020112615,
title = {Convergence analysis of solution sets for fuzzy optimization problems},
journal = {Journal of Computational and Applied Mathematics},
volume = {369},
pages = {112615},
year = {2020},
issn = {0377-0427},
doi = {https://doi.org/10.1016/j.cam.2019.112615},
url = {https://www.sciencedirect.com/science/article/pii/S037704271930620X},
author = {Nguyen Van Hung and Vo Minh Tam and Nguyen Huy Tuan and Donal O?Regan},
keywords = {Fuzzy optimization problems, Fuzzy mappings, Approximate solution, The Painlev?kuratowski convergence, The -convergence},
abstract = {In this paper, we first consider fuzzy optimization problem (in short, (FOP)) and sequences of fuzzy optimization problems (in short, (FOP)n). Then we establish the concept of D-convergence of a sequence of fuzzy mappings and its characterizations. Finally, the Painlevé?Kuratowski lower convergence and the Painlevé?Kuratowski convergence of approximate solution sets for these problems are proposed using D-convergence of a sequence of fuzzy mappings. Some examples are provided to illustrate the essentialness of the imposed assumptions.}
}

%:%%%%%%%%% RELACIONAL

@article{ZEDAM201965,
title = {Left- and right-compatibility of order relations and fuzzy tolerance relations},
journal = {Fuzzy Sets and Systems},
volume = {360},
pages = {65-81},
year = {2019},
issn = {0165-0114},
doi = {https://doi.org/10.1016/j.fss.2018.05.021},
url = {https://www.sciencedirect.com/science/article/pii/S0165011418302975},
author = {Lemnaouar Zedam and Hassane Bouremel and Bernard {De Baets}},
keywords = {Left-compatibility, Right-compatibility, Clone relation, Order relation, Fuzzy equivalence relation, Fuzzy tolerance relation},
abstract = {In a recent paper, De Baets et al. have studied the compatibility of a(n) (strict) order relation with a fuzzy relation, and have characterized the fuzzy tolerance (and, in particular, fuzzy equivalence) relations that a given strict order relation is compatible with. We extend this study by considering the left- and right-compatibility of a(n) (strict) order relation with a fuzzy tolerance relation and vice versa. We characterize the fuzzy tolerance relations that are compatible with a given (strict) order relation. Conversely, we provide a representation of the fuzzy tolerance relations that a given strict order relation is left- or right-compatible with. Specific attention is paid to the case of fuzzy equivalence relations. We conclude by pointing out that the representation theorems in the above-mentioned paper need some minor rectification.}
}


@article{feng2013,
  title={Multiple fuzzy relation and its application to coupled fuzzy control},
  author={Feng, Jun-e and Lv, Hongli and Cheng, Daizhan},
  journal={Asian Journal of Control},
  volume={15},
  number={5},
  pages={1313--1324},
  year={2013},
  publisher={Wiley Online Library}
}

@article{dinola91,
  title={Fuzzy relation equations theory as a basis of fuzzy modelling: An overview},
  author={Di Nola, Alessandro and Pedrycz, W and Sessa, S and Sanchez, E},
  journal={Fuzzy sets and systems},
  volume={40},
  number={3},
  pages={415--429},
  year={1991},
  publisher={Elsevier}
}


@article{dubois1995,
  title={Fuzzy relation equations and causal reasoning},
  author={Dubois, Didier and Prade, Henri},
  journal={Fuzzy sets and systems},
  volume={75},
  number={2},
  pages={119--134},
  year={1995},
  publisher={Elsevier}
}



@article{RubioManzano2020,
  title={A Novel Cause-Effect Variable Analysis in Enterprise Architecture by Fuzzy Logic Techniques},
  author={C. Rubio-Manzano and Juan Carlos D\'iaz-Moreno and D. Alfonso-Robaina and A. Malleuve and Jes\'us Medina},
  year={2020},
  journal={International Journal of Computational Intelligence Systems},
  volume={13},
  issue={1},
  pages={511-523},
  issn={1875-6883},
  url={https://doi.org/10.2991/ijcis.d.200415.001},
  doi={https://doi.org/10.2991/ijcis.d.200415.001}
}


@article{SCI:Alfonso2020,
  title={Modeling enterprise architecture
and strategic management from fuzzy decision rules},
  author={D. Alfonso-Robaina  and Juan Carlos D\'iaz-Moreno and  A. Malleuve-Martinez and Jes\'us Medina and C. Rubio-Manzano},
  year={2020},
  journal={Studies in Computational Intelligence},
  volume={819},
   pages={139--147},
  }
 

@article{CornejoLoboMMAS2019,
author = {Cornejo, M. Eugenia and Lobo, David and Medina, Jesús},
title = {Bipolar fuzzy relation equations systems based on the product t-norm},
journal = {Mathematical Methods in the Applied Sciences},
volume = {42},
number = {17},
pages = {5779-5793},
keywords = {bipolar fuzzy relation equation, fuzzy set, max-product t-norm composition, negation operator},
doi = {https://doi.org/10.1002/mma.5646},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/mma.5646},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/mma.5646},
abstract = {Bipolar fuzzy relation equations arise as a generalization of fuzzy relation equations considering unknown variables together with their logical connective negations. The occurrence of a variable and the occurrence of its negation simultaneously can give very useful information for certain frameworks where the human reasoning plays a key role. Hence, the resolution of bipolar fuzzy relation equations systems is a research topic of great interest. This paper focuses on the study of bipolar fuzzy relation equations systems based on the max-product t-norm composition. Specifically, the solvability and the algebraic structure of the set of solutions of these bipolar equations systems will be studied, including the case in which such systems are composed of equations whose independent term be equal to 0. As a consequence, this paper complements the contribution carried out by the authors on the solvability of bipolar max-product fuzzy relation equations.},
year = {2019}
}




@Article{FREMath2020,
  author    = {M.~E. Cornejo and D. Lobo and J. Medina},
title = {Solving Generalized Equations with Bounded Variables and Multiple Residuated Operators},
journal = {Mathematics},
year = {2020},
volume = {8},
number = {11},
paper = {1992},
pages = {1--22},
doi = {10.3390/math8111992},
}


@Article{CLM:FSS_bipstandard,
author = {Cornejo, M. Eugenia and Lobo, David and Medina, Jes\'us},
journal = {Fuzzy Sets and Systems},
title = {On the solvability of bipolar max-product fuzzy relation equations with the standard negation},
year = {2021},
pages = {1--18},
volume = {410},
doi = {10.1016/j.fss.2020.02.010},
keywords = {Bipolar fuzzy relation equations, Max-product composition, Standard negation, Inverse problem resolution},
abstract = {Bipolar fuzzy relation equations arise when unknown variables together with their logical negations appear simultaneously in fuzzy relation equations. This paper gives a characterization of the solvability of bipolar max-product fuzzy (relation) equations with the standard negation. In addition, some properties associated with the existence of the greatest/least solutifon or maximal/minimal solutions are shown, when these (relation) equations are solvable. Different examples are included in order to clarify the developed theory.}
}




@article{FREStandard:FSS2020,
title = {On the solvability of bipolar max-product fuzzy relation equations with the standard negation},
journal = {Fuzzy Sets and Systems},
year = {2021},
pages = {1--18},
volume = {410},
issn = {0165-0114},
doi = {https://doi.org/10.1016/j.fss.2020.02.010},
url = {https://www.sciencedirect.com/science/article/pii/S0165011420300567},
author = {M. Eugenia Cornejo and David Lobo and Jes\'us Medina},
keywords = {Bipolar fuzzy relation equations, Max-product composition, Standard negation, Inverse problem resolution},
abstract = {Bipolar fuzzy relation equations arise when unknown variables together with their logical negations appear simultaneously in fuzzy relation equations. This paper gives a characterization of the solvability of bipolar max-product fuzzy (relation) equations with the standard negation. In addition, some properties associated with the existence of the greatest/least solution or maximal/minimal solutions are shown, when these (relation) equations are solvable. Different examples are included in order to clarify the developed theory.}
}

@Article{CLM:JCAM2018,
author = {M. Eugenia Cornejo and David Lobo and Jes\'us Medina},
title = {On the solvability of bipolar max-product fuzzy relation equations with the product negation},
journal = {Journal of Computational and Applied Mathematics},
year = {2019},
volume = {354},
pages = {520 - 532},
issn = {0377-0427},
abstract = {This paper studies the solvability of the max-product fuzzy relation equations in which a negation operator is considered. Specifically, the residuated negation of the product t-norm has been introduced in these equations in order to increase the flexibility of the standard fuzzy relation equations introduced by Sanchez in 1976. The solvability and the set of solutions of these bipolar equations have been studied in different scenarios, depending on the considered number of variables and equations.},
doi = {https://doi.org/10.1016/j.cam.2018.09.051},
keywords = {Bipolar fuzzy relation equations, Max-product composition, Negation operator},
url = {http://www.sciencedirect.com/science/article/pii/S0377042718307015},
}


@article{Zhou2016Ins,
title = "Posynomial geometric programming problem subject to max-min fuzzy relation equations",
journal = "Information Sciences",
volume = "328",
pages = "15 - 25",
year = "2016",
issn = "0020-0255",
doi = "https://doi.org/10.1016/j.ins.2015.07.058",
url = "http://www.sciencedirect.com/science/article/pii/S0020025515006064",
author = "Xue-Gang Zhou and Xiao-Peng Yang and Bing-Yuan Cao",
keywords = "Posynomial geometric programming, Fuzzy relation equation, Maxâ“min composition",
abstract = "We discuss a class of posynomial geometric programming problem(PGPF), aimed at minimizing a posynomial subject to fuzzy relational equations with maxâ“min composition. By introducing auxiliary variables, we convert the PGPF into an equivalent programming problem whose objective function is a non-decreasing function with an auxiliary variable. We show that an optimal solution consists of a maximum feasible solution and one of the minimal feasible solutions by an equivalent programming problem. In addition, we introduce some rules for simplifying the problem. Then by using a branch and bound method and fuzzy relational equations (FRE) path, we present an algorithm to obtain an optimal solution to the PGPF. Finally, numerical examples are provided to illustrate the steps of the procedure."
}


@Article{DiMartino2018,
author="Di Martino, Ferdinando
and Sessa, Salvatore",
title="Comparison between images via bilinear fuzzy relation equations",
journal="Journal of Ambient Intelligence and Humanized Computing",
year="2018",
month="Oct",
day="01",
volume="9",
number="5",
pages="1517--1525",
abstract="We present a comparison between two images A and B based on the greatest solution of a system of bilinear fuzzy relation equations Aâ—‹x{\thinspace}={\thinspace}Bâ—‹x, where ``â—‹'' is the max--min composition, being A and B known as fuzzy relations and x is unknown. Here A and B are images considered as fuzzy relations being their pixels normalized in [0, 1] with respect to the grey scale used. Due to symmetry of every equation involved, A (resp., B) could be the original image and B (resp., A) is an image modified of A (resp., B), for instance, either noised or watermarked. The comparison is made by using an index which is more robust than other two indices used in previous works: the first one is based on the greatest eigen fuzzy set (with respect to max--min composition) and smallest eigen fuzzy set (with respect to min--max composition) and the second one is based on the Lukasiewicz triangular norm. The comparison is made between the original image and the same image with noise introduced at several values $\sigma$ of the standard deviation.",
issn="1868-5145",
doi="10.1007/s12652-017-0576-3",
url="https://doi.org/10.1007/s12652-017-0576-3"
}

@article{Li2017Neuro,
title = "A convergent smoothing algorithm for training max-min fuzzy neural networks",
journal = "Neurocomputing",
volume = "260",
pages = "404 - 410",
year = "2017",
issn = "0925-2312",
doi = "https://doi.org/10.1016/j.neucom.2017.04.046",
url = "http://www.sciencedirect.com/science/article/pii/S092523121730797X",
author = "Long Li and Zhijun Qiao and Yan Liu and Yuan Chen",
keywords = "Smoothing algorithm, Maxâ“min fuzzy neural network, Convergence, Fuzzy relational equation",
abstract = "In this paper, a smooth function is constructed to approximate the nonsmooth output of maxâ‰â“minâ‰ fuzzy neural networks (FNNs) and its approximation is also presented. In place of the output of maxâ‰â“minâ‰ FNNs by its smoothing approximation function, the error function, defining the discrepancy between the actual outputs and desired outputs of maxâ‰â“minâ‰ FNNs, becomes a continuously differentiable function. Then, a smoothing gradient decent-based algorithm with Armijoâ“Goldstein step size rule is formulated to train maxâ‰â“minâ‰ FNNs. Based on the existing convergent result, the convergence of our proposed algorithm can easily be obtained. Furthermore, the proposed algorithm also provides a feasible procedure to solve fuzzy relational equations with maxâ‰â“minâ‰composition. Finally, some numerical examples are implemented to support our results and demonstrate that the proposed smoothing algorithm has better learning performance than other two gradient decent-based algorithms."
}

@article{BOURKE1998,
title = "Solution algorithms for fuzzy relational equations with max-product composition",
journal = "Fuzzy Sets and Systems",
volume = "94",
number = "1",
pages = "61 - 69",
year = "1998",
issn = "0165-0114",
doi = "https://doi.org/10.1016/S0165-0114(96)00246-1",
url = "http://www.sciencedirect.com/science/article/pii/S0165011496002461",
author = "Mary M. Bourke and D.Grant Fisher",
keywords = "Inverse problem, Max-product composition, Resolution of fuzzy relational equations, t-norm composition",
abstract = "Abstract The conditions for the existence of an inverse solution to the max-min composition of fuzzy relational equations have been well documented since the original work by Sanchez [30, 31]. These same existence theorems have been extended to the t-norm composition of relational equations, in which the max-product composition is a member [5,13,26]. Several studies [8,15, 24, 33, 34, 38] have shown that the max-min operator may not always be the most desirable fuzzy relational composition and in fact the max-product operator was superior in these instances. This paper reviews the algorithms necessary to determine the complete solution of the inverse for fuzzy relational equations with max-product composition."
}
 
@article{Loetamonphong:99, 
author={J. Loetamonphong and Shu-Cherng Fang}, 
journal={IEEE Transactions on Fuzzy Systems}, 
title={An efficient solution procedure for fuzzy relation equations with max-product composition}, 
year={1999}, 
volume={7}, 
number={4}, 
pages={441-445}, 
abstract={We study a system of fuzzy relation equations with max-product composition and present an efficient solution procedure to characterize the whole solution set by finding the maximum solution as well as the complete set of minimal solutions. Instead of solving the problem combinatorially, the procedure identifies the ?nonminimal? solutions and eliminates them from the set of minimal solutions}, 
keywords={fuzzy set theory;matrix algebra;fuzzy relation equations;max-product composition;minimal solutions;nonminimal solutions;Connectors;Equations;Fuzzy logic;Fuzzy sets;Fuzzy systems;Guidelines;Industrial engineering;Operations research}, 
doi={10.1109/91.784204}, 
ISSN={1063-6706}, 
month={Aug},}

@article{STAMOU2001,
title = "Resolution of composite fuzzy relation equations based on Archimedean triangular norms",
journal = "Fuzzy Sets and Systems",
volume = "120",
number = "3",
pages = "395 - 407",
year = "2001",
issn = "0165-0114",
doi = "https://doi.org/10.1016/S0165-0114(99)00117-7",
url = "http://www.sciencedirect.com/science/article/pii/S0165011499001177",
author = "Giorgos B. Stamou and Spyros G. Tzafestas",
keywords = "t-norms, Archimedean t-norms, Sup-t-norm compositions of fuzzy relations, Fuzzy relation equations, Fuzzy inference systems",
abstract = "Abstract Lately, the sup-t-norm composition of fuzzy relations has been used instead of the well-known max-“min. Thus, there is a need for methods of studying and solving sup-t-norm fuzzy relation equations (t is any t-norm). In this paper, the solution existence problem is first studied and solvability criteria for composite fuzzy relation equations of any t-norm are given. Then, a methodology for solving fuzzy relation equations based on sup-t composition, where t is an Archimedean t-norm, is proposed. This resolution method is simpler and faster than those proposed for covering all the continuous t-norms. The result is important, since, as is shown in the paper, the only continuous t-norm that is not Archimedean is the œminimum."
}

@article{Wu2008, 
author={Y. K. Wu and S. M. Guu}, 
journal={IEEE Transactions on Fuzzy Systems}, 
title={An Efficient Procedure for Solving a Fuzzy Relational Equation With Max-Archimedean t-Norm Composition}, 
year={2008}, 
volume={16}, 
number={1}, 
pages={73-84}, 
abstract={In the literature, a necessary condition for minimal solutions of a fuzzy relational equation with max-product composition shows that each of its components is either zero or the corresponding component's value of the greatest solution. In this paper, we first extend this necessary condition to the situation with max-Archimedean triangular-norm (t-norm) composition. Based on this necessary condition, we then propose rules to reduce the problem size so that the complete set of minimal solutions can be computed efficiently. Furthermore, rather than work with the actual equations, we employ a simple matrix whose elements capture all of the properties of the equations in finding the minimal solutions. Numerical examples with specific cases of the max-Archimedean t-norm composition are provided to illustrate the procedure.}, 
keywords={fuzzy set theory;matrix algebra;optimisation;Archimedean t-norm composition;fuzzy relational equation;matrix algebra;max-product composition;minimal solution;Archimedean triangular norm (t-norm);fuzzy relational equations;minimal solutions}, 
doi={10.1109/TFUZZ.2007.902018}, 
ISSN={1063-6706}, 
month={Feb},}


@article{Hu2016,
title = "Solving  bipolar max-$T_P$ equation constrained multi-objective optimization problems",
journal = "International Journal on Soft Computing",
volume = "7",
number = "4",
pages = "11-23",
year = "2016",
author = "Cheng-Kai Hu and Fung-Bao Liu and Cheng-Feng Hu",
}

@article{Liu2016,
title = "Linear optimization of bipolar fuzzy relational equations with max-{L}ukasiewicz composition",
journal = "Information Sciences",
volume = "360",
number = "Supplement C",
pages = "149 - 162",
year = "2016",
issn = "0020-0255",
doi = "https://doi.org/10.1016/j.ins.2016.04.041",
url = "http://www.sciencedirect.com/science/article/pii/S0020025516302948",
author = "Chia-Cheng Liu and Yung-Yih Lur and Yan-Kuen Wu",
keywords = "Bipolar fuzzy relational equations, {M}ax-{L}ukasiewicz composition, 0-“1 integer linear programming problem",
abstract = "Abstract According to the literature, a linear optimization problem subjected to a system of bipolar fuzzy relational equations with max-Lukasiewicz composition can be translated into a 0-1 integer linear programming problem and solved using integer optimization techniques. However, the technique of integer optimization may involve hight computation complexity. To improve computational efficiency for solving such an optimization problem, this paper proves that each component of an optimal solution obtained from such an optimization problem can either be the corresponding components lower bound or upper bound value. Because of this characteristic, a simple value matrix with some simplified rules can be proposed to reduce the problem size first. A simple solution procedure is then presented for determining optimal solutions without translating such an optimization problem into a 0-1 integer linear programming problem. Two examples are provided to illustrate the simplicity and efficiency of the proposed algorithm."
}
 
@InProceedings{Liu2015,
  title={Some Properties of Bipolar Max-min Fuzzy Relational Equations},
  author={Chia-Cheng Liu and Yung-Yih Lur and Yan-Kuen Wu},
  booktitle = {Proceedings of the International MultiConference of Engineers and Computer Scientists 2015, Vol. II (IMECS 2015)},
  pages ="955--969",
  year={2015}
}


@article{Stankovic2017,
title = "Fuzzy relation equations and inequalities with two unknowns and their applications",
journal = "Fuzzy Sets and Systems",
volume = "322",
number = "",
pages = "86 - 105",
year = "2017",
issn = "0165-0114",
doi = "http://dx.doi.org/10.1016/j.fss.2017.03.011",
url = "http://www.sciencedirect.com/science/article/pii/S0165011417301306",
author = "Ivan Stankovi\'c and Miroslav \'Ciri\'c and Jelena Ignjatovi\'c",
keywords = "Fuzzy relation",
keywords = "Residuals of fuzzy relations",
keywords = "Fuzzy relation equation",
keywords = "Two-mode fuzzy social network",
keywords = "Fuzzy formal context",
keywords = "Data reduction",
abstract = "In this paper we study several types of systems of fuzzy relation equations and inequalities composed of a given family of fuzzy relations between two sets and two unknown fuzzy relations on these sets. Solutions to these systems are pairs of fuzzy relations on the underlying sets and can be ordered coordinatewise. We show that solutions to each of these systems form a complete lattice, and provide procedures for computing the greatest solution which is less than or equal to a given pair of fuzzy relations. We also demonstrate the application of solutions to these systems in data reduction."
}

@article{Stamenkovic2014,
title = "Reduction of fuzzy automata by means of fuzzy quasi-orders ",
journal = "Information Sciences ",
volume = "275",
number = "",
pages = "168 - 198",
year = "2014",
note= "",
issn = "0020-0255",
doi = "http://dx.doi.org/10.1016/j.ins.2014.02.028",
url = "http://www.sciencedirect.com/science/article/pii/S0020025514001340",
author = "Aleksandar Stamenkovi\'c and Miroslav \'Ciri\'c and Jelena Ignjatovi\'c",
keywords = "Fuzzy automaton",
keywords = "Fuzzy quasi-order",
keywords = "State reduction",
keywords = "Afterset automaton",
keywords = "Fuzzy relation equation",
keywords = "Fuzzy discrete event system ",
abstract = "Abstract In our recent paper we have established close relationships between state reduction of a fuzzy automaton and resolution of a particular system of fuzzy relation equations. In that paper we have also studied reductions by means of those solutions which are fuzzy equivalences. In this paper we will see that in some cases better reductions can be obtained using the solutions of this system that are fuzzy quasi-orders. Generally, fuzzy quasi-orders and fuzzy equivalences are equally good in the state reduction, but we show that right and left invariant fuzzy quasi-orders give better reductions than right and left invariant fuzzy equivalences. We also show that alternate reductions by means of fuzzy quasi-orders give better results than alternate reductions by means of fuzzy equivalences. Furthermore we study a more general type of fuzzy quasi-orders, weakly right and left invariant ones, and we show that they are closely related to determinization of fuzzy automatons. We also demonstrate some applications of weakly left invariant fuzzy quasi-orders in conflict analysis of fuzzy discrete event systems. "
}




@article{yang2016,
title = "Latticized linear programming subject to max-product fuzzy relation inequalities with application in wireless communication ",
journal = "Information Sciences ",
volume = "358-359",
number = "",
pages = "44 - 55",
year = "2016",
note= "",
issn = "0020-0255",
doi = "http://dx.doi.org/10.1016/j.ins.2016.04.014",
url = "http://www.sciencedirect.com/science/article/pii/S0020025516302493",
author = "Xiao-Peng Yang and Xue-Gang Zhou and Bing-Yuan Cao",
keywords = "Fuzzy relation inequality",
keywords = "Latticized linear programming",
keywords = "Max-product composition",
keywords = "Fuzzy relation equation",
keywords = "Wireless communication",
keywords = "Min-max programming ",
abstract = "Abstract In this paper we introduce the latticized linear programming problem subject to max-product fuzzy relation inequalities with application in the optimization management model of wireless communication emission base stations. Resolution of max-product fuzzy relation inequalities is studied by comparing with that of the corresponding max-product fuzzy relation equations. A solution matrix approach is developed for solving the proposed problem without finding all the (quasi-) minimal solutions of the constraint. For carrying out the solution matrix approach, we provide a step-by-step algorithm illustrated by a numerical example. "
}


@article{Miltersen,
title = "On converting {CNF} to {DNF} ",
journal = "Theoretical Computer Science ",
volume = "347",
number = "1-2",
pages = "325-335",
year = "2005",
note= "",
issn = "0304-3975",
doi = "http://dx.doi.org/10.1016/j.tcs.2005.07.029",
url = "http://www.sciencedirect.com/science/article/pii/S0304397505004688",
author = "Peter Bro Miltersen and Jaikumar Radhakrishnan and Ingo Wegener",
keywords = "Circuit size",
keywords = "Disjunctive normal form",
keywords = "Conjunctive normal form",
keywords = "Switching lemma "
}


@article{DINOLA199233,
title = "A study on approximate reasoning mechanisms via fuzzy relation equations",
journal = "International Journal of Approximate Reasoning",
volume = "6",
number = "1",
pages = "33 - 44",
year = "1992",
note= "",
issn = "0888-613X",
doi = "http://dx.doi.org/10.1016/0888-613X(92)90038-2",
url = "http://www.sciencedirect.com/science/article/pii/0888613X92900382",
author = "Antonio di Nola and Salvatore Sessa and Witold Pedrycz",
keywords = "expert systems",
keywords = "fuzzy relation equation",
keywords = "production rules",
abstract = "Some aspects of mechanisms of approximate reasoning and knowledge acquisition for rule-based expert systems are studied in the framework of fuzzy relation equations used for the implementation of inference procedures."
}


@article{Ciaramella2006146,
title = "Fuzzy relational neural network ",
journal = "International Journal of Approximate Reasoning ",
volume = "41",
number = "2",
pages = "146 - 163",
year = "2006",
issn = "0888-613X",
doi = "http://dx.doi.org/10.1016/j.ijar.2005.06.016",
url = "http://www.sciencedirect.com/science/article/pii/S0888613X0500054X",
author = "A. Ciaramella and R. Tagliaferri and W. Pedrycz and A. {Di Nola}",
keywords = "Fuzzy relations",
keywords = "Neural networks",
keywords = "Neuro-fuzzy systems",
keywords = "Classification and approximation tasks ",
abstract = "In this paper a fuzzy neural network based on a fuzzy relational IF-THEN reasoning scheme is designed. To define the structure of the model different t-norms and t-conorms are proposed. The fuzzification and the defuzzification phases are then added to the model so that we can consider the model like a controller. A learning algorithm to tune the parameters that is based on a back-propagation algorithm and a recursive pseudoinverse matrix technique is introduced. Different experiments on synthetic and benchmark data are made. Several results using the \{UCI\} repository of Machine learning database are showed for classification and approximation tasks. The model is also compared with some other methods known in literature. "
}


@Inbook{Peeva2016,
author="Peeva, Ketty",
editor="Angelov, Plamen and Sotirov, Sotir",
chapter="Intuitionistic Fuzzy Relational Equations in \emph{BL} Algebras",
title="Imprecision and Uncertainty in Information Representation and Processing: New Tools Based on Intuitionistic Fuzzy Sets and Generalized Nets",
year="2016",
publisher="Springer International Publishing",
address="Cham",
pages="73--85",
isbn="978-3-319-26302-1",
doi="10.1007/978-3-319-26302-1_6",
url="http://dx.doi.org/10.1007/978-3-319-26302-1_6"
}


@article{Peeva2007,
author="Peeva, Ketty and Kyosev, Yordan",
title="Algorithm for Solving Max-product Fuzzy Relational Equations",
journal="Soft Computing",
year="2007",
month="May",
day="01",
volume="11",
number="7",
pages="593--605",
abstract="Analytical methods are proposed for solving fuzzy linear system of equations when the composition is max-product. These methods provide universal algorithm for computing the greatest solution and the set of all minimal solutions, when the system is consistent. In case of inconsistency, the equations that can not be satisfied are obtained.",
issn="1433-7479",
doi="10.1007/s00500-006-0103-5",
url="https://doi.org/10.1007/s00500-006-0103-5"
}

@book{Peeva:2004,
 author = {Peeva K. and Kyosev Y.},
 title = {Fuzzy Relational Calculus: Theory, Applications and Software},
 year = {2004},
 publisher = {World Scientific Publishing Company},
} 


@ARTICLE{bartl15,
author={E. Bartl and R. Belohlavek},
journal={IEEE Transactions on Fuzzy Systems},
title={Hardness of Solving Relational Equations},
year={2015},
volume={23},
number={6},
pages={2435-2438},
abstract={Minimal solutions play a crucial role in describing all solutions of relational equations. For this reason, the problem of computing minimal solutions has for long been examined. The literature contains several algorithms for computing minimal solutions. Recently, contributions regarding computational complexity of the problem itself appeared. The complexity aspect is clearly of fundamental importance. However, the existing results contain serious flaws. In this paper, we inspect the existing contributions, clarify the flaws, examine the problem of complexity of computing minimal solutions, prove that there is no efficient algorithm computing all minimal solutions, and discuss further ramifications of our observations.},
keywords={computational complexity;fuzzy set theory;FRE;computational complexity;fuzzy relational equations;minimal solution computation;Computational complexity;Fuzzy sets;Mathematical model;Optimization;Polynomials;Silicon;Minimal solutions;minimal solutions;optimization problem;relational equation;set cover problem;set cover problem.},
doi={10.1109/TFUZZ.2015.2394396},
ISSN={1063-6706},
month={Dec},}

@article{Ignjatovic20151,
title = "Fuzzy relational inequalities and equations, fuzzy quasi-orders, closures and openings of fuzzy sets ",
journal = "Fuzzy Sets and Systems ",
volume = "260",
number = "",
pages = "1 - 24",
year = "2015",
issn = "0165-0114",
doi = "http://dx.doi.org/10.1016/j.fss.2014.05.006",
url = "http://www.sciencedirect.com/science/article/pii/S0165011414002231",
author = "Jelena Ignjatovi\'c and Miroslav \'Ciri\'c and Branimir {\v S}e{\v s}elja and Andreja Tepav{\v c}evi\'c",
keywords = "Fuzzy relations",
keywords = "Fuzzy relation inequalities",
keywords = "Fuzzy relation equations",
keywords = "Eigen fuzzy sets",
keywords = "Fuzzy quasi-orders",
keywords = "Closures",
keywords = "Openings",
keywords = "Complete residuated lattices ",
abstract = "Abstract The paper deals with systems of fuzzy relation equations known in the literature as eigen fuzzy set equations, as well as with systems of related fuzzy relation inequalities. Our main results are algorithms for computing the greatest and the smallest solutions to the considered systems of fuzzy relation inequalities, and algorithms for computing the greatest solutions to the considered systems of fuzzy relation equations. The systems are studied in the framework of complete residuated lattices as the structure of membership values, by means of fuzzy quasi-orders and closures and openings on a collection of fuzzy sets. "
}

@article{Xiong2014691,
title = "Infinite fuzzy relational equations with sup-conjunctor on complete Brouwerian lattices ",
journal = "Information Sciences ",
volume = "279",
number = "",
pages = "691 - 701",
year = "2014",
note= "",
issn = "0020-0255",
doi = "http://dx.doi.org/10.1016/j.ins.2014.04.020",
url = "http://www.sciencedirect.com/science/article/pii/S0020025514004678",
author = "Qing-quan Xiong and Xue-ping Wang",
keywords = "Fuzzy relation",
keywords = "Fuzzy relational equation",
keywords = "Conjunctor",
keywords = "Minimal solution",
keywords = "Solution set ",
abstract = "Abstract In this paper, a system of infinite fuzzy relational equations with sup-conjunctor on complete Brouwerian lattices is investigated. Some properties of attainable (resp. unattainable, partially attainable) solutions of the system are first shown, which are closely related minimal solutions. Some necessary and sufficient conditions for attainable (resp. minimal) solutions are then represented, and in the end, the set of attainable solutions is given when the right hand sides of the system either are join-irreducible elements or have irredundant finite join-decompositions. "
}


@article {CornejoFRE2017,
author = {Cornejo, M. Eugenia and Díaz-Moreno, J. Carlos and Medina, Jesús},
title = {Multi-adjoint Relation Equations: A Decision Support System for Fuzzy Logic},
journal = {International Journal of Intelligent Systems},
issn = {1098-111X},
volume ={32},
number ={8},
pages = {778--800},
keywords = {Fuzzy relation equations, Galois connection, decision support},
year = {2017},
doi = {10.1002/int.21889},
}


@article{Medina2017:ins402,
title = "Notes on `solution sets of inf-$\alpha_{T}$ fuzzy relational equations on complete Brouwerian lattice' and `fuzzy relational equations on complete Brouwerian lattices' ",
journal = "Information Sciences ",
volume = "402",
number = "",
pages = "82 - 90",
year = "2017",
note= "",
issn = "0020-0255",
doi = "http://dx.doi.org/10.1016/j.ins.2017.03.018",
url = "http://www.sciencedirect.com/science/article/pii/S0020025517306035",
author = "Jesús Medina",
keywords = "Fuzzy relation equations",
keywords = "Residual operators",
keywords = "Pseudo-t-norms "
}



@article{Medina2017:ija,
title = "Minimal solutions of generalized fuzzy relational equations: Clarifications and corrections towards a more flexible setting ",
journal = "International Journal of Approximate Reasoning ",
volume = "84",
pages = " 33-38 ",
year = "2017",
issn = "0888-613X",
doi = "http://dx.doi.org/10.1016/j.ijar.2017.02.002",
url = "http://www.sciencedirect.com/science/article/pii/S0888613X1730097X",
author = "Jes\'us Medina",
keywords = "Fuzzy relation equations",
keywords = "residuated operators",
keywords = "pseudo-t-norms "
}



@article{Medina2016,
title = "Minimal solutions of general fuzzy relation equations on linear carriers. An algebraic characterization",
journal = "Fuzzy Sets and Systems ",
volume = "311",
number = "",
pages = "112 - 123",
year = "2017",
note= "",
issn = "0165-0114",
doi = "http://dx.doi.org/10.1016/j.fss.2016.02.004",
url = "http://www.sciencedirect.com/science/article/pii/S0165011416300215",
author = "Juan Carlos D\'iaz-Moreno and Jes\'us Medina and Esko Turunen",
keywords = "Fuzzy relation equations",
keywords = "Minimal solutions",
keywords = "Residual structures "
}




@inproceedings{medina:turunen:ipmu2014,
  author    = {Jes{\'u}s Medina and
               Esko Turunen and
               Eduard Bartl and
               Juan Carlos D\'{\i}az-Moreno},
  title     = {Minimal Solutions of Fuzzy Relation Equations with General
               Operators on the Unit Interval},
  booktitle = {IPMU (3)},
  year      = {2014},
  pages     = {81-90},
  ee        = {http://dx.doi.org/10.1007/978-3-319-08852-5_9},
  crossref  = {DBLP:conf/ipmu/2014-3},
  bibsource = {DBLP, http://dblp.uni-trier.de}
}

@proceedings{DBLP:conf/ipmu/2014-3,
  editor    = {Anne Laurent and
               Olivier Strauss and
               Bernadette Bouchon-Meunier and
               Ronald R. Yager},
  title     = {Information Processing and Management of Uncertainty in
               Knowledge-Based Systems - 15th International Conference,
               IPMU 2014, Montpellier, France, July 15-19, 2014, Proceedings,
               Part III},
  booktitle = {IPMU (3)},
  publisher = {Springer},
  series    = {Communications in Computer and Information Science},
  volume    = {444},
  year      = {2014},
  isbn      = {978-3-319-08851-8},
  ee        = {http://dx.doi.org/10.1007/978-3-319-08852-5},
  bibsource = {DBLP, http://dblp.uni-trier.de}
}


@article{ciri2013,
title = "Fuzzy relation equations and subsystems of fuzzy transition systems ",
journal = "Knowledge-Based Systems ",
volume = "38",
number = "",
pages = "48 - 61",
year = "2013",
issn = "0950-7051",
doi = "http://dx.doi.org/10.1016/j.knosys.2012.02.008",
url = "http://www.sciencedirect.com/science/article/pii/S0950705112000482",
author = "Jelena Ignjatovi\'c and Miroslav \'Ciri\'c and Vesna Simovi\'c",
keywords = "Fuzzy transition systems",
keywords = "Fuzzy automata",
keywords = "Fuzzy relation equations",
keywords = "Fuzzy quasi-orders",
keywords = "Fuzzy equivalences",
keywords = "Eigen fuzzy sets ",
abstract = "In this paper we study subsystems, reverse subsystems and double subsystems of a fuzzy transition system. We characterize them in terms of fuzzy relation inequalities and equations, as eigen fuzzy sets of the fuzzy quasi-order QÎ´ and the fuzzy equivalence EÎ´ generated by fuzzy transition relations, and as linear combinations of aftersets and foresets of QÎ´ and equivalence classes of EÎ´. We also show that subsystems, reverse subsystems and double subsystems of a fuzzy transition system T form both closure and opening systems in the lattice of fuzzy subsets of A, where A is the set of states of T , and we provide efficient procedures for computing related closures and openings of an arbitrary fuzzy subset of A. These procedures boil down to computing the fuzzy quasi-order QÎ´ or the fuzzy equivalence EÎ´, which can be efficiently computed using the well-known algorithms for computing the transitive closure of a fuzzy relation. "
}




@article{Chang2013,
title = "Linear optimization problem constrained by fuzzy max-min relation equations ",
journal = "Information Sciences ",
volume = "234",
number = "",
pages = "71 - 79",
year = "2013",
issn = "0020-0255",
doi = "http://dx.doi.org/10.1016/j.ins.2011.04.042",
url = "http://www.sciencedirect.com/science/article/pii/S0020025511002167",
author = "Cheung-Wen Chang and Bih-Sheue Shieh",
keywords = "Linear optimization",
keywords = "Branch-and-bound method",
keywords = "Fuzzy relations",
keywords = "Fuzzy relation equations",
keywords = "Maxâ“min composition ",
abstract = "Fang and Li introduced the optimization model with a linear objective function and constrained by fuzzy maxâ“min relation equations. They converted this problem into a 0â“1 integer programming problem and solved it using the jump-tracking branch-and-bound method. Subsequently, Wu et al. improved this method by providing an upper bound on the optimal objective value and presented three rules for simplifying the computation of an optimal solution. This work presents new theoretical results concerning this optimization problem. They include an improved upper bound on the optimal objective value, improved rules for simplifying the problem and a rule for reducing the solution tree. Accordingly, an accelerated approach for finding the optimal objective value is presented, and represents an improvement on earlier approaches. Its potential applications are discussed. "
}




@article{li2014,
title = "Optimal solution of multi-objective linear programming with inf-$\to$ fuzzy relation equations constraint ",
journal = "Information Sciences ",
volume = "271",
number = "0",
pages = "159 - 178",
year = "2014",
note= "",
issn = "0020-0255",
doi = "http://dx.doi.org/10.1016/j.ins.2014.02.110",
url = "http://www.sciencedirect.com/science/article/pii/S0020025514002163",
author = "De-Chao Li and Sheng-Ling Geng",
keywords = "Fuzzy linear programming",
keywords = "Optimal solution",
keywords = "Inf- â†’ composition",
keywords = "Fuzzy relation equations constraint ",
abstract = "Abstract This paper aims to solve the problem of multiple-objective linear optimization model subject to a system of inf- â†’ composition fuzzy relation equations, where â†’ is R-, S- or QL-implications generated by continuous Archimedean t-norm (s-norm). Since the feasible domain of inf- â†’ relation equations constraint is nonconvex, these traditional mathematical programming techniques may have difficulty in computing efficient solutions for this problem. Therefore, we firstly investigate the solution sets of a system of inf- â†’ composition fuzzy relation equations in order to characterize the feasible domain of this problem. And then employing the smallest solution of constraint equation, we yield the optimal values of linear objective functions subject to a system of inf- â†’ composition fuzzy relation equations. Secondly, the two-phase approach is applied to generate an efficient solution for the problem of multiple-objective linear optimization model subject to a system of inf- â†’ composition fuzzy relation equations. Finally, a procedure is represented to compute the optimal solution of multiple-objective linear programming with inf- â†’ composition fuzzy relation equations constraint. In addition, three numerical examples are provided to illustrate the proposed procedure. "
}


@article{montes2011,
title = "Lattice-valued approach to closed sets under fuzzy relations: Theory and applications ",
journal = "Computers \& Mathematics with Applications ",
volume = "62",
number = "10",
pages = "3729--3740",
year = "2011",
note= "",
issn = "0898-1221",
doi = "http://dx.doi.org/10.1016/j.camwa.2011.09.021",
url = "http://www.sciencedirect.com/science/article/pii/S0898122111007899",
author = "Jorge Jim\'enez and Susana Montes and Branimir Seselja and Andreja Tepavcevi\'c",
keywords = "Fuzzy set closed under fuzzy relation",
keywords = "Eigen fuzzy set",
keywords = "Fuzzy control",
keywords = "Lattice valued fuzzy sets and relations "
}



@article{Bartl2015,
title = "Minimal solutions of generalized fuzzy relational equations: Probabilistic algorithm based on greedy approach ",
journal = "Fuzzy Sets and Systems ",
volume = "260",
number = "0",
pages = "25 - 42",
year = "2015",
issn = "0165-0114",
doi = "http://dx.doi.org/10.1016/j.fss.2014.02.012",
url = "http://www.sciencedirect.com/science/article/pii/S0165011414000645",
author = "Eduard Bartl",
keywords = "Generalized fuzzy relational equation",
keywords = "Sup-preserving aggregation structure",
keywords = "Sup-t-norm relational equation",
keywords = "Inf-residuum relational equation",
keywords = "Minimal solutions ",
abstract = "Abstract The paper deals with generalized fuzzy relational equations that are defined within a recently introduced framework of sup-preserving aggregation structures. Generalized fuzzy relational equations subsume all previously studied types of fuzzy relational equations, namely those that are based on sup-t-norm and inf-residuum compositions. The paper contributes to previous studies of generalized fuzzy relational equations by presenting a method for constructing all minimal solutions and, consequently, for determining the whole solution set for any given generalized fuzzy relational equation that is solvable and for which every solution is bounded from below by a minimal solution. Moreover, in the paper we present a simple probabilistic algorithm for finding all minimal solutions. "
}

@article{Qu201434,
title = "Conditions under which the solution sets of fuzzy relational equations over complete {B}rouwerian lattices form lattices ",
journal = "Fuzzy Sets and Systems ",
volume = "234",
number = "0",
pages = "34--45",
year = "2014",
issn = "0165-0114",
doi = "http://dx.doi.org/10.1016/j.fss.2013.03.017",
url = "http://www.sciencedirect.com/science/article/pii/S0165011413001474",
author = "Xiao-Bing Qu and Xue-Ping Wang and Man-Hua Lei",
keywords = "Lattice",
keywords = "Complete Brouwerian lattice",
keywords = "Fuzzy relation",
keywords = "Fuzzy relational equation",
keywords = "Solution set "
}


@article{sessa1989,
title = "Finite fuzzy relation equations with unique solution in complete {B}rouwerian lattices ",
journal = "Fuzzy Sets and Systems ",
volume = "29",
number = "1",
pages = "103--113",
year = "1989",
note= "",
issn = "0165-0114",
doi = "http://dx.doi.org/10.1016/0165-0114(89)90139-5",
url = "http://www.sciencedirect.com/science/article/pii/0165011489901395",
author = "Salvatore Sessa",
keywords = "Brouwerian lattice",
keywords = "linear lattice",
keywords = "finite fuzzy relation equation "
}



@article{yager1980,
title = "An approach to inference in approximate reasoning ",
journal = "International Journal of Man-Machine Studies ",
volume = "13",
number = "3",
pages = "323--338",
year = "1980",
note= "",
issn = "0020-7373",
doi = "http://dx.doi.org/10.1016/S0020-7373(80)80046-0",
url = "http://www.sciencedirect.com/science/article/pii/S0020737380800460",
author = "Ronald R. Yager",
abstract = "We investigate the problem of making inferences based on fuzzy conditional statements. We discuss a new operation for both multivalued implication and fuzzy inference. This operation is based upon the exponentiation operation. "
}

@article{yager1978,
title = "Fuzzy decision making including unequal objectives",
journal = "Fuzzy Sets and Systems",
volume = "1",
number = "2",
pages = "87 - 95",
year = "1978",
note= "",
issn = "0165-0114",
doi = "http://dx.doi.org/10.1016/0165-0114(78)90010-6",
url = "http://www.sciencedirect.com/science/article/pii/0165011478900106",
author = "Ronald R. Yager",
abstract = ""
}


@article{wang2005,
title = "Corrigendum to ``pseudo-t-norms and implication operators on a complete {B}rouwerian lattice''[{F}uzzy {S}ets and {S}ystems 132 (2002) 113--124] ",
journal = "Fuzzy Sets and Systems ",
volume = "153",
number = "2",
pages = "295--296",
year = "2005",
note= "",
issn = "0165-0114",
doi = "http://dx.doi.org/10.1016/j.fss.2005.02.012",
url = "http://www.sciencedirect.com/science/article/pii/S0165011405000783",
author = "Zhudeng Wang"
}





@article{wang2002,
title = "Pseudo-t-norms and implication operators on a complete {B}rouwerian lattice",
journal = "Fuzzy Sets and Systems ",
volume = "132",
number = "1",
pages = "113--124",
year = "2002",
note= "",
issn = "0165-0114",
doi = "http://dx.doi.org/10.1016/S0165-0114(01)00210-X",
url = "http://www.sciencedirect.com/science/article/pii/S016501140100210X",
author = "Zhudeng Wang and Yandong Yu",
keywords = "Non-classical logic",
keywords = "t-norm",
keywords = "Weak t-norm",
keywords = "Pseudo-t-norm",
keywords = "Implication",
keywords = "Strong negation "
}


@article{han2005,
title = "Notes on ``pseudo-t-norms and implication operators on a complete {B}rouwerian lattice'' and ``pseudo-t-norms and implication operators: direct products and direct product decompositions''",
journal = "Fuzzy Sets and Systems ",
volume = "153",
number = "2",
pages = "289--294",
year = "2005",
note= "",
issn = "0165-0114",
doi = "http://dx.doi.org/10.1016/j.fss.2005.02.019",
url = "http://www.sciencedirect.com/science/article/pii/S016501140500093X",
author = "Song-Chol Han and Hong-Xing Li",
keywords = "Non-classical logic",
keywords = "Complete Brouwerian lattice",
keywords = "Pseudo-t-norm",
keywords = "Implication",
keywords = "t-Norm "
}



@article{xiong2012,
title = "Fuzzy relational equations on complete {B}rouwerian lattices ",
journal = "Information Sciences ",
volume = "193",
number = "0",
pages = "141--152",
year = "2012",
note= "",
issn = "0020-0255",
doi = "http://dx.doi.org/10.1016/j.ins.2011.12.030",
url = "http://www.sciencedirect.com/science/article/pii/S0020025512000084",
author = "Qing-Quan Xiong and Xue-Ping Wang",
keywords = "Fuzzy relation",
keywords = "Fuzzy relational equation",
keywords = "Maximal solution",
keywords = "Solution set "
}


@article{xiong2007,
title = "Solution sets of fuzzy relational equations on complete {B}rouwerian lattices ",
journal = "Information Sciences ",
volume = "177",
number = "21",
pages = "4757--4767",
year = "2007",
note= "",
issn = "0020-0255",
doi = "http://dx.doi.org/10.1016/j.ins.2007.03.033",
url = "http://www.sciencedirect.com/science/article/pii/S0020025507001934",
author = "Qing-Quan Xiong and Xue-Ping Wang",
keywords = "Fuzzy relational equation",
keywords = "Complete Brouwerian lattice",
keywords = "Maximal solution",
keywords = "Solution set "
}

@article{fernandez92,
title = "Equations of fuzzy relations defined on fuzzy subsets ",
journal = "Fuzzy Sets and Systems ",
volume = "52",
number = "3",
pages = "319--336",
year = "1992",
note= "",
issn = "0165-0114",
doi = "http://dx.doi.org/10.1016/0165-0114(92)90240-5",
url = "http://www.sciencedirect.com/science/article/pii/0165011492902405",
author = "M.J. Fern\'andez and F. Su\'arez and P. Gil",
keywords = "Fuzzy relations",
keywords = "fuzzy relation equations",
keywords = "types of equations ",
abstract = "In this paper some results of the theory of fuzzy relation equations are generalized, when we consider fuzzy relations defined on fuzzy sets instead of crisp sets. If the extension of classical definitions for composition of relations [12, 13] is not straightforward, we provide suitables counterexamples illustrating the necessity of change in definitions. We find the greatest (or the least) solutions of fuzzy relation equations with different types of compositions, like the sup-T, inf-Tâ², inf-Ï• or sup-Î² compositions. "
}

@book{bvFEL:2005,
	Author = {Radim B\v{e}lohl\'avek and  Vil\'em Vychodil},
	Publisher = {Springer-Verlag},
	Title = {Fuzzy Equational Logic},
	Year = {2005},
        location  = {Berlin Heidelberg},
}

@phdthesis{bartl:Thesis,
	Author = {Bartl, E.},
	School = {Faculty of Science, Palacky University Olomouc},
	Title = {Fuzzy Relational Equation. Phd Dissertation},
	Year = {2013}
}

@article{Markovskii,
title = "On the relation between equations with max-product composition and the covering problem ",
journal = "Fuzzy Sets and Systems ",
volume = "153",
number = "2",
pages = "261--273",
year = "2005",
note= "",
issn = "0165-0114",
doi = "http://dx.doi.org/10.1016/j.fss.2005.02.010",
url = "http://www.sciencedirect.com/science/article/pii/S0165011405000643",
author = "A.V. Markovskii",
keywords = "Fuzzy relations",
keywords = "Fuzzy relation equations",
keywords = "Inverse problem",
keywords = "Max-product composition",
keywords = "Minimal solutions",
keywords = "Covering problem",
keywords = "NP-hard problems",
keywords = "NP-complete problems "
}

@article{LinJL,
title = "On the relation between fuzzy max-Archimedean t-norm relational equations and the covering problem ",
journal = "Fuzzy Sets and Systems ",
volume = "160",
number = "16",
pages = "2328--2344",
year = "2009",
issn = "0165-0114",
doi = "http://dx.doi.org/10.1016/j.fss.2009.01.012",
url = "http://www.sciencedirect.com/science/article/pii/S0165011409000591",
author = "Jun-Lin Lin",
keywords = "Fuzzy constraint satisfaction",
keywords = "Fuzzy relational equations",
keywords = "Max-Archimedean t-norm composition",
keywords = "Covering problem "
}


@article{Turunen1987,
author = {Turunen, Esko},
journal = {Acta Universitatis Carolinae. Mathematica et Physica},
keywords = {fuzzy equations; lattice valued fuzzy relations; sup-min composition; solvability criteria},
language = {eng},
number = {1},
pages = {33-37},
publisher = {Charles University in Prague},
title = {On generalized fuzzy relation equations: necessary and sufficient conditions for the existence of solutions},
url = {http://eudml.org/doc/246361},
volume = {028},
year = {1987},
}

@article{Qu2014,
title = "Conditions under which the solution sets of fuzzy relational equations over complete {B}rouwerian lattices form lattices ",
journal = "Fuzzy Sets and Systems ",
volume = "234",
number = "0",
pages = "34--45",
year = "2014",
issn = "0165-0114",
doi = "http://dx.doi.org/10.1016/j.fss.2013.03.017",
url = "http://www.sciencedirect.com/science/article/pii/S0165011413001474",
author = "Xiao-Bing Qu and Xue-Ping Wang and Man-Hua Lei",
keywords = "Lattice",
keywords = "Complete Brouwerian lattice",
keywords = "Fuzzy relation",
keywords = "Fuzzy relational equation",
keywords = "Solution set ",
abstract = "Abstract It is well known that the solution set of a fuzzy relational equation with supâ“inf composition is a join semilattice, in general, not a meet semilattice. This paper investigates the conditions under which the solution sets of fuzzy relational equations with sup-inf composition over complete Brouwerian lattices form lattices. We first give some properties of the decompositions of elements in complete lattices, then present a necessary and sufficient condition that the meet of a solution with any other solution is again a solution. Finally, we show some necessary and sufficient conditions that the solution sets are lattices. "
}



@article{Li2013,
title = "Complete solution sets of inf-â†’ interval-valued fuzzy relation equations ",
journal = "Information Sciences ",
volume = "219",
number = "0",
pages = "111--123",
year = "2013",
note= "",
issn = "0020-0255",
doi = "http://dx.doi.org/10.1016/j.ins.2012.07.019",
url = "http://www.sciencedirect.com/science/article/pii/S0020025512004835",
author = "De-chao Li and Yong-jian Xie and Sheng-ling Geng",
keywords = "Interval-valued fuzzy implications",
keywords = "Interval-valued fuzzy relation equations",
keywords = "Maximal solutions",
keywords = "Solutions sets",
keywords = "Semilinear space "
}


@article{Sun2012,
title = "Conditions for the existence of the least solution and minimal solutions to fuzzy relation equations over complete {B}rouwerian lattices ",
journal = "Information Sciences ",
volume = "205",
number = "0",
pages = "86--92",
year = "2012",
note= "",
issn = "0020-0255",
doi = "http://dx.doi.org/10.1016/j.ins.2012.04.002",
url = "http://www.sciencedirect.com/science/article/pii/S002002551200240X",
author = "Feng Sun",
keywords = "Fuzzy relation",
keywords = "Fuzzy relation equations",
keywords = "The least solution",
keywords = "Minimal solutions",
keywords = "Complete Brouwerian lattices "
}



 @inproceedings{golinska-fca,
	Author = {J. Golinska-Pilarek and E. Orlowska},
	Booktitle = {{IEEE} Intl. Conf. on Fuzzy 
Systems ({FUZZ-IEEE} 2007)},
	Pages = {1--6},
	Title = {Relational reasoning in formal concept analysis},
	Year = {2007},
	Abstract = {23-26 July, 2007, Imperial College, London, UK. IEEE Press},
	}

 

%:%%%%%%%%%%%%  EQUATIONS PERFILIEVA 
@article{Perfilieva13,
  author    = {Irina Perfilieva},
  title     = {Finitary solvability conditions for systems of fuzzy relation equations},
  journal   = {Information Sciences},
  volume    = {234},
  pages     = {29--43},
  year      = {2013},
  url       = {http://dx.doi.org/10.1016/j.ins.2011.04.035},
  doi       = {10.1016/j.ins.2011.04.035},
 }


 





%:Definition and properties and solutions  using concept lattices",
@article{dm:ins2014,
title = "Using concept lattice theory to obtain the set of solutions of multi-adjoint relation equations ",
journal = "Information Sciences ",
volume = "266",
number = "0",
pages = "218--225",
year = "2014",
note= "",
issn = "0020-0255",
doi = "http://dx.doi.org/10.1016/j.ins.2014.01.006",
url = "http://www.sciencedirect.com/science/article/pii/S0020025514000127",
author = "Juan Carlos D\'iaz-Moreno and Jes\'us Medina",
keywords = "Fuzzy relation equation",
keywords = "Galois connection",
keywords = "Property-oriented concept lattice "
}




@article{dm:mare,
title = "Multi-adjoint relation equations: Definition, properties
and solutions using concept lattices",
journal = "Information Sciences",
volume = "253",
pages = "100--109",
year = "2013",
issn = "0020-0255",
author = "J. C. D\'iaz-Moreno and J. Medina",
}

@article{dm:ins2013,
title = "Solving systems of fuzzy relation equations by fuzzy property-oriented concepts",
journal = "Information Sciences",
volume = "222",
number = "",
pages = "405-412",
year = "2013",
issn = "0020-0255",
url = "http://www.sciencedirect.com/science/article/pii/S0020025512005701?v=s5",
author = "J. C. D\'iaz-Moreno and J. Medina",
keywords = "doi:10.1016/j.ins.2012.08.017",
keywords = "Fuzzy relation equations",
keywords = "Galois connection",
keywords = "Property-oriented concept lattice"
}




@inproceedings{dm:cla2011,
	author = {J. C. D\'iaz-Moreno and J. Medina},
 	Title = {Concept lattices in fuzzy relation equations},
         Booktitle     = {The 8th International Conference on Concept Lattices and Their Applications},
        year      = {2011},
        pages = {75--86},
	}


@inproceedings{dm:estylf2012,
	author = {J. C. D\'{i}az and J. Medina and R. Rodr\'iguez},
 	Title = {Solutions of systems of fuzzy relation equations as concepts of a formal context},
         Booktitle     = {XVI Congreso Español sobre Tecnologías y Lógica
Fuzzy, ESTYLF 2012},
        year      = {2012},
        pages = {156--162},
}


@inproceedings{dm:estylf2014,
	author = {J. C. D\'iaz and J. Medina},
 	Title = {Applying multi-adjoint relation equations to fuzzy logic programming},
         Booktitle     = {XVII Congreso Español sobre Tecnologías y Lógica
Fuzzy, ESTYLF 2014},
        year      = {2014},
        pages = {121--126},
}


@article{belohlavek10JLC,
	Author =  {R. B{\v e}lohl{\'a}vek},
    title = {Optimal decompositions of matrices with entries from residuated lattices},
journal = {Journal of Logic and Computation},
volume = {22},
number = {6},
pages = {1405-1425},
year = {2011},
issn = {0955-792X},
doi = {10.1093/logcom/exr023},
url = {https://doi.org/10.1093/logcom/exr023},
eprint = {https://academic.oup.com/logcom/article-pdf/22/6/1405/2928354/exr023.pdf},
}}

@article{belohlavek10IJGS,
author = {Bartl, Eduard and B{\v e}lohl{\'a}vek, Radim},
title = {Sup-t-norm and inf-residuum are a single type of relational equations},
journal = {International Journal of General Systems},
volume = {40},
number = {6},
pages = {599-609},
year = {2011},
doi = {10.1080/03081079.2011.571438},
URL = {http://www.tandfonline.com/doi/abs/10.1080/03081079.2011.571438},
eprint = {http://www.tandfonline.com/doi/pdf/10.1080/03081079.2011.571438}
}



@article{Radim2012,
title = "Sup-t-norm and inf-residuum are one type of relational product: Unifying framework and consequences",
journal = "Fuzzy Sets and Systems",
volume = "197",
pages = "45--58",
year = "2012",
note= "",
issn = "0165-0114",
doi = "10.1016/j.fss.2011.07.015",
url = "http://www.sciencedirect.com/science/article/pii/S0165011411003575",
author = "R. B{\v e}lohl{\'a}vek",
keywords = "Residuated lattice",
keywords = "Fuzzy logic",
keywords = "Fuzzy relations",
keywords = "Relational product",
keywords = "Duality"
}

@article{Belohlavek:2004,
 author = {B{\v e}lohl\'{a}vek, Radim},
 title = {Concept Equations},
 journal = {Journal of Logic and Computation},
 volume = {14},
 number = {3},
 year = {2004},
 issn = {0955-792X},
 pages = {395--403},
 numpages = {9},
 url = {http://dx.doi.org/10.1093/logcom/14.3.395},
 doi = {10.1093/logcom/14.3.395},
 acmid = {1094479},
 publisher = {Oxford University Press},
 address = {Oxford, UK},
 keywords = {Port-Royal logic, formal concept, relational equation, fuzzy logic},
} 


@book{Nola:1989,
 author = {{Di Nola}, A.  and Sanchez, E. and Pedrycz, W. and Sessa, S.},
 title = {Fuzzy Relation Equations and Their Applications to Knowledge Engineering},
 year = {1989},
 isbn = {0792303075},
 publisher = {Kluwer Academic Publishers},
 address = {Norwell, MA, USA},
} 

@book{rudeanu74,
author = {Rudeanu, S.},
title = {Boolean functions and equations},
year = {1974},
publisher = {North-Holland},
 address = {Amsterdan},
}
 
@book{turunen99,
author = {Turunen, E},
title = {Mathematics behind fuzzy logic},
year = {1999},
publisher = {Physica-Verlag},
}


@inproceedings{perfilieva10Old,
	author = {Irina Perfilieva},
         editor    = {Eyke H\"{u}llermeier and Rudolf Kruse and Frank Hoffmann},
 	Title = {Fuzzy Relation Equations in Semilinear Spaces},
         Booktitle     = {Information Processing and Management of Uncertainty in       Knowledge-Based Systems},
        publisher = {Springer},
        location  = {Heidelberg},
        series    = {Communications in Computer and Information Science},
        volume    = {80},
        year      = {2010},
        isbn      = {978-3-642-14054-9},
        pages = {545--552},
	}

@article{perfilieva_equations,
	author = {Irina Perfilieva},
 	Title = {Fuzzy Relation Equations in Semilinear Spaces},
        publisher = {Springer},
        location  = {Heidelberg},
        journal    = {Communications in Computer and Information Science},
        volume    = {80},
        year      = {2010},
        isbn      = {978-3-642-14054-9},
        pages = {545--552},
	}
	
	
@inproceedings{perfilieva_equationsold,
	author = {Irina Perfilieva},
         editor    = {Eyke H\"{u}llermeier and Rudolf Kruse and Frank Hoffmann},
 	Title = {Fuzzy Relation Equations in Semilinear Spaces},
         Booktitle     = {Information Processing and Management of Uncertainty in       Knowledge-Based Systems},
        publisher = {Springer},
        location  = {Heidelberg},
        series    = {Communications in Computer and Information Science},
        volume    = {80},
        year      = {2010},
        isbn      = {978-3-642-14054-9},
        pages = {545--552},
	}
	
	
	
@article{perfilieva08_fss,
title = "System of fuzzy relation equations with inf-$\to$ composition: Complete set of solutions",
journal = "Fuzzy Sets and Systems",
volume = "159",
number = "17",
pages = "2256--2271",
year = "2008",
issn = "0165-0114",
doi = "DOI: 10.1016/j.fss.2007.12.012",
url = "http://www.sciencedirect.com/science/article/B6V05-4RBYCXT-1/2/f8e5fa99ec4a89052f25ef8f649cc1ea",
author = "I. Perfilieva and L. Noskov\'a",
keywords = "System of fuzzy relation equations",
keywords = "inf---> composition",
keywords = "Maximal solution",
keywords = "Solution set",
abstract = "
The problem of solvability of a system of equations with inf---> composition is considered on finite universes. Equations are expressed using operations of a BL-algebra. We study complete set of solutions of the respective system in the particular case (one equation) and in the general case. In both cases, various conditions of solvability are found and proved. We characterize all maximal solutions and prove that under certain conditions each solution of the system (an equation) is less than or equal to a respective maximal one. As a result, we are able to characterize the complete set of solutions. Examples of single equations and their systems are considered and complete sets of solutions are found for each."
}



@article{perfilieva04,
title = "Fuzzy function as an approximate solution to a system of fuzzy relation equations",
journal = "Fuzzy Sets and Systems",
volume = "147",
number = "3",
pages = "363--383",
year = "2004",
issn = "0165-0114",
doi = "DOI: 10.1016/j.fss.2003.12.007",
url = "http://www.sciencedirect.com/science/article/B6V05-4BD5GWH-1/2/015fbc041c7c61aed0a769760624df7f",
author = "Irina Perfilieva",
keywords = "System of fuzzy relation equations",
keywords = "Solvability and approximate solvability of a fuzzy relation equation system",
keywords = "Fuzzy function",
keywords = "Interpolation and approximation of fuzzy functions",
abstract = "
This paper is mostly focused on the problem of approximate solvability of a system of fuzzy relation equations. However, we put a new light on this problem connecting it with the interpolation of a fuzzy function. We introduce a notion of fuzzy function and its representation by fuzzy relation. We demonstrate how problems of interpolation and approximation of fuzzy functions are connected with solvability of systems of fuzzy relation equations. First, we explain the general framework and then we prove some results related to the problem of the best approximation. In particular, we have shown that fuzzy relations introduced by Sanchez and Mamdani are the best approximations in certain approximation spaces."
}




@article{perfilieva00,
title = "COMPATIBILITY OF SYSTEMS OF FUZZY RELATION EQUATIONS",
journal = "International Journal of General Systems",
volume = "29",
number = "4",
pages = "511--528",
year = "2000",
issn = "0308-1079",
author = "Irina Perfilieva and Alexander Tonis",
keywords = "System of fuzzy relation equations",
abstract = "
In this paper, a fuzzy relation equation system with the generalized conjunction and implication operations is considered. Necessary and sufficient conditions of solvability of this system are proved. The case where these conditions are not fulfilled is considered and the solvability degree of the approximate solution is estimated. The interpolation property of the solution independently on whether it is precise or approximate is established."
}


 
@article{sanchez76,
title = "Resolution of composite fuzzy relation equations",
journal = "Information and Control",
volume = "30",
number = "1",
pages = "38--48",
year = "1976",
note= "",
issn = "0019-9958",
doi = "DOI: 10.1016/S0019-9958(76)90446-0",
author = "E. Sanchez",
abstract = "
This paper provides a methodology for solution of certain basic fuzzy relational equations, with fuzzy sets defined as mappings from sets into complete Brouwerian lattices, covering a large class of types of fuzzy sets."
}
%De sanchez76 url = "http://www.sciencedirect.com/science/article/B7MFM-4DX49K7-24/2/0cd901253364635956c194a1b39595ff",


@article{dinola84,
title = "Fuzzy relation equation under a class of triangular norms: A survey and new results",
journal = "Stochastica: revista de matemática pura y aplicada",
volume = "8",
number = "2",
pages = "99--145",
year = "1984",
issn = "0210-7821",
Author = {{Di Nola}, A. and  Sessa, S. and  Pedrycz, W.},
abstract = "
This paper provides a methodology for solution of certain basic fuzzy relational equations, with fuzzy sets defined as mappings from sets into complete Brouwerian lattices, covering a large class of types of fuzzy sets."
}

 

@ incollection{baets99_eq,
	Author = {{De Baets}, B.},
	Booktitle = {The Handbooks of Fuzzy Sets Series},
	Editor = {Dubois, D. and Prade, H.},
	Publisher = {Kluwer, Dordrecht},
	Title = {Analytical solution methods for fuzzy relation equations},
	Volume = {1},
	Pages = {291--340},
	Year = {1999}}
	
	

		
@article{zadeh_ling75,
	Author = {Zadeh, L.~A.},
	Journal = {Information Sciences},
	Pages = {199--257, 301--357, 43--80},
	Title = {The concept of a linguistic variable and its application to approximate reasoning
{I}, {II}, {III}},
	Volume = {8--9},
	Year = {1975}}
	
		
@article{Kohout80,
	Author = {Bandler, W. and Kohout, L.},
	Journal = {Int. J. Man-Machine Studies},
	Pages = {89--116},
	Title = {Semantics of implication operators and fuzzy relational products},
	Volume = {12},
	Year = {1980}}
	
	@article{PedryczGC:83,
title = "Fuzzy relational equations with generalized connectives and their applications",
journal = "Fuzzy Sets and Systems",
volume = "10",
number = "1-3",
pages = "185--201",
year = "1983",
note= "",
issn = "0165-0114",
doi = "DOI: 10.1016/S0165-0114(83)80114-6",
url = "http://www.sciencedirect.com/science/article/pii/S0165011483801146",
author = "Witold Pedrycz",
keywords = "Fuzzy relational equation",
keywords = "Connectives",
keywords = "Fuzzy systems analysis",
keywords = "Decision-making"
}

@article{PedryczGC:85,
title = "On generalized fuzzy relational equations and their applications",
journal = "Journal of Mathematical Analysis and Applications",
volume = "107",
number = "2",
pages = "520 - 536",
year = "1985",
issn = "0022-247X",
doi = "https://doi.org/10.1016/0022-247X(85)90329-4",
url = "http://www.sciencedirect.com/science/article/pii/0022247X85903294",
author = "Witold Pedrycz",
abstract = "Abstract The paper provides an idea of generalization of fuzzy relational equations where t- and s-norms are introduced. The first part contains an extensive presentation of the resolution of fuzzy relational equations; next the solutions are specified for a list of several triangular norms. Moreover the dual equations are considered. The second part deals with the applicational aspects of these equations in systems analysis, decision-making, and arithmetic of fuzzy numbers."
}

@article {chenwang02,
   author = {Chen, L. and Wang, P. P.},
   affiliation = {Department of Computing and Information Systems, University of Luton, Luton, LU1 3JU, UK, and Scientific & Practical Computing, P.O. Box 17, Centerville, UT 84014, USA e-mail: moorechen@yahoo.com US},
   title = {Fuzzy relation equations (I): the general and specialized solving algorithms},
   journal = {Soft Computing--A Fusion of Foundations, Methodologies and Applications},
   publisher = {Springer Berlin / Heidelberg},
   issn = {1432-7643},
   keyword = {Computer Science},
   pages = {428-435},
   volume = {6},
   issue = {6},
   url = {http://dx.doi.org/10.1007/s00500-001-0157-3},
    year = {2002}
}

@article {chenwang07,
   author = {Chen, Li and Wang, Paul},
   affiliation = {University of the District of Columbia Department of Electrical Engineering and Computer Science Washington DC 20008 USA Washington DC 20008 USA},
   title = {Fuzzy Relation Equations (II): The Branch-point-solutions and the Categorized Minimal Solutions},
   journal = {Soft Computing--A Fusion of Foundations, Methodologies and Applications},
   publisher = {Springer Berlin / Heidelberg},
   issn = {1432-7643},
   keyword = {Computer Science},
   pages = {33-40},
   volume = {11},
   issue = {1},
   url = {http://dx.doi.org/10.1007/s00500-006-0050-1},
   year = {2007},
abstract = {   This paper presents some novel theoretical results
as well as practical algorithms and computational procedures
on fuzzy relation equations (FRE)(max-min). These results refine and
improve what has already been reported in a significant manner.
In the previous paper, the authors have already proved
that the problem of solving the system of fuzzy relation equations
is an NP-hard problem. Therefore, it is practically
impossible to determine all minimal solutions for a large
system if P \noteq NP. In this paper, an existence theorem is
proven: there exists a special branch-point-solution that is
greater than all minimal solutions and less than the maximum
solution. Such branch-point-solution can be calculated
based on the solution-base-matrix. Furthermore, a procedure
for determining all branch-point-solutions is designed. We
also provide efficient algorithms which is capable of determining
as well as searching for certain types ofminimal solutions.
We have thus obtained: (1) a fast algorithm to determine
whether a solution is a minimal solution, (2) the algorithm to
search for the minimal solutions that has at least a minimum
value at a component in the solution vector, and (3) the procedure
of determining if a system of fuzzy relation equations
has the unique minimal solution. Other properties are also
investigated.}
}



@article{Yeh2008,
title = "On the minimal solutions of max-min fuzzy relational equations",
journal = "Fuzzy Sets and Systems",
volume = "159",
number = "1",
pages = "23--39",
year = "2008",
issn = "0165-0114",
doi = "10.1016/j.fss.2007.07.017",
url = "http://www.sciencedirect.com/science/article/pii/S0165011407003478",
author = "Chi-Tsuen Yeh",
keywords = "Fuzzy relational equation",
keywords = "Minimal solution",
keywords = "Max-min algebra",
keywords = "Matrix representation",
keywords = "Irredundant covering",
abstract = "In this paper, the minimal solutions of max-“min fuzzy relational equations are investigated. A sufficient and necessary condition, for discriminating whether a given solution is minimal or not, is shown. Furthermore, we propose a new algorithm for computing all minimal solutions less than or equal to a given one."
}

@article{Lin2011,
title = "On fuzzy relational equations and the covering problem",
journal = "Information Sciences",
volume = "181",
number = "14",
pages = "2951--2963",
year = "2011",
note= "",
issn = "0020-0255",
doi = "10.1016/j.ins.2011.03.004",
url = "http://www.sciencedirect.com/science/article/pii/S002002551100123X",
author = "Jun-Lin Lin and Yan-Kuen Wu and Sy-Ming Guu",
keywords = "Fuzzy relational equations",
keywords = "Max-Archimedean <span style='font-style: italic'>t</span>-norm composition",
keywords = "Max-arithmetic mean composition",
keywords = "Covering problem",
abstract = "Previous studies have shown that fuzzy relational equations (FREs) based on either the max-continuous Archimedean t-norm or the max-arithmetic mean composition can be transformed into the covering problem, which is an NP-hard problem. Exploiting the properties common to the continuous Archimedean t-norm and the arithmetic mean, this study proposes a generalization of them as the âœu-normâ, enabling FREs that are based on the max-continuous u-norm composition also to be transformed into the covering problem. This study also proposes a procedure for transforming the covering problem into max-product FREs. Consequently, max-continuous u-norm FREs can be solved by extending any procedure for solving either the covering problem or max-product FREs."
}

%Basado en el anterior (FRE Covering problem) se tiene el siguiente:
@article{Shieh2013,
title = "Solution to the covering problem ",
journal = "Information Sciences ",
volume = "222",
number = "0",
pages = "626--633",
year = "2013",
issn = "0020-0255",
doi = "10.1016/j.ins.2012.08.018",
url = "http://www.sciencedirect.com/science/article/pii/S0020025512005713",
author = "Bih-Sheue Shieh",
keywords = "Covering problem",
keywords = "Combinatorial problem",
keywords = "Minimal covering",
keywords = "Fuzzy relation equation",
keywords = "Minimal solution ",
abstract = "This work is motivated by recent investigations that reveal the intractability of the covering problem. Current methods for solving this problem lack an explicit procedure. Therefore, they are of limited value. This work presents the steps for solving such problems using a novel algorithm. The search performance is better than that achieved in other works. Some numerical examples are presented to demonstrate the performance and to compare it with the performance of other methods. The proposed algorithm can be utilized to solve fuzzy relation equations that exhibit the zero-or-greatest property. 
%Shieh2013 también left-continuous u-norms and 
%fuzzy relation equations that exhibit the zero-or-greatest property
"
}



%:%%%%%%%%%%%%  Optimización Lineal con restricciones (FRE)

@article{molai2010,
title = "Two new algorithms for solving optimization problems with one linear objective function and finitely many constraints of fuzzy relation inequalities",
journal = "Journal of Computational and Applied Mathematics",
volume = "233",
number = "8",
pages = "2090 - 2103",
year = "2010",
issn = "0377-0427",
doi = "https://doi.org/10.1016/j.cam.2009.09.042",
url = "http://www.sciencedirect.com/science/article/pii/S0377042709006669",
author = "Ali Abbasi Molai",
keywords = "Fuzzy relation inequality, Max-Einstein composition, Fuzzy optimization, Minimum solution, Partial solution",
abstract = "Abstract This paper studies the optimization model of a linear objective function subject to a system of fuzzy relation inequalities (FRI) with the max-Einstein composition operator. If its feasible domain is non-empty, then we show that its feasible solution set is completely determined by a maximum solution and a finite number of minimal solutions. Also, an efficient algorithm is proposed to solve the model based on the structure of FRI path, the concept of partial solution, and the branch-and-bound approach. The algorithm finds an optimal solution of the model without explicitly generating all the minimal solutions. Some sufficient conditions are given that under them, some of the optimal components of the model are directly determined. Some procedures are presented to reduce the search domain of an optimal solution of the original problem based on the conditions. Then the reduced domain is decomposed (if possible) into several sub-domains with smaller dimensions that finding the components of the optimal solution in each sub-domain is very easy. In order to obtain an optimal solution of the original problem, we propose another more efficient algorithm which combines the first algorithm, these procedures, and the decomposition method. Furthermore, sufficient conditions are suggested that under them, the problem has a unique optimal solution. Also, a comparison between the recently proposed algorithm and the known ones will be made."
}




%:%%%%%%%%%%%%   BIPOLAR -  FRelationEquations

@article{sci:bipolar19,
author="Cornejo, M. Eugenia
and Lobo, David
and Medina, Jes{\'u}s",
title="Bipolar Max-Product Fuzzy Relation Equations with the Product Negation",
bookTitle="Trends in Mathematics and Computational Intelligence",
journal="Studies in Computational Intelligence",
pages="147--153",
volume = "796",
year = "2019",
abstract="ThisCornejo, M. Eugenia paperLobo, David willMedina, Jes{\'u}s study the bipolar fuzzy relation equation based on the max-product composition and the adjoint negation operator obtained from the product residuated implication. Interesting properties and different examples of this bipolar max-product fuzzy relation equation will be introduced.",
isbn="978-3-030-00485-9",
doi="10.1007/978-3-030-00485-9_17",
url="https://doi.org/10.1007/978-3-030-00485-9_17"
}


@InProceedings{Cornejo2019,
author="Cornejo, M. Eugenia
and Lobo, David
and Medina, Jes{\'u}s",
editor="Cornejo, Mar{\'i}a Eugenia
and K{\'o}czy, L{\'a}szl{\'o} T.
and Medina, Jes{\'u}s
and De Barros Ruano, Antonio Eduardo",
title="Bipolar Max-Product Fuzzy Relation Equations with the Product Negation",
bookTitle="Trends in Mathematics and Computational Intelligence",
year="2019",
book="Studies in Computational Intelligence",
publisher="Springer International Publishing",
address="Cham",
pages="147--153",
volume = "796",
abstract="ThisCornejo, M. Eugenia paperLobo, David willMedina, Jes{\'u}s study the bipolar fuzzy relation equation based on the max-product composition and the adjoint negation operator obtained from the product residuated implication. Interesting properties and different examples of this bipolar max-product fuzzy relation equation will be introduced.",
isbn="978-3-030-00485-9",
doi="10.1007/978-3-030-00485-9_17",
url="https://doi.org/10.1007/978-3-030-00485-9_17"
}

@InProceedings{fuzzieee2017,
author = {M.E. Cornejo and D. Lobo and J. Medina},
title = {Bipolar fuzzy relation equations based on product t-norm},
booktitle = {Proc. {FUZZ-IEEE}'17},
year = {2017},
organization = {2017 IEEE International Conference on Fuzzy Systems},
publisher = {IEEE Press},
}

@InProceedings{escim2017,
author = {M.E. Cornejo and D. Lobo and J. Medina},
title = {Bipolar fuzzy relation equations based on product t-norm},
booktitle = {Proceedings of the 9th European Symposium on Computational Intelligence and Mathematics. (ESCIM 2017)},
year = {2017}
}
 
 


@article{sanchez79,
title = "Inverses of fuzzy relations. Application to possibility distributions and medical diagnosis ",
journal = "Fuzzy Sets and Systems ",
volume = "2",
number = "1",
pages = "75 - 86",
year = "1979",
note= "",
issn = "0165-0114",
doi = "http://dx.doi.org/10.1016/0165-0114(79)90017-4",
url = "http://www.sciencedirect.com/science/article/pii/0165011479900174",
author = "E. Sanchez",
keywords = "Multi-valued fuzzy relations",
keywords = "Lower inverses",
keywords = "Upper inverses",
keywords = "Ponderated inverses",
keywords = "Inverse possibility distributions",
keywords = "Medical diagnosis assistance ",
abstract = "In this paper we define and explore the properties of lower and upper inverses of fuzzy relations which extend multi-valued mappings. With the notion of degree of inclusion of non-fuzzy sets, we then relate the preceding notions to possibility distributions in natural languages and to problems of medical diagnosis. "
}

@article{Zhou2016,
author="Zhou, Jian
and Yu, Ying
and Liu, Yuhan
and Zhang, Yuanyuan",
title="Solving nonlinear optimization problems with bipolar fuzzy relational equation constraints",
journal="Journal of Inequalities and Applications",
year="2016",
volume="2016",
number="1",
pages="126",
issn="1029-242X",
doi="10.1186/s13660-016-1056-6",
url="http://dx.doi.org/10.1186/s13660-016-1056-6"
}

@article{Klement2004,
title = "Triangular norms. Position paper I: basic analytical and algebraic properties",
journal = "Fuzzy Sets and Systems",
volume = "143",
number = "1",
pages = "5 - 26",
year = "2004",
note= "",
issn = "0165-0114",
doi = "http://dx.doi.org/10.1016/j.fss.2003.06.007",
url = "http://www.sciencedirect.com/science/article/pii/S0165011403004950",
author = "Erich Peter Klement and Radko Mesiar and Endre Pap",
keywords = "Triangular norms",
abstract = "We present the basic analytical and algebraic properties of triangular norms. We discuss continuity as well as the important classes of Archimedean, strict and nilpotent t-norms. Triangular conorms and De Morgan triples are also mentioned. Finally, a brief historical survey on triangular norms is given."
}


@article{Loia2005,
title = "Fuzzy relation equations for coding/decoding processes of images and videos ",
journal = "Information Sciences ",
volume = "171",
number = "1-3",
pages = "145 - 172",
year = "2005",
note= "",
issn = "0020-0255",
doi = "http://dx.doi.org/10.1016/j.ins.2004.04.003",
url = "//www.sciencedirect.com/science/article/pii/S0020025504001306",
author = "Vincenzo Loia and Salvatore Sessa",
abstract = "We adopt fuzzy relation equations with continuous triangular norms for compression/decompression processes of grey images, colour images in the \{RGB\} space and frames of videos, by comparing the results of the reconstructed images with standard methods like \{JPEG\} and MPEG-4. Any image is subdivided in blocks and each block is coded/decoded using arbitrary fuzzy sets as coders in the fuzzy equations. We evaluate the peak signal to noise ratio (PSNR) on the decompressed images for several values of the compression rates as measure of the quality of images and frames reconstructed. The original frames of a video are classified in Intra-frames and Predictive frames by using a similarity measure based on the well known Lukasiewicz t-norm. "
}


@article{Nobuhara2000, 
author={H. Nobuhara and W. Pedrycz and K. Hirota}, 
journal={IEEE Transactions on Fuzzy Systems}, 
title={Fast solving method of fuzzy relational equation and its application to lossy image compression/reconstruction}, 
year={2000}, 
volume={8}, 
number={3}, 
pages={325-334}, 
abstract={A fast solving method of the solution for max continuous t-norm composite fuzzy relational equation of the type G(i, j)=(RT?Ai)T?Bj , i=1, 2, ..., I, j=1, 2, ..., J, where Ai?F(X)X={x1, x2, ..., xM }, Bj?F(Y) Y={y1, y2, ..., yN}, R?F(X×Y), and ?: max continuous t-norm composition, is proposed. It decreases the computation time IJMN(L+T+P) to JM(I+N)(L+P), where L, T, and P denote the computation time of min, t-norm, and relative pseudocomplement operations, respectively, by simplifying the conventional reconstruction equation based on the properties of t-norm and relative pseudocomplement. The method is applied to a lossy image compression and reconstruction problem, where it is confirmed that the computation time of the reconstructed image is decreased to 1/335.6 the compression rate being 0.0351, and it achieves almost equivalent performance for the conventional lossy image compression methods based on discrete cosine transform and vector quantization}, 
keywords={data compression;fuzzy set theory;image reconstruction;vector quantisation;discrete cosine transform;fast solving method;fuzzy relational equation;image reconstruction;lossy image compression;t-norm composition;vector quantization;Discrete cosine transforms;Equations;Fuzzy sets;Gray-scale;Image coding;Image reconstruction;Inverse problems;Performance loss;Pixel;Vector quantization}, 
doi={10.1109/91.855920}, 
ISSN={1063-6706}, 
month={Jun},}

@article{Hirota1999, 
author={K. Hirota and W. Pedrycz}, 
journal={IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)}, 
title={Fuzzy relational compression}, 
year={1999}, 
volume={29}, 
number={3}, 
pages={407-415}, 
abstract={This study concentrates on fuzzy relational calculus regarded as a basis of data compression. In this setting, images are represented as fuzzy relations. We investigate fuzzy relational equations as a basis of image compression. It is shown that both compression and decompression (reconstruction) phases are closely linked with the way in which fuzzy relational equations are being usually set and solved. The theoretical findings encountered in the theory of these equations are easily accommodated as a backbone of the relational compression. The character of the solutions to the equations make them ideal for reconstruction purposes as they specify the extremal elements of the solution set and in such a way help establish some envelopes of the original images under compression. The flexibility of the conceptual and algorithmic framework arising there is also discussed. Numerical examples provide a suitable illustrative material emphasizing the main features of the compression mechanisms}, 
keywords={data compression;image coding;image reconstruction;relational algebra;data compression;fuzzy relational calculus;fuzzy relations;image compression;reconstruction;relational compression;Calculus;Data compression;Equations;Fuzzy sets;Image coding;Image processing;Image reconstruction;Solids;Spine;Vehicles}, 
doi={10.1109/3477.764876}, 
ISSN={1083-4419}, 
month={Jun},}


@article{Hirota2002,
title = "Data compression with fuzzy relational equations",
journal = "Fuzzy Sets and Systems",
volume = "126",
number = "3",
pages = "325 - 335",
year = "2002",
issn = "0165-0114",
doi = "https://doi.org/10.1016/S0165-0114(01)00009-4",
url = "http://www.sciencedirect.com/science/article/pii/S0165011401000094",
author = "Kaoru Hirota and Witold Pedrycz",
keywords = "Relational structures, Fuzzy relational equations, Data compression, Image processing, Information granularity",
abstract = "Abstract This study focuses on fuzzy relational calculus viewed as a basis of data compression. Images are fuzzy relations. We investigate fuzzy relational equations as a basis of image compression. It is shown that both compression and decompression (reconstruction) phases are closely linked with the way in which fuzzy relational equations are developed and solved. The theoretical findings encountered in the theory of these equations are easily accommodated as the backbone of the relational compression. The character of the solutions to the equations makes them ideal for reconstruction purposes as they specify the extremal elements of the solution set and in such a way help establish some envelopes of the original images under compression. The flexibility of the conceptual and algorithmic framework arising there is also discussed. Numerical examples provide a suitable illustrative material emphasizing the main features of the compression mechanisms."}


@inproceedings{Nobuhara2002, 
author={H. Nobuhara and W. Pedrycz and K. Hirota}, 
booktitle={Fuzzy Systems, 2002. {FUZZ-IEEE}'02. Proceedings of the 2002 IEEE International Conference on Fuzzy Systems.}, 
title={A digital watermarking algorithm using image compression method based on fuzzy relational equation}, 
year={2002}, 
volume={2}, 
pages={1568-1573}, 
abstract={A digital watermarking method using image compression based on a fuzzy relational equation (ICF) is proposed. The method is based on least significant bit modification. If the coding system of ICF is not designed appropriately, the fuzzy relational equation will be unsolvable due to the watermarking (modification of compressed image). In order to avoid this problem, a condition for appropriate coding system design is represented in terms of the solvability degree of the fuzzy relational equation. Image compression and reconstruction experiments using 100 images (extracted from Corel Gallery) are performed, and it is confirmed that the signed image is indistinguishable from the unsigned one}, 
keywords={copy protection;data compression;fuzzy set theory;image coding;image reconstruction;Corel Gallery;coding system solvability degree;digital watermarking algorithm;fuzzy relational equation;image compression method;image reconstruction;least significant bit modification;Color;Computational intelligence;Equations;Fuzzy systems;Image coding;Image reconstruction;Microcomputers;Pixel;Reconstruction algorithms;Watermarking}, 
doi={10.1109/FUZZ.2002.1006740}, 
month={},}

@article{Nobuhara2006,
title = "A motion compression/reconstruction method based on max t-norm composite fuzzy relational equations",
journal = "Information Sciences",
volume = "176",
number = "17",
pages = "2526 - 2552",
year = "2006",
issn = "0020-0255",
doi = "https://doi.org/10.1016/j.ins.2005.12.004",
url = "http://www.sciencedirect.com/science/article/pii/S0020025505003373",
author = "Hajime Nobuhara and Witold Pedrycz and Salvatore Sessa and Kaoru Hirota",
keywords = "Fuzzy relational equations, Motion compression, Fuzzy equalization",
abstract = "Abstract A motion compression/reconstruction method based on max t-norm composite fuzzy relational equations (MCF) is proposed, where into intra-pictures (I-pictures) and predictive-pictures (P-pictures) of the original motion are compressed by uniform and non-uniform coders, respectively. The non-uniform coders of the proposed method can preserve edge information of P-pictures on the compressed image. To perform an effective compression/reconstruction of the P-pictures, a design method of non-uniform coders is proposed based on an overlap level of fuzzy sets and a fuzzy equalization. An experiment using 10 P-pictures confirms that the root mean square error of the reconstructed images obtained by the proposed non-uniform coders is decreased to 89.4% of that one of the uniform coders under the condition that compression rate (the ratio between the file size of compressed image and original one) is 0.0057. Two test motions (â˜Tennisâ™ and â˜Womanâ™, 100 frames) are compressed and reconstructed by the proposed MCF."
}


@article{Li2008,
author="Li, Pingke
and Fang, Shu-Cherng",
title="On the resolution and optimization of a system of fuzzy relational equations with sup-T composition",
journal="Fuzzy Optimization and Decision Making",
year="2008",
volume="7",
number="2",
pages="169--214",
abstract="This paper provides a thorough investigation on the resolution of a finite system of fuzzy relational equations with sup-T composition, where T is a continuous triangular norm. When such a system is consistent, although we know that the solution set can be characterized by a maximum solution and finitely many minimal solutions, it is still a challenging task to find all minimal solutions in an efficient manner. Using the representation theorem of continuous triangular norms, we show that the systems of sup-T equations can be divided into two categories depending on the involved triangular norm. When the triangular norm is Archimedean, the minimal solutions correspond one-to-one to the irredundant coverings of a set covering problem. When it is non-Archimedean, they only correspond to a subset of constrained irredundant coverings of a set covering problem. We then show that the problem of minimizing a linear objective function subject to a system of sup-T equations can be reduced into a 0--1 integer programming problem in polynomial time. This work generalizes most, if not all, known results and provides a unified framework to deal with the problem of resolution and optimization of a system of sup-T equations. Further generalizations and related issues are also included for discussion.",
issn="1573-2908",
doi="10.1007/s10700-008-9029-y",
url="http://dx.doi.org/10.1007/s10700-008-9029-y"
}

@article{Li2009,
author="Li, Pingke
and Fang, Shu-Cherng",
title="Minimizing a linear fractional function subject to a system of sup-T equations with a continuous Archimedean triangular norm",
journal="Journal of Systems Science and Complexity",
year="2009",
month="Mar",
day="01",
volume="22",
number="1",
pages="49--62",
abstract="This paper shows that the problem of minimizing a linear fractional function subject to a system of sup-T equations with a continuous Archimedean triangular norm T can be reduced to a 0-1 linear fractional optimization problem in polynomial time. Consequently, parametrization techniques, e.g., Dinkelbach's algorithm, can be applied by solving a classical set covering problem in each iteration. Similar reduction can also be performed on the sup-T equation constrained optimization problems with an objective function being monotone in each variable separately. This method could be extended as well to the case in which the triangular norm is non-Archimedean.",
issn="1559-7067",
doi="10.1007/s11424-009-9146-x",
url="https://doi.org/10.1007/s11424-009-9146-x"
}


@article{Freson2013,
title = "Linear optimization with bipolar max-min constraints ",
journal = "Information Sciences ",
volume = "234",
number = "",
pages = "3 - 15",
year = "2013",
issn = "0020-0255",
doi = "http://dx.doi.org/10.1016/j.ins.2011.06.009",
url = "//www.sciencedirect.com/science/article/pii/S0020025511002830",
author = "S. Freson and B. {De Baets} and H. {De Meyer}",
keywords = "Bipolar constraints",
keywords = "Equality constraints",
keywords = "Fuzzy relational equations",
keywords = "Inequality constraints",
keywords = "Linear optimization",
keywords = "Max-??min composition ",
abstract = "We consider a generalization of the linear optimization problem with fuzzy relational (in)equality constraints by allowing for bipolar maxâ??min constraints, i.e. constraints in which not only the independent variables but also their negations occur. A necessary condition to have a non-empty feasible domain is given. The feasible domain, if not empty, is algebraically characterized. A simple procedure is described to generate all maximizers of the linear optimization problem considered and is applied to various illustrative example problems. "
}


@article{Li2016,
abstract = {This paper investigates bipolar max-min equations which can be viewed as a generalization of fuzzy relational equations with max-min composition. The relation between the consistency of bipolar max-min equations and the classical boolean satisfiability problem is revealed. Consequently, it is shown that the problem of determining whether a system of bipolar max-min equations is consistent or not is NP-complete. Moreover, a consistent system of bipolar max-min equations, as well as its solution set, can be fully characterized by a system of integer linear inequalities.},
author = {Li, Pingke and Jin, Qingwei},
journal = {Kybernetika},
keywords = {bipolar max-min equations; fuzzy relational equations; satisfiability; linear inequalities; bipolar max-min equations; fuzzy relational equations; satisfiability; linear inequalities},
language = {eng},
number = {4},
pages = {514-530},
publisher = {Institute of Information Theory and Automation AS CR},
title = {On the resolution of bipolar max-min equations},
url = {http://eudml.org/doc/286830},
volume = {52},
year = {2016},
}


%:%%%%%%%%%%%%   ALGORITHM FRelationEquations




@article{np:hardness:FRE,
year={2002},
issn={1432-7643},
journal={Soft Computing},
volume={6},
number={6},
doi={10.1007/s00500-001-0157-3},
title={Fuzzy relation equations (I): the general and specialized solving algorithms},
url={http://dx.doi.org/10.1007/s00500-001-0157-3},
publisher={Springer-Verlag},
keywords={??Fuzzy relation equation, Algorithm, Polynomial time problem, NP-hard problem},
author={Chen, L. and Wang, P. P.},
pages={428--435},
language={English}
}


@article{shivanian10,
year={2010},
journal={Mathware and Soft Computing},
volume={17},
title={An Algorithm for Finding Solutions of Fuzzy Relation Equations with max-Lukasiewicz Composition},
author={Shivanian, E.},
pages={15--26},
}




@ELECTRONIC{zahariev:2010,
author={Zahariev, Z.},
year = {2010},
title = {\texttt{http://www.mathworks.com/matlabcentral, fuzzy-calculus-core-fc2ore}},
}

 
@article{Peeva2013,
title = "Resolution of fuzzy relational equations: Method, algorithm and software with applications",
journal = "Information Sciences ",
volume = "234",
number = "0",
pages = "44--63",
year = "2013",
issn = "0020-0255",
doi = "10.1016/j.ins.2011.04.011",
url = "http://www.sciencedirect.com/science/article/pii/S0020025511001794",
author = "K. Peeva",
keywords = "Fuzzy relational equations",
keywords = "Inverse problem resolution ",
abstract = "Analytical methods and algorithms for inverse problem resolution of fuzzy linear systems of equations in some BL-algebras (GÃ¶del algebra in case of maxâ“min and minâ“max compositions, and Goguen algebra in case of maxâ“product composition) are presented. Algorithms with software realization for solving fuzzy linear systems of equations are proposed. Applications include fuzzy optimization with fuzzy linear systems of equation constraint, fuzzy machines and covering problem. "
}




%:%%%%%%%%%%%%   ALGORITHM FCA
@article{Demko2020,
title = {NextPriorityConcept: A new and generic algorithm computing concepts from complex and heterogeneous data},
journal = {Theoretical Computer Science},
volume = {845},
pages = {1-20},
year = {2020},
issn = {0304-3975},
doi = {https://doi.org/10.1016/j.tcs.2020.08.026},
url = {https://www.sciencedirect.com/science/article/pii/S0304397520304837},
author = {Christophe Demko and Karell Bertet and Cyril Faucher and Jean-François Viaud and Sergei O. Kuznetsov},
keywords = {Formal Concept Analysis, Lattice, Pattern structures, Strategies, Heterogeneous data},
abstract = {In this article, we present a new data type agnostic algorithm calculating a concept lattice from heterogeneous and complex data. Our NextPriorityConcept algorithm is first introduced and proved in the binary case as an extension of Bordat's algorithm with the notion of strategies to select only some predecessors of each concept, avoiding the generation of unreasonably large lattices. The algorithm is then extended to any type of data in a generic way. It is inspired by the pattern structure theory, where data are locally described by predicates independent of their types, allowing the management of heterogeneous data.}
}




@article{Shen2002,
title = "A rough-fuzzy approach for generating classification rules ",
journal = "Pattern Recognition ",
volume = "35",
number = "11",
pages = "2425 - 2438",
year = "2002",
note= "",
issn = "0031-3203",
doi = "http://dx.doi.org/10.1016/S0031-3203(01)00229-1",
url = "http://www.sciencedirect.com/science/article/pii/S0031320301002291",
author = "Qiang Shen and Alexios Chouchoulas",
keywords = "Pattern classification",
keywords = "Rough sets",
keywords = "Fuzzy sets",
keywords = "Feature selection",
keywords = "Rule induction ",
abstract = "The generation of effective feature pattern-based classification rules is essential to the development of any intelligent classifier which is readily comprehensible to the user. This paper presents an approach that integrates a potentially powerful fuzzy rule induction algorithm with a rough set-assisted feature reduction method. The integrated rule generation mechanism maintains the underlying semantics of the feature set. Through the proposed integration, the original rule induction algorithm (or any other similar technique that generates descriptive fuzzy rules), which is sensitive to the dimensionality of the dataset, becomes usable on classifying patterns composed of a moderately large number of features. The resulting learned ruleset becomes manageable and may outperform rules learned using more features. This, as demonstrated with successful realistic applications, makes the present approach effective in handling real world problems. "
}



@article{Ren2016, author = {Ren, Ruisi and Wei, Ling}, title = {The Attribute Reductions of Three-way Concept Lattices}, journal = {Knowledge-Based Systems}, issue_date = {May 2016}, volume = {99}, number = {C}, month = may, year = {2016}, issn = {0950-7051}, pages = {92--102}, numpages = {11}, url = {http://dx.doi.org/10.1016/j.knosys.2016.01.045}, doi = {10.1016/j.knosys.2016.01.045}, acmid = {2906290}, publisher = {Elsevier Science Publishers B. V.}, address = {Amsterdam, The Netherlands, The Netherlands}, keywords = {Attribute reduction, Attribute-induced three-way attribute concept, Discernibility attribute set, Irreducible element, Object-induced three-way object concept, Three-way concept},} 


@article{Shao2017,
title = "Attribute reduction in generalized one-sided formal contexts ",
journal = "Information Sciences ",
volume = "378",
number = "",
pages = "317--327",
year = "2017",
note= "",
issn = "0020-0255",
doi = "http://dx.doi.org/10.1016/j.ins.2016.03.018",
url = "http://www.sciencedirect.com/science/article/pii/S0020025516301657",
author = "Ming-Wen Shao and Ke-Wen Li",
keywords = "Attribute reduction",
keywords = "Concept lattice",
keywords = "Formal concept analysis",
keywords = "Galois connection ",
abstract = "Abstract In this paper, we present a new pair of adjoint mappings between a power set and the direct product of complete lattices. The proposed pair of adjoint mappings form a Galois connection and the corresponding concept lattice is constructed from a generalized one-sided formal context. We also propose a lattice-keep-based attribute reduction approach for generalized one-sided formal contexts. Specifically, we present concrete judgment theorems and an algorithm to calculate the attribute reducts in generalized one-sided formal contexts. Furthermore, according to the importance of attributes, we discuss attributive characteristics for the proposed generalized one-sided concept lattice. "
}

@article{Shao2015,
title = "Knowledge reduction in formal fuzzy contexts ",
journal = "Knowledge-Based Systems ",
volume = "73",
number = "",
pages = "265 - 275",
year = "2015",
note= "",
issn = "0950-7051",
doi = "http://dx.doi.org/10.1016/j.knosys.2014.10.008",
url = "http://www.sciencedirect.com/science/article/pii/S095070511400375X",
author = "Ming-Wen Shao and Hong-Zhi Yang and Wei-Zhi Wu",
keywords = "Concept lattices",
keywords = "Discernibility matrices",
keywords = "Formal fuzzy contexts",
keywords = "Knowledge reduction",
keywords = "Variable threshold ",
abstract = "Abstract Knowledge reduction is a basic issue in knowledge representation and data mining. Although various methods have been developed to reduce the size of classical formal contexts, the reduction of formal fuzzy contexts based on fuzzy lattices remains a difficult problem owing to its complicated derivation operators. To address this problem, we propose a general method of knowledge reduction by reducing attributes and objects in formal fuzzy contexts based on the variable threshold concept lattices. Employing the proposed approaches, we remove attributes and objects which are non-essential to the structure of a variable threshold concept lattice, i.e., with a given threshold level, the concept lattice constructed from a reduced formal context is made identical to that constructed from the original formal context. Discernibility matrices and Boolean functions are, respectively, employed to compute the attribute reducts and object reducts of the formal fuzzy contexts, by which all the attribute reducts and object reducts of the formal fuzzy contexts are determined without changing the structure of the lattice. "
}
 
@article{Du2016,
title = "Attribute reduction in ordered decision tables via evidence theory ",
journal = "Information Sciences ",
volume = "364-365",
number = "",
pages = "91 - 110",
year = "2016",
note= "",
issn = "0020-0255",
doi = "http://dx.doi.org/10.1016/j.ins.2016.05.011",
url = "//www.sciencedirect.com/science/article/pii/S0020025516303358",
author = "Wen Sheng Du and Bao Qing Hu",
keywords = "Ordered decision table",
keywords = "Attribute reduction",
keywords = "Dominance-based rough set approach",
keywords = "Evidence theory ",
abstract = "Abstract Rough set theory and Dempsterâ??Shafer theory of evidence are two distinct but closely related approaches to modeling and manipulating uncertain information. It is quite natural to set up a hybrid model based on these two theories. In this paper, we investigate the problem of attribute reduction for ordered decision tables based on evidence theory. Belief and plausibility functions, which are strongly connected with lower and upper approximation operators in dominance-based rough set approach, are proposed to define relative belief and plausibility reducts of ordered decision tables. Relationships among various types of relative reducts are thoroughly studied in consistent and inconsistent ordered decision tables. A pair of numeric measures, the inner and outer significance measures of a criterion, is presented to search for a relative belief/plausibility reduct, which is meaningful for practical problems. Some real-world tasks taken from the \{UCI\} repository are employed to verify the feasibility and effectiveness of the proposed technique. "
}

 @article{DeMaio2012,
title = "Hierarchical web resources retrieval by exploiting Fuzzy Formal Concept Analysis",
journal = "Information Processing \& Management",
volume = "48",
number = "3",
pages = "399--418",
year = "2012",
note= "",
issn = "0306-4573",
doi = "http://dx.doi.org/10.1016/j.ipm.2011.04.003",
url = "http://www.sciencedirect.com/science/article/pii/S0306457311000458",
author = "Carmen De Maio and Giuseppe Fenza and Vincenzo Loia and Sabrina Senatore",
}

@inproceedings{eusflat14:dgmr,
	Author = {J.C. Díaz and B. García and J. Medina and  R. Rodríguez},
	Title = {Building multi-adjoint  concept lattices},
	 Booktitle = {Intl Conference on Fuzzy Logic and Technology (EUSFLAT 2013)},
	Pages = {340--346},
	Year = {2013}}


@Webpage{fuzzypy1,
url = {http://mavrinac.com/index.cgi?page=fuzzpy},
author = {Fuzzypy},
title = {},
year = 2012,
lastchecked = {January 2012}
}
 
@url{fuzzypy,
	Title = {Fuzzypy},
	Urldate = {http://mavrinac.com/index.cgi?page=fuzzpy}}

@article{fuzzypy2,
	Author =  {Fuzzypy},
	Journal = {},
	Pages = {},
	Title = {},
	Volume = {},
	Year = {}
	}

%:%%%%%%%%%%%%  GENERAL DE CONCEPT LATTICES 



@Article{Hu2019,
  author    = {Hu, J. and Chen, D. and Liang, P.},
title = {A Novel Interval Three-Way Concept Lattice Model with Its Application in Medical Diagnosis},
journal = {Mathematics},
year = {2019},
volume = {7},
paper = {103},
pages = {103},
}


@Article{Valverde2020,
  author    = {Valverde-Albacete, F.J. and Peláez-Moreno, C},
title = {The Singular Value Decomposition over Completed Idempotent Semifields},
journal = {Mathematics},
year = {2020},
volume = {8},
paper = {1577},
pages = {1577},
}



@article{Alcalde2020Red,
author = {Cristina Alcalde and Ana Burusco},
title = {Reduction of the size of {L}-fuzzy contexts. {A} tool for differential diagnoses of diseases},
journal = {International Journal of General Systems},
volume = {48},
number = {7},
pages = {692-712},
year  = {2019},
publisher = {Taylor & Francis},
doi = {10.1080/03081079.2019.1620740},

URL = { 
        https://doi.org/10.1080/03081079.2019.1620740
    
},
peprint = { 
        https://doi.org/10.1080/03081079.2019.1620740
    
}
,
    abstract = { ABSTRACTInformation extraction from an L-fuzzy context becomes a hard problem when we work with a large set of objects and/or attributes. The goal of this paper is to present two different and complementary techniques to reduce the size of the context. First, using overlap indexes, we will establish rankings among the elements of the context that will allow us to determine those that do not provide relevant information and eliminate them. Second, by means of Choquet integrals, we will aggregate some objects or attributes of the context in order to jointly use the provided information. One interesting application of the developed theory consists on helping in the differential diagnoses of diseases that share a large number of symptoms and, therefore, that are difficult of distinguish. }
}



@article{Alcalde2020,
  author    = {Cristina Alcalde and
               Ana Burusco},
	Journal = {Soft Computing},
	Pages = {3413--3423},
	Title = {Use of Choquet integrals in multivalued contexts},
	Volume = {24},
	Year = {2020},
	doi = {10.1007/s00500-019-04104-1},
	}


@inproceedings{AlcaldeIPMU12,
  author    = {Cristina Alcalde and
               Ana Burusco and
               Ram{\'o}n Fuentes-Gonz{\'a}lez},
  title     = {Some Results on the Composition of {L}-Fuzzy Contexts},
  booktitle = {IPMU (2)},
  year      = {2012},
  pages     = {305-314},
  ee        = {http://dx.doi.org/10.1007/978-3-642-31715-6_33},
  crossref  = {DBLP:conf/ipmu/2012-2},
  bibsource = {DBLP, http://dblp.uni-trier.de}
}

@proceedings{DBLP:conf/ipmu/2012-2,
  editor    = {Salvatore Greco and
               Bernadette Bouchon-Meunier and
               Giulianella Coletti and
               Mario Fedrizzi and
               Benedetto Matarazzo and
               Ronald R. Yager},
  title     = {Advances on Computational Intelligence - 14th International
               Conference on Information Processing and Management of Uncertainty
               in Knowledge-Based Systems, IPMU 2012, Catania, Italy, July
               9-13, 2012. Proceedings, Part II},
  booktitle = {IPMU (2)},
  publisher = {Springer},
  series    = {Communications in Computer and Information Science},
  volume    = {298},
  year      = {2012},
  isbn      = {978-3-642-31714-9},
  ee        = {http://dx.doi.org/10.1007/978-3-642-31715-6},
  bibsource = {DBLP, http://dblp.uni-trier.de}
}


@article{belohlavek10,
	Author =  {R. B{\v e}lohl{\'a}vek and B. {De Baets} and J. Outrata  and V. Vychodil},
	Journal = {IEEE Transactions on Fuzzy Systems},
	Pages = {546--557},
	Title = {Computing the Lattice of All Fixpoints  of a Fuzzy Closure Operator},
	Volume = {18},
	Number={3},
	Year = {2010}}
	
@article{belohlavek07,
	Author =  {R. B{\v e}lohl{\'a}vek and B. {De Baets} and J. Outrata  and V. Vychodil},
	Journal = {Lecture Notes in Computer Science},
	Pages = {156--167},
	Title = {Lindig's Algorithm for Concept Lattices over Graded Attributes},
	Volume = {4617},
	Year = {2007}}


@inproceedings{belohlavek_isotone,
	Author = {E. Bartl and  R. B{\v e}lohl{\'a}vek and  J. Konecny and V. Vychodil},
	 Booktitle = {4th International IEEE Conference ``Intelligent Systems''},
	Pages = {15.24--15.28},
	Title = {Isotone {G}alois connections and concept lattices
with hedges},
	Year = {2008}}

@article{belohlavek_isotoneINS,
  author    = {Radim B{\v e}lohl{\'a}vek and
               Jan Konecny},
  title     = {Concept lattices of isotone vs. antitone {G}alois connections
               in graded setting: Mutual reducibility revisited},
  journal   = {Information Sciences},
  volume    = {199},
  year      = {2012},
  pages     = {133-137},
  ee        = {http://dx.doi.org/10.1016/j.ins.2012.02.064},
 }


@article{Belohlavek99,
  author    = {Radim B{\v e}lohl{\'a}vek},
  title     = {Fuzzy {G}alois Connections},
  journal   = {Mathematical Logic Quarterly},
  volume    = {45},
  year      = {1999},
  pages     = {497-504},
}


@article{diday03,
  author    = {Edwin Diday and  Richard Emilion},
  title     = {Maximal and Stochastic {G}alois Lattices},
  journal   = {Discrete Applied Mathematics},
  volume    = {127},
  Number={2},
  year      = {2003},
  pages     = {271--284},
}


@article{kuznetsov02,
	Author = {S.O. Kuznetsov and S.A.Obiedkov},
	Journal = {J. Exp. Theor. Artif. Intelligence},
	Pages = {189--216},
	Title = {Comparing performance of algorithms for generating concept lattices},
	Volume = {14},
	Number={2/3},
	Year = {2002}}


@inproceedings{lindig2000,
	Author = {Lindig, C.},
	Editor = {Stumme, G.},	
	 Booktitle = {Working with Conceptual Structures-Contributions to ICCS 2000},
	Pages = {152--161},
	Title = {Fast concept analysis},
	Year = {2000}}


@article{buruscoFSSEx,
	Author = {A. Burusco and R. Fuentes-Gonz\'alez},
	Journal = {Fuzzy Sets and Systems},
	Pages = {431--436},
	Title = {Concept lattices defined from implication operators},
	Volume = {114},
	Year = {2000}}



@book{nla.cat-vn2805576,
	Author = {H.~v. Hentig},
	Publisher = {E. Klett Stuttgart},
	Title = {Magier eder Magister? uber die Einheit der Wissenschaft im
  Verstandigungsprozess},
	Year = {1972}} 


@book{DaveyPriestley,
	Author = {B.A. Davey and H.A. Priestley},
	Edition = {Second},
	Publisher = {Cambridge University Press},
	Title = {Introduction to lattices and order},
	Year = {2002}}

@book{GanterW,
	Author = {B. Ganter and R. Wille},
	Publisher = {Springer Verlag},
	Title = {Formal concept analysis: Mathematical foundation},
	Year = {1999}}

@book{Ganter:2005,
	Editor = {Ganter, Bernhard and Stumme, Gerd and Wille, Rudolf},
	Publisher = {Springer Verlag},
	Series = {Lecture Notes in Computer Science},
	Title = {Formal Concept Analysis: Foundations and Applications},
	Year = {2005}}

 @incollection{wille:dyadic,
year={2004},
booktitle={Galois   Connections and Applications},
volume={565},
series={Lecture Notes in Computer Science},
editor={K. Denecke and M. Erné and S. Wismath},
title={Dyadic mathematics an abstractions from logical thought},
publisher={Springer Berlin Heidelberg},
author={R. Wille},
pages={453--498},
language={English}
}

 @incollection{wille:FCAMT,
year={2005},
booktitle={Formal Concept Analysis},
volume={3626},
series={Lecture Notes in Computer Science},
editor={B. Ganter and G. Stumme  and R. Wille},
title={Formal concept analysis as mathematical theory of concepts and
  concept hierarchies},
publisher={Springer Berlin Heidelberg},
author={R. Wille},
pages={1--33},
language={English}
}





@article{georgescu02,
	Author = {G. Georgescu and A. Popescu},
	Journal = {Fundamenta Informaticae},
	Number = {1},
	Pages = {23--54},
	Title = {Concept lattices and similarity in non-commutative fuzzy logic},
	Volume = {53},
	Year = {2002}}

@article{georgescu:2003,
	Author = {G. Georgescu and A. Popescu},
	Journal = {Soft Computing},
	Number = {7},
	Pages = {458--467},
	Title = {Non-commutative fuzzy {G}alois connections},
	Volume = {7},
	Year = {2003},
 Url = {http://www.springerlink.com/openurl.asp?genre=article&issn=1432-7643&volume=7&issue=7&spage=458},
	Abstract = {Fuzzy Galois connections were introduced by B&ecaron;lohl{\'a}vek in [4]. The structure considered there for the set of truth values is a complete residuated lattice, which places the discussion in a ``commutative fuzzy world''. What we are doing in this paper is dropping down the commutativity, getting the corresponding notion of Galois connection and generalizing some results obtained by B&ecaron;lohl{\'a}vek in [4] and [7]. The lack of the commutative law in the structure of truth values makes it appropriate for dealing with a sentences conjunction where the order between the terms of the conjunction counts, gaining thus a temporal dimension for the statements. In this ``non-commutative world'', we have not one, but two implications ([15]). As a consequence, a Galois connection will not be a pair, but a quadruple of functions, which is in fact two pairs of functions, each function being in a symmetric situation to his pair. Stating that these two pairs are compatible in some sense, we get the notion of strong L-Galois connection, a more operative and prolific notion, repairing the ``damage'' done by non-commutativity.
},
}
 
@book{gratzer,
	Author = {G. Gr{\"a}tzer},
	Publisher = {Birkh\" auser Verlag},
	Title = {General Lattice Theory},
	Year = {1998}}




@article{Stano:GCL,
	Author = {S. Kraj{\v c}i},
	Journal = {Logic Journal of IGPL},
	Number = {5},
	Pages = {543--550},
	Title = {A generalized concept lattice},
	Volume = {13},
	Year = {2005}}

@inproceedings{StanoGCL:CLA,
	Author = {S. Kraj{\v c}i},
	Booktitle = {ERCIM workshop on soft computing},
	Title = {A generalized concept lattice},
	Year = {2004}}

@inproceedings{Stano:BThGCL,
	Author = {S. Kraj{\v c}i},
	Booktitle = {International Workshop on Concept Lattices and their Applications, CLA 2004},
	Editor = {V. Sn\'asel and R. B{\v e}lohl\'avek},
	Pages = {25--33},
	Title = {The basic theorem on generalized concept lattice},
	Year = {2004}}


@article{Antoni2018,
title = "On stability of fuzzy formal concepts over randomized one-sided formal context",
journal = "Fuzzy Sets and Systems",
volume = "333",
pages = "36 - 53",
year = "2018",
issn = "0165-0114",
doi = "https://doi.org/10.1016/j.fss.2017.04.006",
url = "http://www.sciencedirect.com/science/article/pii/S0165011417301598",
author = "Lubomir Antoni and Stanislav Kraj{\v c}i and Ondrej Kr\'idlo",
keywords = "Stability, Fuzzy formal concept, Randomized formal context, Normal distribution",
abstract = "We propose a probabilistic approach to the issue of one-sided fuzzy formal concepts stability. The modified Riceâ“Siff algorithm represents a crisp index how to select the relevant concepts from the set of all one-sided fuzzy formal concepts. We suggest to explore the formal concepts stability affected by the random fluctuation of values in a formal context. We describe the algorithm and study the properties of the concept stability using random variables with the Gaussian normal distribution. In combination with the modified Riceâ“Siff algorithm, the Gaussian probabilistic index improves the analysis of the most relevant one-sided formal concepts from the original one-sided formal context. The connections to recent works in the related directions are presented."
}

@article{Antoni2016,
title = "Constraint heterogeneous concept lattices and concept lattices with heterogeneous hedges ",
journal = "Fuzzy Sets and Systems ",
volume = "303",
number = "",
pages = "21 - 37",
year = "2016",
issn = "0165-0114",
doi = "http://dx.doi.org/10.1016/j.fss.2015.12.007",
url = "http://www.sciencedirect.com/science/article/pii/S0165011415005874",
author = "Lubomir Antoni and Stanislav Kraj{\v c}i and Ondrej Kr\'idlo",
keywords = "Formal concept analysis",
keywords = "Algebra",
keywords = "Heterogeneous concepts",
keywords = "Hedges ",
abstract = "Abstract The paper deals with the isomorphism between the constraint heterogeneous concept lattices and concept lattices with heterogeneous hedges. The essential point of the former approach encompasses the full diversification of data structures within a formal context. In particular, we use a different complete lattice for diverse objects, a different complete lattice for diverse attributes and a different poset for diverse matrix fields. The latter framework with heterogeneous hedges results in a reduction in the size of the corresponding concept lattice. We present the properties of constraint heterogeneous approach that is associated with the fixpoints of hedges and we add remarks to the related studies. "
}




@article{krajci2013,
  author    = {L'ubom{\'{\i}}r Antoni and
               Stanislav Kraj{\v c}i and
               Ondrej Kridlo and
               Bohuslav Macek and
               Lenka Piskov{\'{a}}},
  title     = {On heterogeneous formal contexts},
  journal   = {Fuzzy Sets and Systems},
  volume    = {234},
  pages     = {22--33},
  year      = {2014},
  url       = {http://dx.doi.org/10.1016/j.fss.2013.04.008},
  doi       = {10.1016/j.fss.2013.04.008},
  timestamp = {Thu, 21 Nov 2013 14:11:40 +0100},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/fss/AntoniKKMP14},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}




@inproceedings{ipmu06CL,
	Author = {J. Medina and J. Ruiz-Calvi{\~{n}}o},
	Booktitle = {Information Processing and Management of Uncertainty for Knowledge-Based Systems, IPMU'06},
	Pages = {2566--2571},
	Title = {Towards Multi-Adjoint Concept Lattices},
	Year = {2006}}


@inproceedings{mor-estylf06,
	Author = {J. Medina and M. Ojeda-Aciego and J. Ruiz-Calvi{\~{n}}o},
	Booktitle = {XIII Congreso Español sobre Tecnologías y Lógica
Fuzzy, ESTYLF 2006},
	Pages = {147--152},
	Title = {Multi-adjoint concept lattices from a
non-commutative perspective},
	Year = {2006}}


@article{icfca-mor,
	Author = {J. Medina and M. Ojeda-Aciego and J. Ruiz-Calvi{\~{n}}o},
	Journal = {Lecture Notes in Artificial Intelligence},
	Pages = {197--209},
	Title = {On multi-adjoint concept lattices: definition and representation theorem},
	Volume = {4390},
	Year = {2007}}
	
@inproceedings{mor-eusflat07,
	Author = {J. Medina and M. Ojeda-Aciego and J. Ruiz-Calvi{\~{n}}o},
	Booktitle = {Intl Conference on Fuzzy Logic and Technology, EUSFLAT 2007},
	Pages = {209--212},
	Title = {Concept lattices under non-commutative conjunctors
are generalized concept lattices},
	Year = {2007}}



@article{mor-fss-cmpi,
	Author = {J. Medina and M. Ojeda-Aciego and J. Ruiz-Calvi{\~{n}}o},
	Date-Modified = {2009-01-20 16:15:50 +0100},
	Journal = {Fuzzy Sets and Systems},
	Number = 2,
	Pages = {130--144},
	Title = {Formal concept analysis via multi-adjoint concept lattices},
	Volume = 160,
	Year = 2009,
	Bdsk-Url-1 = {http://dx.doi.org/10.1016/j.fss.2008.05.004}}


	
@article{mor-aml,
	Author = {Medina, J. and Ojeda-Aciego, M. and Ruiz-Calvi{\~{n}}o, J.},
	Date-Modified = {2009-01-20 16:15:50 +0100},
	Journal = {Applied Mathematics Letters},
	Number = 12,
	Pages = {1296--1300},
	Title = {Relating generalized concept lattices with concept lattices for non-commutative conjunctors},
	Volume = 21,
	Year = 2008,
	Bdsk-Url-1 = {http://dx.doi.org/10.1016/j.aml.2007.12.026}}




@article{mo-ins,
	Author = {Medina, J. and Ojeda-Aciego, M.},
	Journal = {Information Sciences},
	Pages = {712--725},
	Title = {Multi-adjoint t-concept lattices},
	Volume = 180,
	Number = 5,
	Year = 2010,
}

 @article{iwann09-medina,
	Author = {Medina, J.},
	Journal = {Lecture Notes in Computer Science},
	Pages = {279--286},
	Title = {Overcoming non-commutativity in multi-adjoint concept lattices},
	Volume = 5517,
	Year = 2009,
}
 
 @article{fss-hetero,
	Author = {J.~Medina and M.~Ojeda-Aciego},
	Journal = {Fuzzy Sets and Systems},
	Pages = {95-110},
	Title = {On multi-adjoint concept lattices based on heterogeneous conjunctors},
	Volume = {208},
	Year = 2012,
	Url = {http://dx.doi.org/10.1016/j.fss.2012.02.008},
}


@article{medina:amai14,
year={2014},
issn={1012-2443},
journal={Annals of Mathematics and Artificial Intelligence},
doi={10.1007/s10472-014-9405-y},
title={Multi-adjoint concept lattices with heterogeneous conjunctors and hedges},
url={http://dx.doi.org/10.1007/s10472-014-9405-y},
publisher={Springer International Publishing},
keywords={Galois connection; Residuated algebra; Formal concept analysis; Multi-adjoint concept lattices; 03G10; 08A72},
author={Konecny, J. and Medina, J. and Ojeda-Aciego, M.},
Volume = {72},
pages={73-89},
language={English}
}


 
	
	
@inproceedings{heterog:cla2012,
	author = {Jan Konecny and J. Medina and   M. Ojeda-Aciego},
 	Title = {Intensifying hedges and  the size of multi-adjoint concept lattices with heterogeneous conjunctors},
         Booktitle     = {The 9th International Conference on Concept Lattices and Their Applications},
        year      = {2012},
        pages = {245--256},
	}


@book{pollandt97,
	Address = {Berlin},
	Author = {S. Pollandt},
	Publisher = {Springer},
	Title = {Fuzzy Begriffe},
	Year = {1997}}

@phdthesis{umbreit,
	Author = {S. Umbreit},
	School = {Halle, Saale},
	Title = {Formale Begriffsanalyse mit unscharfen Begriffen},
	Year = {1995}}

@techreport{iberamia06,
	Address = {http://www.satd.uma.es/matap/jmedina/MACL.zip},
	Author = {J. Medina and M. Ojeda-Aciego and J. Ruiz-Calvi{\~{n}}o},
	Institution = {University of M\'alaga},
	Title = {On multi-adjoint concept lattices: definition and representation theorem},
	Year = {2006}}
	
	
	
	
	
%:%%%%%%% DE MANOLO

@article{KridloKO12,
  author    = {Ondrej Kridlo and
               Stanislav Kraj{\v c}i and
               Manuel Ojeda-Aciego},
  title     = {The Category of {L}-{C}hu Correspondences and the Structure
               of {L}-Bonds},
  journal   = {Fundamenta Informaticae},
  volume    = {115},
  number    = {4},
  year      = {2012},
  pages     = {297-325},
  ee        = {http://dx.doi.org/10.3233/FI-2012-657},
  bibsource = {DBLP, http://dblp.uni-trier.de}
}



	

@article{beloh-note,
	Author = {B{\v e}lohl{\'a}vek, R.},
	Date-Added = {2008-12-30 09:26:41 +0100},
	Date-Modified = {2008-12-30 09:28:35 +0100},
	Journal = {Information Sciences},
	Keywords = {Concept lattice; Galois connection; Fuzzy logic; Formal concept analysis},
	Number = {15},
	Pages = {3186-3191},
	Title = {A note on variable threshold concept lattices: Threshold-based operators are reducible to classical concept-forming operators},
	Volume = {177},
	Year = {2007},
	Abstract = {The present paper deals with formal concept analysis of data with fuzzy attributes. We clarify several points of a new approach of [S.Q. Fan, W.X. Zhang, Variable threshold concept lattice, Inf. Sci., accepted for publication] which is based on using thresholds in concept-forming operators. We show that the extent- and intent-forming operators from [S.Q. Fan, W.X. Zhang, Inf. Sci., accepted for publication] can be defined in terms of basic fuzzy set operations and the original operators as introduced and studied e.g. in [R. Belohlavek, Fuzzy Galois connections, Math. Logic Quarterly 45 (4) (1999) 497--504; R. Belohlavek, Concept lattices and order in fuzzy logic, Ann. Pure Appl. Logic 128 (2004) 277--298; S. Pollandt, Fuzzy Begriffe, Springer-Verlag, Berlin/Heidelberg, 1997]. As a consequence, main properties of the new operators from [S.Q. Fan, W.X. Zhang, Inf. Sci., accepted for publication], including the properties studied in [S.Q. Fan, W.X. Zhang, Inf. Sci., accepted for publication], can be obtained as consequences of the original operators from [R. Belohlavek, 1999; R. Belohlavek, 2004; S. Pollandt, 1997].},
	Bdsk-Url-1 = {http://dx.doi.org/10.1016/j.ins.2007.02.024}}

@article{zhang:2007,
	Author = {Zhang, Wen-Xiu and Ma, Jian-Min and Fan, Shi-Qing},
	Date-Added = {2008-12-30 09:24:21 +0100},
	Date-Modified = {2008-12-30 09:55:17 +0100},
	Journal = {Information Sciences},
	Keywords = {Formal concept analysis; Fuzzy concept lattice; Fuzzy logic; Galois connection; Variable threshold concept lattice},
	Number = {22},
	Pages = {4883-4892},
	Title = {Variable threshold concept lattices},
	Volume = {177},
	Year = {2007},
	Abstract = {In this paper, the definition of a variable threshold concept lattice is introduced. Based on a Galois connection, three kinds of variable threshold concept lattices, in which diverse requirements of knowledge discovery can be satisfied by adjusting a threshold, are defined. The number of formal concepts in a variable threshold concept lattice is far less than that in a fuzzy concept lattice. The three kinds of variable threshold concept lattices are constructed between two crisp sets, between a crisp set and a fuzzy set, and between a fuzzy set and a crisp set. Their properties are analogous to that of the classical concept lattices, and can be induced by the fuzzy concept lattice.},
	Bdsk-Url-1 = {http://dx.doi.org/10.1016/j.ins.2007.05.031}}

@article{alcalde:2009,
	Author = {Alcalde, C. and Burusco, A. and Fuentes-Gonz{\'a}lez, R. and Zubia, I.},
	Date-Added = {2008-12-29 11:03:34 +0100},
	Date-Modified = {2008-12-29 11:05:36 +0100},
	Journal = {Information Sciences},
	Keywords = {Implications between attributes; L-Fuzzy context; L-Fuzzy concept; Association rules},
	Pages = {1-15},
	Title = {Treatment of {L}-Fuzzy contexts with absent values},
	Volume = {179},
	Year = {2009},
	Abstract = {This work shows how to extract the missing information from an interval-valued L-Fuzzy context with some unknown values.
Absent values are replaced using implications between attributes with high levels of support and confidence. Three kinds of implications are defined and analyzed for this purpose.
We apply these results to an electrical network simulation, where the estimated relations between faulty power lines and voltage measurements can be compared with their real values.},
	Bdsk-Url-1 = {http://dx.doi.org/10.1016/j.ins.2008.09.005}}

@article{buruscoFRE12,
  author    = {Cristina Alcalde and
               Ana Burusco and
               Ram{\'o}n Fuentes-Gonz{\'a}lez},
  title     = {Analysis of certain {L}-Fuzzy Relational equations and the
               Study of its solutions by Means of the {L}-Fuzzy Concept Theory},
  journal   = {International Journal of Uncertainty, Fuzziness and Knowledge-Based
               Systems},
  volume    = {20},
  number    = {1},
  year      = {2012},
  pages     = {21-40},
  ee        = {http://dx.doi.org/10.1142/S021848851250002X},
  bibsource = {DBLP, http://dblp.uni-trier.de}
}


@article{Alcalde20151,
title = "The use of two relations in {L}-fuzzy contexts ",
journal = "Information Sciences ",
volume = "301",
number = "",
pages = "1 - 12",
year = "2015",
note= "",
issn = "0020-0255",
doi = "http://dx.doi.org/10.1016/j.ins.2014.12.057",
url = "http://www.sciencedirect.com/science/article/pii/S0020025515000092",
author = "C. Alcalde and A. Burusco and R. Fuentes-González",
keywords = "Formal concept analysis",
keywords = "L-fuzzy concept analysis",
keywords = "Knowledge acquisition ",
abstract = "Abstract In the analysis of relations among the elements of two sets it is usual to obtain different values depending on the point of view from which these relations are measured. The main goal of the paper is the modelization of these situations by means of a generalization of the L-fuzzy concept analysis called L-fuzzy bicontext. We study the L-fuzzy concepts of these L-fuzzy bicontexts obtaining some interesting results. Specifically, we will be able to classify the biconcepts of the L-fuzzy bicontext. Finally, a practical case is developed using this new tool. "
}




@article{qu:2008,
	Author = {Qu, Kai-She and Zhai, Yan-Hui},
	Date-Added = {2008-12-29 10:52:21 +0100},
	Date-Modified = {2008-12-29 10:53:49 +0100},
	Journal = {Knowledge-Based Systems},
	Keywords = {Formal context; Formal concept analysis; Implication; Non-redundant set; Minimal generator},
	Pages = {429-433},
	Title = {Generating complete set of implications for formal contexts},
	Volume = {21},
	Year = {2008},
	Abstract = {In this paper, a necessary and sufficient condition on which a set of implications is complete is proposed with the help of the notion of model from logic. Besides, using the closure of an attribute subset to a set of implications, we present a formal method to remove the redundant implications from a complete set. Subsequently, we provide an algorithm to generate a complete set of implications and an illustrative example guarantees the availability of the algorithm.
},
	Bdsk-Url-1 = {http://dx.doi.org/10.1016/j.knosys.2008.03.001}}

@article{kuznetsov:2004,
	Author = {Kuznetsov, Sergei O.},
	Date-Added = {2008-12-29 10:50:30 +0100},
	Date-Modified = {2008-12-29 12:05:04 +0100},
	Journal = {Discrete Applied Mathematics},
	Keywords = {Concept lattice; Learning; Algorithmic complexity},
	Pages = {111-125},
	Title = {Complexity of learning in concept lattices from positive and negative examples},
	Volume = {142},
	Year = {2004},
	Abstract = {A model of learning from positive and negative examples in concept lattices is considered. Lattice- and graph-theoretic interpretations of learning concept-based classification rules (called hypotheses) and classification in this model are given. The problems of counting all formal concepts, all hypotheses, and all minimal hypotheses are shown to be #P-complete. NP-completeness of some decision problems related to learning and classification in this setting is demonstrated and several conditions of tractability of these problems are considered. Some useful particular cases where these problems can be solved in polynomial time are indicated.
},
	Bdsk-Url-1 = {http://dx.doi.org/10.1016/j.dam.2003.11.002}}

@article{wu:2009,
	Author = {Wu, Qiang and Liu, Zongtian},
	Date-Added = {2008-12-29 10:48:16 +0100},
	Date-Modified = {2008-12-29 10:50:03 +0100},
	Journal = {Knowledge-Based Systems},
	Keywords = {Grey information sysytem; Grey-rough set; Formal concept analysis; Galois lattices construction},
	Number = {1},
	Pages = {38-45},
	Title = {Real formal concept analysis based on grey-rough set theory},
	Volume = {22},
	Year = {2009},
	Abstract = {One of the main concepts in grey system theory is how systems should be controlled under incomplete or lack of information situation. Grey number denoting an uncertain value is described in real interval from this concept. In this paper, we introduce the real formal concept analysis based on grey-rough set theory by using grey numbers, instead of binary values. We propose, to extend the notion of Galois connection in a real binary relation as well as the notions of formal concept and Galois lattice. The relationships between the new notions and old ones are discussed. Finally, we present a grey-rough set approach to Galois lattices reduction.
},
	Bdsk-Url-1 = {http://dx.doi.org/10.1016/j.knosys.2008.06.001}}

@article{luong:2008,
	Author = {Phan-Luong, V.},
	Date-Added = {2008-12-29 10:46:00 +0100},
	Date-Modified = {2008-12-29 10:47:33 +0100},
	Journal = {Information Fusion},
	Keywords = {Information fusion; Lattice structure; Information conflict; Information complement; Consensus; Aggregation},
	Pages = {278-292},
	Title = {A framework for integrating information sources under lattice structure},
	Volume = {9},
	Year = {2008},
	Abstract = {Different observations over one and the same natural phenomenon often lead to different collections of information elements describing that phenomenon. Such collections of information elements, which we call information sources, can be heterogeneous, redundant, complementary, or even contradictory. In general, the information elements describing the phenomenon can be unified and related in a hierarchical structure, using existing methods for data integration and ontology merging. In this paper, we consider the problem of redundancy, complementarity, and consistency of information sources, under the assumption that the information elements of each source are related in a lattice structure. We propose various methods for integrating information sources and establish relationships between these methods. Applications of the framework are illustrated through examples in the areas of geographic information and battlefield target identification.
},
	Bdsk-Url-1 = {http://dx.doi.org/10.1016/j.inffus.2007.01.002}}

@article{liu:2007,
	Author = {Liu, Xiaodong and Wang, Wei and Chai, Tianyou and Liu, Wanquan},
	Date-Added = {2008-12-29 10:42:52 +0100},
	Date-Modified = {2008-12-30 09:05:21 +0100},
	Journal = {Information Sciences},
	Keywords = {AFS algebras; Completely distributive lattices; AFS structures; Preference relations; Sub-preference relations},
	Number = {4},
	Pages = {1007-1026},
	Title = {Approaches to the representations and logic operations of fuzzy concepts in the framework of axiomatic fuzzy set theory {I}},
	Volume = {177},
	Year = {2007},
	Abstract = {In this paper, the representations of fuzzy concepts based on raw data have been investigated within the framework of AFS (Axiomatic Fuzzy Set) theory. First, a brief review of AFS theory is presented and a completely distributive lattice, the E#I algebra, is proposed. Secondly, two kinds of E#I algebra representations of fuzzy concepts are derived in detail. In order to represent the membership functions of fuzzy concepts in the interval [0, 1], the norm of AFS algebra is defined and studied. Finally, the relationships of various representations with their advantages and drawbacks are analyzed.},
	Bdsk-Url-1 = {http://dx.doi.org/10.1016/j.ins.2006.07.011}}

@article{liu:2007a,
	Author = {Liu, Xiaodong and Wang, Wei and Chai, Tianyou and Liu, Wanquan},
	Date-Added = {2008-12-29 10:36:59 +0100},
	Date-Modified = {2008-12-29 12:04:53 +0100},
	Journal = {Information Sciences},
	Keywords = {AFS algebras; AFS structures; Formal concept analysis; Concept lattice; Fuzzy clustering},
	Number = {4},
	Pages = {1027-1045},
	Title = {Approaches to the representations and logic operations of fuzzy concepts in the framework of axiomatic fuzzy set theory {II}},
	Volume = {177},
	Year = {2007},
	Abstract = {In part II of this paper, firstly, we study the relationship between the AFS (Axiomatic Fuzzy Zet) and FCA (Formal Concept Analysis, which has become a powerful theory for data analysis, information retrieval, and Knowledge discovery) and some algebraic homomorphisms between the AFS algebras and the concept lattices are established. Then, the numerical approaches to determining membership functions proposed in part I of this paper are used to study the fuzzy description and data clustering problems by mimicking human reasoning process. Finally, illustrative examples show that the framework of AFS theory offers a far more flexible and effective approach to artificial intelligence system analysis and design with applications to knowledge acquisition and representations in practice.
},
	Bdsk-Url-1 = {http://dx.doi.org/10.1016/j.ins.2006.07.012}}

@article{guoqian-jiang:2003,
	Author = {Jiang, Guoqian and Ogasawara, Katsuhiko and Endoh, Akira and Sakurai, Tsunetaro},
	Date-Added = {2008-12-29 10:33:25 +0100},
	Date-Modified = {2008-12-29 10:35:40 +0100},
	Journal = {International Journal of Medical Informatics},
	Keywords = {Knowledge representation; Information retrieval; Formal concept analysis; Natural language processing; Medical records; Knowledge acquisition},
	Number = {1},
	Pages = {71-81},
	Title = {Context-based ontology building support in clinical domains using formal concept analysis},
	Volume = {71},
	Year = {2003},
	Abstract = {Objective: Ontology in clinical domains is becoming a core research field in the realm of medical informatics. The objective of this study is to explore the potential role of formal concept analysis (FCA) in a context-based ontology building support in a clinical domain (e.g. cardiovascular medicine here). Methodology: We developed an ontology building support system that integrated an FCA module with a natural language processing (NLP) module. The user interface of the system was developed as a Prot{\'e}g{\'e}-2000 JAVA tab plug-in. A collection of 368 textual discharge summaries and a standard dictionary of Japanese diagnostic terms (MEDIS ver2.0) were used as the main knowledge sources. A preliminary evaluation was taken to show the usefulness of the system. Results: Stability was shown on the MEDIS-based medical concept extraction with high precision. 73$\pm$14% (mean$\pm$S.D.) of the compound medical phrases extracted were sufficiently meaningful to form a medical concept from a clinical perspective. Also, 57.7% of attribute implication pairs (i.e. medical concept pairs) extracted were identified as positive from a clinical perspective. Conclusion: Under the framework of our ontology building support system using FCA, the clinical experts could reach a mass of both linguistic information and context-based knowledge that was demonstrated as useful to support their ontology building tasks.
},
	Bdsk-Url-1 = {http://dx.doi.org/10.1016/S1386-5056(03)00092-3}}

@article{fan:2006,
	Author = {Fan, Shi-Qing and Zhang, Wen-Xiu and Xu, Wei},
	Date-Added = {2008-12-29 10:29:50 +0100},
	Date-Modified = {2008-12-29 10:31:58 +0100},
	Journal = {Fuzzy Sets and Systems},
	Keywords = {Galois connection; Formal concept analysis; Fuzzy concept lattice; Fuzzy inference; Fuzzy logic},
	Number = {24},
	Pages = {3177-3187},
	Title = {Fuzzy inference based on fuzzy concept lattice},
	Volume = {157},
	Year = {2006},
	Abstract = {In this paper, a fuzzy inference method based on the notion of fuzzy concept lattice is studied. We first propose a new form of fuzzy concept lattice, and then based on three kinds of known fuzzy concept lattices and our new fuzzy concept lattice, two coherent fuzzy inference methods, the lower approximate fuzzy inference and the upper approximate fuzzy inference, are proposed, and the combined use of the two methods will make the fuzzy inference more precise.},
	Bdsk-Url-1 = {http://dx.doi.org/10.1016/j.fss.2006.07.011}}

@article{lei:2009,
	Author = {Lei, Yinbin and Luo, Maokang},
	Date-Added = {2008-12-29 10:10:45 +0100},
	Date-Modified = {2008-12-29 12:06:37 +0100},
	Journal = {Annals of Pure and Applied Logic},
	Keywords = {Concept lattice; Galois connection; Information system; Rough approximable concept; Scott domain; Algebraic lattice},
	Number = {3},
	Pages = {333--340},
	Volume = {159},
	Title = {Rough concept lattices and domains},
	Url = {http://dx.doi.org/10.1016/j.apal.2008.09.028,},
	Year = {2009},
	Abstract = {In the paper, we study connections between rough concept lattices and domains. The main result is representation theorems of complete lattices and algebraic lattices by concepts based on Rough Set Theory. It is shown that there is a deep relationship between Rough Set Theory and Domain Theory.
},
	Bdsk-Url-1 = {http://dx.doi.org/10.1016/j.apal.2008.09.028}}

@article{formica:2008,
	Author = {Formica, Anna},
	Date-Added = {2008-12-29 10:08:05 +0100},
	Date-Modified = {2008-12-29 10:09:38 +0100},
	Journal = {Knowledge-Based Systems},
	Keywords = {Formal Concept Analysis; Semantic web; Information content; Similarity reasoning},
	Number = {1},
	Pages = {80-87},
	Title = {Concept similarity in Formal Concept Analysis: An information content approach},
	Volume = {21},
	Year = {2008},
	Abstract = {Formal Concept Analysis (FCA) is revealing interesting in supporting difficult activities that are becoming fundamental in the development of the Semantic Web. Assessing concept similarity is one of such activities since it allows the identification of different concepts that are semantically close. In this paper, a method for measuring the similarity of FCA concepts is presented, which is a refinement of a previous proposal of the author. The refinement consists in determining the similarity of concept descriptors (attributes) by using the information content approach, rather than relying on human domain expertise. The information content approach which has been adopted allows a higher correlation with human judgement than other proposals for evaluating concept similarity in a taxonomy defined in the literature.},
	Bdsk-Url-1 = {http://dx.doi.org/10.1016/j.knosys.2007.02.001}}

@article{shao:2007,
	Author = {Shao, Ming-Wen and Liu, Min and Zhang, Wen-Xiu},
	Date-Added = {2008-12-29 10:04:16 +0100},
	Date-Modified = {2008-12-29 10:07:08 +0100},
	Journal = {Fuzzy Sets and Systems},
	Keywords = {Concept lattice; Formal concept analysis; Rough set; Lower approximation; Upper approximation; Fuzzy rough sets},
	Number = {23},
	Pages = {2627-2640},
	Title = {Set approximations in fuzzy formal concept analysis},
	Volume = {158},
	Year = {2007},
	Abstract = {Formal concept analysis and rough set theory are two important tools in knowledge representation and knowledge discovery in relational information systems. The purpose of this paper is to study rough set approximations within formal concept analysis in fuzzy environment. Properties of existent fuzzy concept lattices derived from an adjoint pair of operations are first reviewed and examined. Based on both lattice-theoretic and fuzzy set-theoretic operators, two new pairs of rough fuzzy set approximations within fuzzy formal contexts are then defined. Finally, properties of the rough fuzzy set approximation operators are presented in detail.},
	Bdsk-Url-1 = {http://dx.doi.org/10.1016/j.fss.2007.05.002}}

@article{belohlavek:2007,
	Author = {B{\v e}lohl{\'a}vek, R. and Dvo{\v r}{\'a}k, Ji{\v r}{\'\i} and Outrata, Jan},
	Date-Added = {2008-12-29 10:01:00 +0100},
	Date-Modified = {2008-12-29 12:07:12 +0100},
	Journal = {Journal of Computer and System Sciences},
	Keywords = {Tabular data; Clustering; Formal concept analysis; fuzzy attribute; Similarity; Factorization},
	Number = {6},
	Pages = {1012-1022},
	Title = {Fast factorization by similarity in formal concept analysis of data with fuzzy attributes},
	Volume = {73},
	Year = {2007},
	Abstract = {We present a method of fast factorization in formal concept analysis (FCA) of data with fuzzy attributes. The output of FCA consists of a partially ordered collection of clusters extracted from a data table describing objects and their attributes. The collection is called a concept lattice. Factorization by similarity enables us to obtain, instead of a possibly large concept lattice, its factor lattice. The elements of the factor lattice are maximal blocks of clusters which are pairwise similar to degree exceeding a user-specified threshold. The factor lattice thus represents an approximate version of the original concept lattice. We describe a fuzzy closure operator the fixed points of which are just clusters which uniquely determine the blocks of clusters of the factor lattice. This enables us to compute the factor lattice directly from the data without the need to compute the whole concept lattice. We present theoretical solution and examples demonstrating the speed-up of our method.},
	Bdsk-Url-1 = {http://dx.doi.org/10.1016/j.jcss.2007.03.016}}

@article{liushao:2007,
	Author = {Liu, Min and Shao, Mingwen and Zhang, Wenxiu and Wu, Cheng},
	Date-Added = {2008-12-29 09:57:55 +0100},
	Date-Modified = {2008-12-29 11:00:04 +0100},
	Journal = {Computers \& Mathematics with Applications},
	Keywords = {Formal context; Concept lattice; Rough set; Attribute reduction; Object reduction; Scheduling},
	Number = {9},
	Pages = {1390-1410},
	Title = {Reduction method for concept lattices based on rough set theory and its application},
	Volume = {53},
	Year = {2007},
	Abstract = {Rough set theory and formal concept analysis are two complementary mathematical tools for data analysis. In this paper, we study the reduction of the concept lattices based on rough set theory and propose two kinds of reduction methods for the above concept lattices. First, we present the sufficient and necessary conditions for justifying whether an attribute and an object are dispensable or indispensable in the above concept lattices. Based on the above justifying conditions, we propose a kind of multi-step attribute reduction method and object reduction method for the concept lattices, respectively. Then, on the basis of the defined discernibility functions of the concept lattices, we propose a kind of single-step reduction method for the concept lattices. Additionally, the relations between the attribute reduction of the concept lattices in FCA and the attribute reduction of the information system in rough set theory are discussed in detail. At last, we apply the above multi-step attribute reduction method for the concept lattices based on rough set theory to the reduction of the redundant premises of the multiple rules used in the job shop scheduling problem. The numerical computational results show that the reduction method for the concept lattices is effective in the reduction of the multiple rules.},
	Bdsk-Url-1 = {http://dx.doi.org/10.1016/j.camwa.2006.03.040}}

@article{boucher-ryana:2006,
	Author = {du Boucher-Ryana, Patrick and Bridge, Derek},
	Date-Added = {2008-12-29 09:52:08 +0100},
	Date-Modified = {2008-12-29 09:55:35 +0100},
	Journal = {Knowledge-Based Systems},
	Keywords = {Collaborative filtering; Recommender systems; Formal Concept Analysis},
	Number = {5},
	Pages = {309-315},
	Title = {Collaborative Recommending using Formal Concept Analysis},
	Volume = {19},
	Year = {2006},
	Abstract = {We show how Formal Concept Analysis (FCA) can be applied to Collaborative Recommenders. FCA is a mathematical method for analysing binary relations. Here we apply it to the relation between users and items in a collaborative recommender system. FCA groups the users and items into concepts, ordered by a concept lattice. We present two new algorithms for finding neighbours in a collaborative recommender. Both use the concept lattice as an index to the recommender's ratings matrix. Our experimental results show a major decrease in the amount of work needed to find neighbours, while guaranteeing no loss of accuracy or coverage.},
	Bdsk-Url-1 = {http://dx.doi.org/10.1016/j.knosys.2005.11.017}}

@article{xia-wang:2008,
	Author = {Wang, Xia and Zhang, Wenxiu},
	Date-Added = {2008-12-29 09:48:34 +0100},
	Date-Modified = {2008-12-29 09:51:33 +0100},
	Journal = {Knowledge-Based Systems},
	Keywords = {Object oriented concept lattice; Property oriented concept lattice; Attribute reduction; Partial relation; Irreducible element},
	Number = { 5},
	Pages = {398-403},
	Title = {Relations of attribute reduction between object and property oriented concept lattices},
	Volume = {21},
	Year = {2008},
	Abstract = {As one of the basic problems of knowledge discovery and data analysis, knowledge reduction can make the discovery of implicit knowledge in data easier and the representation simpler. In this paper, relations of attribute reduction between object and property oriented formal concept lattices are discussed. And beautiful results are obtained that attribute reducts and attribute characteristics in the two concept lattices are the same based on new approaches to attribute reduction by means of irreducible elements. It turns out to be meaningful and effective in dealing with knowledge reduction, as attribute reducts and attribute characteristics in the object and property oriented formal concept lattices can be acquainted by only investigating one of the two concept lattices.},
	Bdsk-Url-1 = {http://dx.doi.org/10.1016/j.knosys.2008.02.005}}

@article{gerd-stumme:2002,
	Author = {Stumme, Gerd and Taouil, Rafik and Bastide, Yves and Pasquier, Nicolas and Lakhal, Lotfi},
	Date-Added = {2008-12-29 09:44:03 +0100},
	Date-Modified = {2008-12-29 09:48:05 +0100},
	Journal = {Data \& Knowledge Engineering},
	Keywords = {Knowledge discovery; Database analysis; Formal concept analysis; Closure systems; Lattices; Algorithms},
	Number = {2},
	Pages = {189-222},
	Title = {Computing iceberg concept lattices with Titanic},
	Volume = {42},
	Year = {2002},
	Abstract = {We introduce the notion of iceberg concept lattices and show their use in knowledge discovery in databases. Iceberg lattices are a conceptual clustering method, which is well suited for analyzing very large databases. They also serve as a condensed representation of frequent itemsets, as starting point for computing bases of association rules, and as a visualization method for association rules. Iceberg concept lattices are based on the theory of Formal Concept Analysis, a mathematical theory with applications in data analysis, information retrieval, and knowledge discovery. We present a new algorithm called Titanic for computing (iceberg) concept lattices. It is based on data mining techniques with a level-wise approach. In fact, Titanic can be used for a more general problem: Computing arbitrary closure systems when the closure operator comes along with a so-called weight function. The use of weight functions for computing closure systems has not been discussed in the literature up to now. Applications providing such a weight function include association rule mining, functional dependencies in databases, conceptual clustering, and ontology engineering. The algorithm is experimentally evaluated and compared with Ganter's Next-Closure algorithm. The evaluation shows an important gain in efficiency, especially for weakly correlated data.},
	Bdsk-Url-1 = {http://dx.doi.org/10.1016/S0169-023X(02)00057-5}}

@article{lidong-wang:2008,
	Author = {Wang, Lidong and Liu, Xiaodong},
	Date-Added = {2008-12-29 09:39:16 +0100},
	Date-Modified = {2008-12-29 12:05:32 +0100},
	Journal = {Information Sciences},
	Keywords = {Formal concept analysis; Concept lattice; AFS algebras; AFS formal concept; Rough set; Concept approximation},
	Number = {21},
	Pages = {4125-4137},
	Title = {Concept analysis via rough set and {AFS} algebra},
	Volume = {178},
	Year = {2008},
	Abstract = {Formal concept analysis (FCA) was originally proposed by Wille (1982), which is an important theory for data analysis and knowledge discovery. AFS (axiomatic fuzzy set) algebra was proposed by Liu [X. Liu, The fuzzy theory based on AFS algebras and AFS structure, Journal of Mathematical Analysis and Applications 217 (1998) 459--478; X. Liu, The topology on AFS algebra and AFS structure, Journal of Mathematical Analysis and Applications 217 (1998) 479--489], which is a semantic methodology relating to the fuzzy theory. Combining above two theories, we propose AFS formal concept, which can be viewed as the generalization and development of monotone concept proposed by Deogun and Saquer (2003). Moreover, we show that the set of all AFS formal concepts forms a complete lattice. AFS formal concept can be applied to represent the logic operations of queries in information retrieval. Furthermore, we give an approach to find the AFS formal concepts whose intents (extents) approximate any element of AFS algebra by virtue of rough set theory.},
	Bdsk-Url-1 = {http://dx.doi.org/10.1016/j.ins.2008.07.004}}

@article{krajci,
	Author = {Kraj{\v c}i, S.},
	Date-Added = {2007-12-17 10:58:58 +0100},
	Date-Modified = {2007-12-17 10:59:44 +0100},
	Journal = {Neural Network World},
	Number = {5},
	Pages = {521--530},
	Title = {Cluster based efficient generation of fuzzy concepts},
	Volume = {13},
	Year = {2003}}

@inproceedings{bj,
	Author = {Ben Yahia, S. and Jaoua, A.},
	Booktitle = {Data mining and computational intelligence},
	Date-Added = {2007-12-17 10:57:56 +0100},
	Date-Modified = {2007-12-17 10:58:54 +0100},
	Pages = {169--190},
	Publisher = {Physica Verlag},
	Title = {Discovering knowledge from fuzzy concept lattice.},
	Year = {2001}}

@inproceedings{bsz,
	Author = {B{\v e}lohl{\'a}vek, R. and Sklen{\'a}{\v r}, V and Zacpal, J.},
	Booktitle = {Intl Conf on Fuzzy Concept Analysis},
	Date-Added = {2007-12-17 10:54:55 +0100},
	Date-Modified = {2007-12-17 11:04:42 +0100},
	Pages = {268--283},
	Series = {Lecture Notes in Computer Science},
	Title = {Crisply generated fuzzy concepts},
	Volume = {3403},
	Year = {2005}}

@incollection{wille:1982,
	Author = {Wille, R.},
	Booktitle = {Ordered Sets},
	Date-Added = {2007-05-11 12:04:54 +0200},
	Date-Modified = {2007-05-11 12:07:39 +0200},
	Editor = {Rival, I.},
	Pages = {445-470},
	Publisher = {Reidel},
	Title = {Restructuring lattice theory: an approach based on hierarchies of concepts},
	Year = {1982}}
	
	@ article{stumme,
  author = {Stumme, G.},
  journal = {Lecture Notes in Computer Science},
  volume = {2393},
  publisher = {Springer},
  pages = {2--19},
  title = {Formal Concept Analisis on Its Way from Mathematics to Computer Science},
  year = {2002}}

@article{freeman,
  author = {Freeman, L. and White, D.},
  journal = {Sociological Methodology},
  pages = {127--146},
  title = {Using {G}alois Lattices to represent network data},
  year =      {1993}}
 
@inproceedings{fischer98,
  author =    {Fischer, B.},
  title =     {Specification-Based Browsing of Software Component
Libraries},
   pages =  {246--254},
  booktitle = {In Proceedings of the Proc. Automated Software Engineering, Hawaii},
  year = {1998}}
  
  

@inproceedings{eisenbarth,
  author =    {Eisenbarth, T. and Koschke, R. and Simon, D.},
  title =     {Feature-Driven Program Understanding Using Concept Analisis of Execution Trace},
   pages =  {300--309},
  publisher = {International Conference on Software Maintenance},
  booktitle = {In Proceedings of the Ninth International Workshop on Program Comprehension},
  year = {2001}}

@book{sowa,
  author = {Sowa, J.},
  publisher = {Addison-Wesley},
  title = {Conceptual Structures: Information Processing in Mind and Machine},
  year = {1984}}

@inproceedings{godin,
  author = {Godin, R. and Gecsei, J. and Pichet, C.},
  publisher = {In N. J. Belkin and C.J. van Rijsbergen (ed.), Ordered sets},
  pages = {32--39},
  title = {Design of Browsing Interface for Information Retrieval},
  booktitle = {Proceedings SIGIR 89},
  year = {1989}}
  

@book{belohlavek:2002,
	Author = {B{\v e}lohl{\'a}vek, R.},
	Date-Added = {2007-05-11 11:03:19 +0200},
	Date-Modified = {2007-05-11 11:07:46 +0200},
	Publisher = {Kluwer Academic Publishers},
	Title = {Fuzzy Relational Systems: Foundations and Principles},
	Year = {2002}}

@inproceedings{belohlavek:1998b,
	Author = {B{\v e}lohl{\'a}vek, R.},
	Booktitle = {4th Intl Conf on Fuzzy Sets Theory and Applications},
	Date-Added = {2007-05-11 11:00:42 +0200},
	Date-Modified = {2007-05-11 11:02:51 +0200},
	Pages = {11},
	Title = {Lattice generated by binary fuzzy relations (extended abstract)},
	Year = {1998}}

@inproceedings{krajci-hedges:2005,
	Author = {Kraj{\v c}i, S.},
	Booktitle = {Intl Workshop on Concept Lattices and their Applications},
	Date-Added = {2006-12-20 10:32:11 +0100},
	Date-Modified = {2006-12-20 11:05:41 +0100},
	Pages = {1--9},
	Title = {Every Concept Lattice With Hedges Is Isomorphic To Some Generalized Concept Lattice},
	Year = {2005}}

@article{belohlavek:2001a,
	Author = {B{\v e}lohl{\'a}vek, R.},
	Date-Added = {2006-11-29 14:00:29 +0100},
	Date-Modified = {2006-11-29 14:05:29 +0100},
	Journal = {Fundamenta Informaticae},
	Number = {4},
	Pages = {277-285},
	Title = {Reduction and a simple proof of characterization of fuzzy concept lattices},
	Url = {http://iospress.metapress.com/openurl.asp?genre=article&issn=0169-2968&volume=46&issue=4&spage=277},
	Volume = {46},
	Year = {2001},
	Bdsk-Url-1 = {http://iospress.metapress.com/openurl.asp?genre=article&issn=0169-2968&volume=46&issue=4&spage=277}}

@article{georgescu:2004a,
	Author = {Georgescu, G. and Popescu, A.},
	Date-Added = {2006-11-28 15:48:32 +0100},
	Date-Modified = {2006-11-28 16:07:57 +0100},
	Journal = {Fuzzy Sets and Systems},
	Keywords = {Weak pseudo-BL-algebra, Pseudo-MTL-algebra, Pseudo-t-norm, Pair of weak negations},
	Number = {1},
	Pages = {129-155},
	Title = {Non-commutative fuzzy structures and pairs of weak negations},
	Url = {http://www.sciencedirect.com/science?_ob=ArticleURL&_udi=B6V05-4B3JH42-3&_coverDate=04%2F01%2F2004&_alid=497108362&_rdoc=1&_fmt=&_orig=search&_qd=1&_cdi=5637&_sort=d&view=c&_acct=C000032799&_version=1&_urlVersion=0&_userid=618624&md5=e43aeeb693f45c265d0bf6ae5b290864},
	Volume = {143},
	Year = {2004},
	Abstract = {Weak pseudo BL-algebras (WPBL-algebras) are non-commutative fuzzy structures which arise from pseudo-t-norms (i.e. the non-commutative versions of triangular norms). In this paper, we study the pairs of weak negations on WPBL-algebras, extending the case of weak negations on Esteva--Godo MTL-algebras. A geometrical characterization of the pairs of weak negations in bounded chains is provided.

Our main result characterizes the pairs of weak negations compatible with the multiplication of totally ordered WPBL-algebras giving a way to obtain new examples of WPBL-algebras. We use this to identify all the compatible pairs of weak negations on finite MV-chains.},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science?_ob=ArticleURL&_udi=B6V05-4B3JH42-3&_coverDate=04/01/2004&_alid=497108362&_rdoc=1&_fmt=&_orig=search&_qd=1&_cdi=5637&_sort=d&view=c&_acct=C000032799&_version=1&_urlVersion=0&_userid=618624&md5=e43aeeb693f45c265d0bf6ae5b290864}}

@article{georgescu:2004,
	Author = {Georgescu, G. and Popescu, A.},
	Date-Added = {2006-11-28 15:47:12 +0100},
	Date-Modified = {2006-11-28 16:03:09 +0100},
	Journal = {Archive for Mathematical Logic},
	Keywords = {Duality, Isotone structure, Fuzzy set theory, Galois connection, conjugated pair, Closure operator},
	Local-Url = {file://localhost/Users/aciego/Documents/papers-imac/De%20otra%20gente/Concept%20lattices%20Georgescu/non-dual-fuzz-conn.pdf},
	Number = {8},
	Pages = {1009-1039},
	Title = {Non-dual fuzzy connections},
	Url = {http://dx.doi.org/10.1007/s00153-004-0240-4},
	Volume = {43},
	Year = {2004},
	Abstract = {The lack of double negation and de Morgan properties makes fuzzy logic unsymmetrical. This is the reason why fuzzy versions of notions like closure operator or Galois connection deserve attention for both antiotone and isotone cases, these two cases not being dual. This paper offers them attention, comming to the following conclusions:
-- some kind of hardly describable local preduality still makes possible important parallel results;
-- interesting new concepts besides antitone and isotone ones (like, for instance, conjugated pair), that were classically reducible to the first, gain independency in fuzzy setting.},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/s00153-004-0240-4}}


@article {popescu04,
author = {Popescu, Andrei},
title = {A general approach to fuzzy concepts},
journal = {Mathematical Logic Quarterly},
volume = {50},
number = {3},
publisher = {WILEY-VCH Verlag},
issn = {1521-3870},
url = {http://dx.doi.org/10.1002/malq.200310098},
doi = {10.1002/malq.200310098},
pages = {265--280},
keywords = {Fuzzy concept analysis, fuzzy logic, Galois connection, conceptual hierarchy, concept equation},
year = {2004},
abstract = {The paper proposes a flexible way to build concepts within fuzzy logic and set theory. The framework is general enough to capture some important particular cases, with their own independent interpretations, like âœantitoneâ or âœisotoneâ concepts constructed from fuzzy binary relations, but also to allow the two universes (of objects and attributes) to be equipped each with its own truth structure. Perhaps the most important feature of our approach is that we do not commit ourselves to any kind of logical connector, covering thus the case of a possibly non-commutative conjunction too. (Â© 2004 WILEY-VCH Verlag GmbH & Co. KGaA, Weinheim)},
}


@article{george-georgescu:2005,
	Author = {Georgescu, G. and Popescu, A.},
	Date-Added = {2006-11-28 15:42:40 +0100},
	Date-Modified = {2006-11-28 16:05:32 +0100},
	Journal = {Logic Journal of the IGPL},
	Keywords = {similarity convergence, residuated lattice, Cauchy completion, Lukasiewicz-Moisil algebra, relation algebra},
	Local-Url = {file://localhost/Users/aciego/Documents/papers-imac/De%20otra%20gente/Concept%20lattices%20Georgescu/non-dual-fuzz-conn.pdf},
	Number = {4},
	Pages = {389-413},
	Title = {Similarity Convergence in Residuated Structures},
	Url = {http://dx.doi.org/10.1093/jigpal/jzi031},
	Volume = {13},
	Year = {2005},
	Abstract = {We introduce and study a notion of logical convergence in residuated lattices (with operators). It is considered a convergence in similarity degree, rather than a bare order convergence -- the lack of symmetry of residuated lattices brings our approach more related to the logical structure than to the set of truth values.},
	Bdsk-Url-1 = {http://dx.doi.org/10.1093/jigpal/jzi031}}

@inproceedings{belohlavek:1998,
	Author = {B{\v e}lohl{\'a}vek, R.},
	Booktitle = {Joint Conference on Information Sciences},
	Date-Added = {2006-11-28 13:35:31 +0100},
	Date-Modified = {2006-11-28 13:38:05 +0100},
	Pages = {179-182},
	Title = {Fuzzy concepts and conceptual structures: induced similarities},
	Year = {1998}}

@article{burusco:1998,
	Author = {Burusco, A. and Fuentes-Gonz{\'a}lez, R.},
	Date-Added = {2006-10-31 13:57:31 +0100},
	Date-Modified = {2006-11-21 15:26:27 +0100},
	Journal = {Fuzzy Sets and Systems},
	Number = {1},
	Pages = {109--114},
	Title = {Construction of the ${L}$-fuzzy concept lattice},
	Url = {http://dx.doi.org/10.1016/S0165-0114(96)00318-1},
	Volume = {97},
	Year = {1998},
	Abstract = {We propose two processes to obtain L-fuzzy concepts based on finite L-fuzzy contexts and the theory of Cousot and Cousot [Pacific J. Math. 82 (1979) 43]. The first algorithm calculates the L-fuzzy concepts derived from an L-fuzzy set and the second one constructs the whole L-fuzzy concept lattice. We also represent graphically the L-fuzzy concept lattice.},
	Bdsk-Url-1 = {http://dx.doi.org/10.1016/S0165-0114(96)00318-1}}

@article{belohlavek:2001,
	Author = {B{\v e}lohl{\'a}vek, R.},
	Date-Added = {2006-10-31 13:51:50 +0100},
	Date-Modified = {2008-12-29 11:41:18 +0100},
	Journal = {Mathematical Logic Quartely},
	Keywords = {Fuzzy logic, Galois connection, Lattice of fixed points, Concept lattice},
	Local-Url = {file://localhost/Users/aciego/Documents/papers-imac/De%20otra%20gente/concept%20lattices%20papers/behloh-mlq.pdf},
	Number = {1},
	Pages = {111-116},
	Title = {Lattices of Fixed Points of Fuzzy {G}alois Connections},
	Url = {http://dx.doi.org/10.1002/1521-3870(200101)47:1%3C111::AID-MALQ111%3E3.0.CO;2-A},
	Volume = {47},
	Year = {2001},
	Bdsk-Url-1 = {http://dx.doi.org/10.1002/1521-3870(200101)47:1%3C111::AID-MALQ111%3E3.0.CO;2-A}}

@article{belohlavek,
	Author = {B{\v e}lohl{\'a}vek, R.},
	Date-Modified = {2006-10-31 13:26:46 +0100},
	Journal = {Annals of Pure and Applied Logic},
	Keywords = {Fuzzy logic; Concept lattice; Formal concept analysis; Fuzzy order},
	Pages = {277--298},
	Title = {Concept lattices and order in fuzzy logic},
	Url = {http://dx.doi.org/10.1016/j.apal.2003.01.001},
	Volume = {128},
	Year = {2004},
	Abstract = {The theory of concept lattices (i.e. hierarchical structures of concepts in the sense of Port-Royal school) is approached from the point of view of fuzzy logic. The notions of partial order, lattice order, and formal concept are generalized for fuzzy setting. Presented is a theorem characterizing the hierarchical structure of formal fuzzy concepts arising in a given formal fuzzy context. Also, as an application of the present approach, Dedekind--MacNeille completion of a partial fuzzy order is described. The approach and results provide foundations for formal concept analysis of vague data---the propositions ``object x has attribute y'', which form the input data to formal concept analysis, are now allowed to have also intermediate truth values, meeting reality better.},
	Bdsk-Url-1 = {http://dx.doi.org/10.1016/j.apal.2003.01.001}}

@inproceedings{belohlavekVychodilCLA05,
	Author = {B{\v e}lohl{\'a}vek, R. and Vychodil, V.},
	Booktitle = {Intl Workshop on Concept Lattices and their Applications},
	Date-Modified = {2006-12-20 11:05:33 +0100},
	Keywords = {formal concept analysis, fuzzy logic, fuzzy attribute},
	Local-Url = {file://localhost/Users/aciego/Documents/papers-imac/De%20otra%20gente/concept%20lattices%20papers/paper4.pdf},
	Pages = {34--45},
	Title = {What is a fuzzy concept lattice?},
	Url = {http://ftp.informatik.rwth-aachen.de/Publications/CEUR-WS/Vol-162/paper4.pdf},
	Year = {2005},
	Abstract = {The paper is an overview of several approaches to the notion 
of a concept lattice from the point of view of fuzzy logic. The main aim 
is to clarify relationships between the various approaches. 
},
	Bdsk-Url-1 = {http://ftp.informatik.rwth-aachuren.de/Publications/CEUR-WS/Vol-162/paper4.pdf}}

@article{burusco,
	Author = {Burusco, A. and Fuentes-Gonz\'alez, R.},
	Date-Modified = {2006-11-21 15:26:40 +0100},
	Journal = {Mathware \& Soft Computing},
	Keywords = {fuzzy attribute, Formal concept analysis},
	Local-Url = {file://localhost/Users/aciego/Documents/papers-imac/De%20otra%20gente/concept%20lattices%20papers/burusco.pdf},
	Pages = {209--218},
	Title = {The study of ${L}$-fuzzy concept lattice}, 
	Volume = {3},
	Year = {1994},
	Bdsk-Url-1 = {http://docto-si.ugr.es/Mathware/v1n3/PS/burusco.ps.gz}}

@article{buruscoFSSEx,
	Author = {Burusco, A. and Fuentes-Gonz\'alez, R.},
	Date-Modified = {2008-12-29 12:07:38 +0100},
	Journal = {Fuzzy Sets and Systems},
	Keywords = {Fuzzy concept lattice, formal concept analysis},
	Local-Url = {file://localhost/Users/aciego/Documents/papers-imac/De%20otra%20gente/concept%20lattices%20papers/sdarticle-10.pdf},
	Pages = {431--436},
	Title = {Concept lattices defined from implication operators},
	Url = {http://dx.doi.org/10.1016/S0165-0114(98)00182-1},
	Volume = {114},
	Year = {2000},
	Bdsk-Url-1 = {http://dx.doi.org/10.1016/S0165-0114(98)00182-1}}


%:%%%%%%%%%%%% POSSIBILITY--THEORETIC

@article {Djouadi:2011,
   author = {Djouadi, Yassine and Prade, Henri},
   affiliation = {Department of Computer Science, University of Tizi-Ouzou, BP 17 RP, Tizi-Ouzou, Algeria},
   title = {Possibility-theoretic extension of derivation operators in formal concept analysis over fuzzy lattices},
   journal = {Fuzzy Optimization and Decision Making},
   publisher = {Springer Netherlands},
   issn = {1568-4539},
   keyword = {Computer Science},
   pages = {287-309},
   Volume = {4},
   Year = {2011},
  url = {http://dx.doi.org/10.1007/s10700-011-9106-5}

}


@article{guo:2011,
	Author = {Guo, L. and Huang, F. and Li, Q. and Zhang, G.},
	Date-Added = {2012-05-11 11:42:03 +0000},
	Date-Modified = {2012-05-11 11:42:03 +0000},
	Journal = {Discrete Mathematics},
	Number = {18-19},
	Pages = {2049-2063},
	Title = {Power contexts and their concept lattices},
	Volume = {311},
	Year = {2011}}



@article{dubois:2011,
	Author = {Dubois, D. and Prade, H.},
	Date-Added = {2012-05-11 11:35:21 +0000},
	Date-Modified = {2012-05-11 11:35:21 +0000},
	Journal = {Applied and Computational Mathematics},
	Number = {1},
	Pages = {10-19},
	Title = {On possibility theory, formal concept analysis and granulation: Survey},
	Volume = {10},
	Year = {2011}}

@article{dubois:2012,
	Author = {Dubois, D. and Prade, H.},
	Date-Added = {2012-05-11 11:35:21 +0000},
	Date-Modified = {2012-05-11 11:35:21 +0000},
	Journal = {Fuzzy Sets and Systems},
	Pages = {4-16},
	Title = {Possibility theory and formal concept analysis: Characterizing independent sub-contexts},
	Volume = {196},
	Year = {2012}}
	
	


@article{DuboisSP07,
  author = {D. Dubois and F. Dupin de Saint-Cyr and H. Prade},
  interHash = {d2f0841c2a667600731f7749ece12e34},
  intraHash = {0e534df07ee89b54a0cf0a86bf83cca9},
  journal = {Fundamenta Informaticae},
  number = {1-4},
  pages = {195-213},
  title = {A Possibility-Theoretic View of Formal Concept Analysis.},
  volume = {75},
  year = {2007},
   date = {2007-03-13}
}


@inproceedings{DuboisP09,
   author    = {D. Dubois and H. Prade},
  title     = {Possibility theory and  formal concept analysis in information systems},
  booktitle = {IFSA/EUSFLAT'09},
  year      = {2009},
  pages     = {1021-1026},
}


@inproceedings{DuntschG03,
   author    = {I. D{\"u}ntsch and
               G. Gediga},
  title     = {Approximation Operators in Qualitative Data Analysis},
  booktitle = {Theory and Applications of Relational Structures as Knowledge
               Instruments},
  year      = {2003},
  pages     = {214-230},
}
%  ee        = {http://springerlink.metapress.com/openurl.asp?genre=article{\&}issn=0302-9743{\&}volume=2929{\&}spage=214},
%  crossref  = {DBLP:conf/RelMiCS/2003},
%  bibsource = {DBLP, http://dblp.uni-trier.de}


@inproceedings{DuntschG02,
  author    = {G. Gediga and I. D{\"u}ntsch},
  title     = {Modal-style operators in qualitative data analysis},
  booktitle = {Proc. IEEE Int. Conf. on Data Mining},
  year      = {2002},
  pages     = {155-162},
}
%  ee        = {http://computer.org/proceedings/icdm/1754/17540155abs.htm},
%  crossref  = {DBLP:conf/icdm/2002},
%  bibsource = {DBLP, http://dblp.uni-trier.de}

@article{chen07,
  author = { X. Chen and  Q. Li},
    journal = {Fuzzy Sets and
Systems},
  number = {23},
  pages = {2641--2653},
  title = {Construction of rough approximations in fuzzy setting},
  volume = {158},
  year = {2007},
}


@article{wolski03,
  author = {M. Wolski},
    journal = {Fundamenta Informaticae},
  pages = {1--15},
  title = {{G}alois connections and data analysis},
  volume = {CSP},
  year = {2003},
}


@inproceedings{yao06,
  author    = {Y. Y. Yao  and  Y. Chen},
  title     = {Rough Set Approximations in Formal Concept Analysis},
  booktitle = {Transactions
on Rough Sets V},
	Series = {Lecture Notes in Computer Science},
  volume = {4100},	
 year      = {2006},
  pages     = {285--305},
 }
 
 
@article{liu08,
  author = {G. L. Liu},
    journal = {Information Sciences},
  number = {6},
  pages = {1651--1662},
  title = {Generalized rough set over fuzzy lattices},
  volume = {178},
  year = {2008},
}


 @article{chenyao08,
  author = {Y. Chen and Y. Yao},
    journal = {Information Sciences},
  number = {1},
  pages = {1--20},
  title = {A multiview approach for intelligent data analysis based on data operators},
  volume = {178},
  year = {2008},
}
  
  
  
@inproceedings{yao04,
  author    = {Y. Y. Yao},
  title     = {Concept lattices in rough set theory},
  booktitle = {Proceedings of Annual Meeting of the North American Fuzzy Information
Processing Society (NAFIPS'04)},
  year      = {2004},
  pages     = {796--801},
 }
  

 @article{frascella08,
  author = {A. Frascella  and C. Guido},
    journal = {Fuzzy Sets and Systems},
  number = {1},
  pages = {1--22},
  title = {Transporting many-valued sets along many-valued relations.},
  volume = {159},
  year = {2008},
}
  
%:%%%%%%%%%% GAME THEORY WITH LATTICES
@article{Xu2012,
title = "Lattice-valued matrix game with mixed strategies for intelligent decision support ",
journal = "Knowledge-Based Systems ",
volume = "32",
number = "0",
pages = "56--64",
year = "2012",
issn = "0950-7051",
doi = "http://dx.doi.org/10.1016/j.knosys.2011.08.019",
url = "http://www.sciencedirect.com/science/article/pii/S0950705111001985",
author = "Yang Xu and Jun Liu and Xiaomei Zhong and Shuwei Chen",
keywords = "Lattice-valued matrix game",
keywords = "Lattice",
keywords = "Decision support system",
keywords = "Multi-agent system",
keywords = "Knowledge-based system",
keywords = "lâˆ—-Module",
keywords = "Mixed strategy "
}

%:%%%%%%%%%% DECISION SUPPORT (DSS)


@article{Wood2016,
title = "Supplier selection for development of petroleum industry facilities, applying multi-criteria decision making techniques including fuzzy and intuitionistic fuzzy \{TOPSIS\} with flexible entropy weighting ",
journal = "Journal of Natural Gas Science and Engineering ",
volume = "28",
number = "",
pages = "594 - 612",
year = "2016",
note= "",
issn = "1875-5100",
doi = "http://dx.doi.org/10.1016/j.jngse.2015.12.021",
url = "http://www.sciencedirect.com/science/article/pii/S1875510015303127",
author = "David A. Wood",
keywords = "Supplier selection",
keywords = "Gas oil facilities",
keywords = "Fuzzy TOPSIS",
keywords = "Intuitionistic fuzzy TOPSIS",
keywords = "Flexible entropy weighting ",
abstract = "Abstract Generic supplier selection from the perspective of multi-criteria decision making (MCDM) methodologies including crisp, fuzzy and intuitionistic fuzzy analysis of decision matrices has received much attention, but less so specifically for the gas and oil industry, and in terms of comparing performance of a number of available techniques. A set of 30 criteria are identified for assessing supplier selection for facilities and field development projects across the petroleum industry. Bidders are assessed in terms of these criteria, with varying degrees of uncertainty and subjectivity, using linguistic scoring terms that are then transformed into crisp and fuzzy numerical sets. Eight \{MCDM\} scoring methods are described mathematically and applied to a facilities-procurement scenario in order to analyze a linguistic-assessment matrix for five alternative bidders using the 30 recommended criteria. These scoring methods are: linear; non-linear; the order of preference by similarity to an ideal solution (TOPSIS); Fuzzy \{TOPSIS\} (with and without entropy weighting); and, intuitionistic fuzzy \{TOPSIS\} (IFT) with three alternative methods for calculating entropy weighting (We). Performance of the eight methods is assessed by comparing calculated rankings for the five bidders in relation to the defined supplier selection scenario for a base case and ten sensitivity cases. The results of the analysis suggest that entropy weightings applied to fuzzy sets provide more consistent bidder selection, and led to the proposal of a new intuitionistic-fuzzy-TOPSIS-method-with-flexible-entropy-weighting method that enables the entropy weighting scale to be tuned to suit the circumstances of specific scenarios using equation 30 to flexibly normalize the entropy weighting scale. "
}



@book{KeenMorton,
	Author = {Peter G.W. Keen and Michael S. Scott Morton},
	Edition = {First},
	Publisher = {Addison-Wesley},
	Title = {Decision Support Systems. An organizational perspective.},
	Year = {1978}}
	
@book{Alter,
	Author = {Steven L. Alter},
	Edition = {First},
	Publisher = {Addison-Wesley},
	Title = {Decision Support systems: Current Practices and Continuing Challenges.},
	Year = {1979}}
	
@article{Moore,
 author = {Jeffery H. Moore and Michael G. Chang},
 title = {Design of Decision Support Systems},
 journal = {SIGMIS Database},
 issue_date = {Fall 1980},
 volume = {12},
 number = {1-2},
 month = sep,
 year = {1980},
 issn = {0095-0033},
 pages = {8--14},
 numpages = {7},
 url = {http://doi.acm.org/10.1145/1017654.1017658},
 doi = {10.1145/1017654.1017658},
 acmid = {1017658},
 publisher = {ACM},
 address = {New York, NY, USA},
} 

@book{Finlay,
	Author = {Paul N. Finlay},
	Edition = {First},
	Publisher = {NCC Blackwell},
	Title = {Introducing Decision Support Systems},
	Year = {1989}}

@book{Turban,
	Author = {Efraim Turban and Jay E. Aronson},
	Edition = {Fifth},
	Publisher = {Prentice Hall International Editions},
	Title = {Decision Support Systems and Intelligent Systems},
	Year = {1998}}
	
@book{Sprague,
	Author = {Ralph H. Sprague, JR. and Hugh J. Aronson},
	Edition = {Second},
	Publisher = {Prentice Hall International Editions},
	Title = {Decision Support Systems. Putting Theory into Practice},
	Year = {1989}}
	


@article{Shim2002,
title = "Past, present, and future of decision support technology ",
journal = "Decision Support Systems ",
volume = "33",
number = "2",
pages = "111--126",
year = "2002",
issn = "0167-9236",
doi = "http://dx.doi.org/10.1016/S0167-9236(01)00139-7",
url = "http://www.sciencedirect.com/science/article/pii/S0167923601001397",
author = "J.P. Shim and Merrill Warkentin and James F. Courtney and Daniel J. Power and Ramesh Sharda and Christer Carlsson",
keywords = "Decision support technology",
keywords = "\{DSS\} development",
keywords = "Collaborative support systems",
keywords = "Virtual teams",
keywords = "Optimization-based decision support "
}


%%%%industria e ingenieria

@article{Kallestrup2014,
title = "Decision support in hierarchical planning systems: The case of procurement planning in oil refining industries ",
journal = "Decision Support Systems ",
volume = "68",
number = "0",
pages = "49--63",
year = "2014",
note= "",
issn = "0167-9236",
doi = "http://dx.doi.org/10.1016/j.dss.2014.09.003",
url = "http://www.sciencedirect.com/science/article/pii/S0167923614002310",
author = "Kasper Bislev Kallestrup and Lasse Hadberg Lynge and Renzo Akkerman and Thordis Anna Oddsdottir",
keywords = "Advanced planning systems",
keywords = "Hierarchical planning",
keywords = "Crude oil operations",
keywords = "Procurement planning "
}



@article{Zanuttigh2014,
title = "THESEUS decision support system for coastal risk management ",
journal = "Coastal Engineering ",
volume = "87",
number = "0",
pages = "218--239",
year = "2014",
issn = "0378-3839",
doi = "http://dx.doi.org/10.1016/j.coastaleng.2013.11.013",
url = "http://www.sciencedirect.com/science/article/pii/S0378383913001968",
author = "Barbara Zanuttigh and Dario Simcic and Stefano Bagli and Fabio Bozzeda and Luca Pietrantoni and Fabio Zagonari and Simon Hoggart and Robert J. Nicholls",
keywords = "Decision support system",
keywords = "Scenario analysis",
keywords = "Risk assessment",
keywords = "Risk mitigation",
keywords = "Society",
keywords = "Economy",
keywords = "Ecology",
keywords = "\{GIS\} "
}


%%%%% empresa

@article{Kolomvatsos2014,
title = "Sellers in e-marketplaces: A Fuzzy Logic based decision support system ",
journal = "Information Sciences ",
volume = "278",
number = "0",
pages = "267--284",
year = "2014",
note= "",
issn = "0020-0255",
doi = "http://dx.doi.org/10.1016/j.ins.2014.03.052",
url = "http://www.sciencedirect.com/science/article/pii/S0020025514003430",
author = "Kostas Kolomvatsos and Christos Anagnostopoulos and Stathes Hadjiefthymiades",
keywords = "Negotiation",
keywords = "Fuzzy Logic "
}

@article{Alalwan2014,
title = "Decision support capabilities of enterprise content management systems: An empirical investigation ",
journal = "Decision Support Systems",
volume = "68",
number = "0",
pages = "39--48",
year = "2014",
note= "",
issn = "0167-9236",
doi = "http://dx.doi.org/10.1016/j.dss.2014.09.002",
url = "http://www.sciencedirect.com/science/article/pii/S0167923614002309",
author = "Jaffar A. Alalwan and Manoj A. Thomas and H. Roland Weistroffer",
keywords = "Enterprise content management",
keywords = "\{ECM\}",
keywords = "Decision support "
}

@article{Munoz2014,
title = "Using mathematical knowledge management to support integrated decision-making in the enterprise",
journal = "Computers and Chemical Engineering ",
volume = "66",
number = "0",
pages = "139--150",
year = "2014",
issn = "0098-1354",
doi = "http://dx.doi.org/10.1016/j.compchemeng.2014.02.026",
url = "http://www.sciencedirect.com/science/article/pii/S0098135414000738",
author = "Edrisi Muñoz and Elisabet Cap\'on-Garc\'i­a and Jos\'e M. La\'i­nez-Aguirre and Antonio Espuña and Luis Puigjaner",
keywords = "Mathematical modeling",
keywords = "Decision support systems",
keywords = "Enterprise integration",
keywords = "Knowledge management "
}


%%%%%%medioambiente

@article{Reichert2007,
title = "Concepts of decision support for river rehabilitation ",
journal = "Environmental Modelling and Software ",
volume = "22",
number = "2",
pages = "188--201",
year = "2007",
issn = "1364-8152",
doi = "http://dx.doi.org/10.1016/j.envsoft.2005.07.017",
url = "http://www.sciencedirect.com/science/article/pii/S1364815205001799",
author = "P. Reichert and M. Borsuk and M. Hostmann and S. Schweizer and C. Spörri and K. Tockner and B. Truffer",
keywords = "Decision analysis",
keywords = "Stakeholder involvement",
keywords = "Decision support",
keywords = "Probability network",
keywords = "River rehabilitation",
keywords = "Ecological prediction "
}

@article{Kort2007,
title = "Decision making under uncertainty in a decision support system for the Red River ",
journal = "Environmental Modelling and Software ",
volume = "22",
number = "2",
pages = "128--136",
year = "2007",
issn = "1364-8152",
doi = "http://dx.doi.org/10.1016/j.envsoft.2005.07.014",
url = "http://www.sciencedirect.com/science/article/pii/S1364815205001738",
author = "Inge A.T. de Kort and Martijn J. Booij",
keywords = "Decision support system",
keywords = "Water management",
keywords = "Flood damage",
keywords = "Uncertainty",
keywords = "Ranking methodology",
keywords = "Appropriate scale",
keywords = "Red River "
}


%%%%medicina

@article{Lee2014,
title = "Impact of a clinical decision support system for high-alert medications on the prevention of prescription errors ",
journal = "International Journal of Medical Informatics ",
year = "2014",
issn = "1386--5056",
doi = "http://dx.doi.org/10.1016/j.ijmedinf.2014.08.006",
url = "http://www.sciencedirect.com/science/article/pii/S1386505614001609",
author = "JaeHo Lee and Hyewon Han and Minsu Ock and Sang-il Lee and SunGyo Lee and Min-Woo Jo",
keywords = "Medication errors",
keywords = "Patient safety",
keywords = "Clinical decision support systems",
keywords = "Computerized physician order entry system "
}

@article{Lomotan2012,
title = "Evaluating the use of a computerized clinical decision support system for asthma by pediatric pulmonologists ",
journal = "International Journal of Medical Informatics ",
volume = "81",
number = "3",
pages = "157--165",
year = "2012",
note= "",
issn = "1386-5056",
doi = "http://dx.doi.org/10.1016/j.ijmedinf.2011.11.004",
url = "http://www.sciencedirect.com/science/article/pii/S1386505611002371",
author = "Edwin A. Lomotan and Laura J. Hoeksema and Diana E. Edmonds and Gabriela RamÃ­rez-Garnica and Richard N. Shiffman and Leora I. Horwitz",
keywords = "Decision support systems",
keywords = "Clinical",
keywords = "Qualitative evaluation",
keywords = "Asthma "
}

%:%%%%%%%%% Para artículo extensión CMMSE2018 - Citados en IJCM

@article{zhang2017,
author = {Tengfei Zhang and Fumin Ma},
title = {Improved rough k-means clustering algorithm based on weighted distance measure with Gaussian function},
journal = {International Journal of Computer Mathematics},
volume = {94},
number = {4},
pages = {663-675},
year  = {2017},
publisher = {Taylor & Francis},
doi = {10.1080/00207160.2015.1124099},
URL = {https://doi.org/10.1080/00207160.2015.1124099},
eprint = {https://doi.org/10.1080/00207160.2015.1124099},
    abstract = { ABSTRACTRough k-means clustering algorithm and its extensions are introduced and successfully applied to real-life data where clusters do not necessarily have crisp boundaries. Experiments with the rough k-means clustering algorithm have shown that it provides a reasonable set of lower and upper bounds for a given dataset. However, the same weight was used for all the data objects in a lower or upper approximate set when computing the new centre for each cluster while the different impacts of the objects in a same approximation were ignored. An improved rough k-means clustering based on weighted distance measure with Gaussian function is proposed in this paper. The validity of this algorithm is demonstrated by simulation and experimental analysis. }
}

%:%%%%%%%%% Para artículo extensión CMMSE2018 - Citados en MMAS

@article{cordero2016,
author = {Rodríguez-Jiménez, Jose Manuel and Cordero, Pablo and Enciso, Manuel and Mora, Angel},
title = {Data mining algorithms to compute mixed concepts with negative attributes: an application to breast cancer data analysis},
journal = {Mathematical Methods in the Applied Sciences},
volume = {39},
number = {16},
year = {2016},
pages = {4829-4845},
keywords = {knowledge discovery, formal concept analysis, negative attributes, medical issues},
doi = {10.1002/mma.3814},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/mma.3814},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/mma.3814},
abstract = {In the design of mathematical methods for a medical problem, one of the kernel issues is the identification of symptoms and measures that could help in the diagnosis. Discovering connections among them constitute a big challenge because it allows to reduce the number of parameters to be considered in the mathematical model. In this work, we focus on formal concept analysis as a very promising technique to address this problem. In previous works, we have studied the use of formal concept analysis to manage attribute implications. In this work, we propose to extend the knowledge that we can extract from every context using positive and negative information, which constitutes an open problem. Based on the main classical algorithms, we propose new methods to generate the lattice concept with positive and negative information to be used as a kind of map of attribute connections. We also compare them in an experiment built with datasets from the UCI repository for machine learning. We finally apply the mining techniques to extract the knowledge contained in a real data set containing information about patients suffering breast cancer. The result obtained have been contrasted with medical scientists to illustrate the benefits of our proposal. Copyright Â© 2016 John Wiley \& Sons, Ltd.}
}


@article{barbary2017,
author = {El Barbary, O. G. and Salama, A. S. and Atlam, El Sayed},
title = {Granular information retrieval using neighborhood systems},
journal = {Mathematical Methods in the Applied Sciences},
volume = {41},
number = {15},
year = {2017},
pages = {5737-5753},
keywords = {document classification, granular computing, information retrieval, mixed neighborhood systems, rough sets, topological near open sets},
doi = {10.1002/mma.4610},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/mma.4610},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/mma.4610},
abstract = {With the rapid growth of the amount of information stored on networks such as the internet, it is more difficult for information seekers to retrieve relevant information. This paper illustrates the design and improvement of a near neighborhood approach of information retrieval system to facilitate domain specific search. In exacting, a novel model depending on the notion of neighborhood system designed to rank documents according the searchers specific granularity requirements. The initial experiments confirm that our approach outperforms a classical vector-based information retrieval system. Our research work opens the door to the design and development of the next generation of internet search engines to alleviate the problem of information overload using more topological concepts.}
}


@article{BAS2020112656,
title = {Picture fuzzy regression functions approach for financial time series based on ridge regression and genetic algorithm},
journal = {Journal of Computational and Applied Mathematics},
volume = {370},
pages = {112656},
year = {2020},
issn = {0377-0427},
doi = {https://doi.org/10.1016/j.cam.2019.112656},
url = {https://www.sciencedirect.com/science/article/pii/S0377042719306612},
author = {Eren Bas and Ufuk Yolcu and Erol Egrioglu},
keywords = {Forecasting, Picture fuzzy sets, Inference system, Ridge regression, Picture fuzzy clustering, Genetic algorithm},
abstract = {Recent years, fuzzy inference systems are efficient tools for solving forecasting problems. Fuzzy inference systems are based on fuzzy sets and use membership values besides original data so a data augmentation mechanism is employed in the fuzzy inference. Picture fuzzy sets provide additional information to original data via positive degree membership, negative degree membership, neutral degree membership and refusal degree membership apart from fuzzy sets. The data augmentation with this additional information will be provided to build a better inference system than fuzzy inference systems. In this study, picture fuzzy inference system is proposed for forecasting purpose by using ridge regression and genetic algorithm. Ridge regression method is used to obtain picture fuzzy functions and genetic algorithm is used to emerge different information coming from systems which are designed for positive degree membership, negative degree membership and neutral degree membership. In the proposed method, picture fuzzification is provided by picture fuzzy clustering. The proposed inference system is tested by various stock exchange data sets. The forecasting of the proposed method is compared with well-known forecasting methods. The obtained results are evaluated according to different error measures such as root of mean square error and mean of absolute percentage error.}
}
  